[
    {
        "title": "Soundtracks of Our Lives: How Age Influences Musical Preferences",
        "url": "http://arxiv.org/abs/2509.08337v1",
        "pub_date": "2025-09-10",
        "summary": "The majority of research in recommender systems, be it algorithmic improvements, context-awareness, explainability, or other areas, evaluates these systems on datasets that capture user interaction over a relatively limited time span. However, recommender systems can very well be used continuously for extended time. Similarly so, user behavior may evolve over that extended time. Although media studies and psychology offer a wealth of research on the evolution of user preferences and behavior as individuals age, there has been scant research in this regard within the realm of user modeling and recommender systems. In this study, we investigate the evolution of user preferences and behavior using the LFM-2b dataset, which, to our knowledge, is the only dataset that encompasses a sufficiently extensive time frame to permit real longitudinal studies and includes age information about its users. We identify specific usage and taste preferences directly related to the age of the user, i.e., while younger users tend to listen broadly to contemporary popular music, older users have more elaborate and personalized listening habits. The findings yield important insights that open new directions for research in recommender systems, providing guidance for future efforts.",
        "translated": "当前推荐系统领域的大多数研究——无论是算法改进、上下文感知、可解释性还是其他方向——均基于有限时间跨度的用户交互数据集进行评估。然而，推荐系统实际往往需要长期持续运行，用户行为也可能随时间推移产生演变。尽管媒体研究和心理学领域对用户偏好随年龄演变的规律已有丰富成果，但在用户建模与推荐系统领域中，针对这一问题的研究仍十分匮乏。本研究采用LFM-2b数据集（据我们所知，这是唯一兼具足够长时间跨度支持真实纵向研究、且包含用户年龄信息的数据集）深入探究用户偏好与行为的演变规律。我们发现：年轻用户倾向于广泛收听当代流行音乐，而年长用户则展现出更精细化、个性化的收听习惯——这种使用偏好与品味特征与用户年龄存在直接关联。这些发现为推荐系统研究开辟了新方向，为后续研究提供了重要指导。"
    },
    {
        "title": "Vector embedding of multi-modal texts: a tool for discovery?",
        "url": "http://arxiv.org/abs/2509.08216v1",
        "pub_date": "2025-09-10",
        "summary": "Computer science texts are particularly rich in both narrative content and illustrative charts, algorithms, images, annotated diagrams, etc. This study explores the extent to which vector-based multimodal retrieval, powered by vision-language models (VLMs), can improve discovery across multi-modal (text and images) content. Using over 3,600 digitized textbook pages largely from computer science textbooks and a Vision Language Model (VLM), we generate multi-vector representations capturing both textual and visual semantics. These embeddings are stored in a vector database. We issue a benchmark of 75 natural language queries and compare retrieval performance to ground truth and across four similarity (distance) measures. The study is intended to expose both the strengths and weakenesses of such an approach. We find that cosine similarity most effectively retrieves semantically and visually relevant pages. We further discuss the practicality of using a vector database and multi-modal embedding for operational information retrieval. Our paper is intended to offer design insights for discovery over digital libraries.   Keywords: Vector embedding, multi-modal document retrieval, vector database benchmark, digital library discovery",
        "translated": "计算机科学文献通常兼具丰富的叙述性内容与说明性图表、算法、图像及带标注的图示等。本研究探讨基于视觉语言模型（VLM）的向量多模态检索在提升跨文本与图像的多模态内容发现能力方面的效果。通过使用超过3,600页主要来自计算机科学教材的数字化页面及视觉语言模型，我们生成了能同时捕获文本与视觉语义的多向量表征。这些嵌入向量被存储于向量数据库中。我们发布了包含75个自然语言查询的基准测试集，并将检索效果与人工标注真值进行对比，同时评估了四种相似度（距离）度量方法的性能。本研究旨在揭示此类方法的优势与局限性。研究发现，余弦相似度能够最有效地检索出语义和视觉相关性较高的页面。我们进一步讨论了使用向量数据库与多模态嵌入在实际信息检索操作中的可行性。本文旨在为数字图书馆的文献发现机制提供设计参考。  \n关键词：向量嵌入，多模态文档检索，向量数据库基准测试，数字图书馆发现"
    },
    {
        "title": "Smart Fast Finish: Preventing Overdelivery via Daily Budget Pacing at\n  DoorDash",
        "url": "http://arxiv.org/abs/2509.07929v1",
        "pub_date": "2025-09-09",
        "summary": "We present a budget pacing feature called Smart Fast Finish (SFF). SFF builds upon the industry standard Fast Finish (FF) feature in budget pacing systems that depletes remaining advertising budget as quickly as possible towards the end of some fixed time period. SFF dynamically updates system parameters such as start time and throttle rate depending on historical ad-campaign data. SFF is currently in use at DoorDash, one of the largest delivery platforms in the US, and is part of its budget pacing system. We show via online budget-split experimentation data and offline simulations that SFF is a robust solution for overdelivery mitigation when pacing budget.",
        "translated": "我们提出了一种名为\"智能快速完成\"（Smart Fast Finish, SFF）的预算调控功能。该功能基于行业标准的快速完成（Fast Finish, FF）技术进行优化——在固定时间段末期将剩余广告预算以最快速度消耗完毕。SFF通过分析历史广告活动数据，动态更新系统参数（包括启动时间和调控速率）。目前该功能已应用于美国最大配送平台之一DoorDash的预算调控系统。在线预算分流实验数据和离线仿真结果表明，SFF是一种能有效缓解预算调控过程中超量投放问题的稳健解决方案。\n\n（注：根据学术论文摘要的规范要求，译文采用以下处理：\n1. 专业术语统一：\"budget pacing\"译为\"预算调控\"，\"overdelivery mitigation\"译为\"缓解超量投放\"\n2. 技术概念准确传达：\"dynamic updates\"译为\"动态更新\"，\"throttle rate\"译为\"调控速率\"\n3. 企业名称保留原文：\"DoorDash\"不译\n4. 研究论证表述规范：\"online/offline\"译为\"在线/离线\"，\"robust solution\"译为\"稳健解决方案\"\n5. 保持学术文本的客观性，避免口语化表达）"
    },
    {
        "title": "KLIPA: A Knowledge Graph and LLM-Driven QA Framework for IP Analysis",
        "url": "http://arxiv.org/abs/2509.07860v1",
        "pub_date": "2025-09-09",
        "summary": "Effectively managing intellectual property is a significant challenge. Traditional methods for patent analysis depend on labor-intensive manual searches and rigid keyword matching. These approaches are often inefficient and struggle to reveal the complex relationships hidden within large patent datasets, hindering strategic decision-making. To overcome these limitations, we introduce KLIPA, a novel framework that leverages a knowledge graph and a large language model (LLM) to significantly advance patent analysis. Our approach integrates three key components: a structured knowledge graph to map explicit relationships between patents, a retrieval-augmented generation(RAG) system to uncover contextual connections, and an intelligent agent that dynamically determines the optimal strategy for resolving user queries. We validated KLIPA on a comprehensive, real-world patent database, where it demonstrated substantial improvements in knowledge extraction, discovery of novel connections, and overall operational efficiency. This combination of technologies enhances retrieval accuracy, reduces reliance on domain experts, and provides a scalable, automated solution for any organization managing intellectual property, including technology corporations and legal firms, allowing them to better navigate the complexities of strategic innovation and competitive intelligence.",
        "translated": "有效管理知识产权是一项重大挑战。传统的专利分析方法依赖于劳动密集型的人工检索和僵化的关键词匹配。这些方法往往效率低下，难以揭示海量专利数据中隐藏的复杂关联，从而阻碍战略决策。为突破这些局限，我们提出KLIPA这一创新框架，该框架通过结合知识图谱和大语言模型（LLM）显著推进专利分析能力。我们的方法整合了三个核心组件：用于构建专利间显性关联的结构化知识图谱、用于挖掘上下文联系的检索增强生成（RAG）系统，以及能动态确定最优解策策略的智能代理。我们在真实世界的全量专利数据库上验证了KLIPA，其在知识提取、新颖关联发现和整体操作效率方面均展现出显著提升。这种技术融合增强了检索精度，降低了对领域专家的依赖，为包括科技企业和律师事务所在内的知识产权管理机构提供了可扩展的自动化解决方案，使其能更好地应对战略创新与竞争情报领域的复杂性。"
    },
    {
        "title": "SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and\n  Relation Extraction in NLP",
        "url": "http://arxiv.org/abs/2509.07801v2",
        "pub_date": "2025-09-09",
        "summary": "Structured information extraction from scientific literature is crucial for capturing core concepts and emerging trends in specialized fields. While existing datasets aid model development, most focus on specific publication sections due to domain complexity and the high cost of annotating scientific texts. To address this limitation, we introduce SciNLP - a specialized benchmark for full-text entity and relation extraction in the Natural Language Processing (NLP) domain. The dataset comprises 60 manually annotated full-text NLP publications, covering 7,072 entities and 1,826 relations. Compared to existing research, SciNLP is the first dataset providing full-text annotations of entities and their relationships in the NLP domain. To validate the effectiveness of SciNLP, we conducted comparative experiments with similar datasets and evaluated the performance of state-of-the-art supervised models on this dataset. Results reveal varying extraction capabilities of existing models across academic texts of different lengths. Cross-comparisons with existing datasets show that SciNLP achieves significant performance improvements on certain baseline models. Using models trained on SciNLP, we implemented automatic construction of a fine-grained knowledge graph for the NLP domain. Our KG has an average node degree of 3.2 per entity, indicating rich semantic topological information that enhances downstream applications. The dataset is publicly available at https://github.com/AKADDC/SciNLP.",
        "translated": "从科学文献中抽取结构化信息对于捕捉专业领域的核心概念与新兴趋势至关重要。虽然现有数据集有助于模型开发，但由于领域复杂性和科学文本标注成本高昂，多数数据集仅聚焦特定章节。为突破这一局限，我们推出SciNLP——专为自然语言处理（NLP）领域设计的全文实体与关系抽取基准数据集。该数据集包含60篇经人工标注的NLP领域全文文献，涵盖7,072个实体和1,826组关系。与现有研究相比，SciNLP是首个提供NLP领域全文级实体及其关系标注的数据集。为验证SciNLP的有效性，我们与同类数据集进行对比实验，并评估了前沿监督模型在该数据集上的表现。结果显示现有模型对不同长度学术文本的抽取能力存在显著差异。与现有数据集的交叉对比表明，SciNLP在部分基线模型上实现了显著性能提升。基于SciNLP训练的模型，我们实现了NLP领域细粒度知识图谱的自动构建。该知识图谱平均每个实体拥有3.2个节点连接度，展现出丰富的语义拓扑信息，可有效增强下游应用性能。数据集已公开于https://github.com/AKADDC/SciNLP。\n\n（注：译文严格遵循学术论文表述规范，对\"entity and relation extraction\"采用\"实体与关系抽取\"标准译法，\"knowledge graph\"译为\"知识图谱\"，\"node degree\"译为\"节点连接度\"等专业术语均符合计算机领域中文表达惯例。长难句如\"Results reveal varying...\"通过拆分重组转化为符合中文表达习惯的短句，同时保持逻辑严谨性。）"
    },
    {
        "title": "Query Expansion in the Age of Pre-trained and Large Language Models: A\n  Comprehensive Survey",
        "url": "http://arxiv.org/abs/2509.07794v1",
        "pub_date": "2025-09-09",
        "summary": "Modern information retrieval (IR) must bridge short, ambiguous queries and ever more diverse, rapidly evolving corpora. Query Expansion (QE) remains a key mechanism for mitigating vocabulary mismatch, but the design space has shifted markedly with pre-trained language models (PLMs) and large language models (LLMs). This survey synthesizes the field from three angles: (i) a four-dimensional framework of query expansion - from the point of injection (explicit vs. implicit QE), through grounding and interaction (knowledge bases, model-internal capabilities, multi-turn retrieval) and learning alignment, to knowledge graph-based argumentation; (ii) a model-centric taxonomy spanning encoder-only, encoder-decoder, decoder-only, instruction-tuned, and domain/multilingual variants, highlighting their characteristic affordances for QE (contextual disambiguation, controllable generation, zero-/few-shot reasoning); and (iii) practice-oriented guidance on where and how neural QE helps in first-stage retrieval, multi-query fusion, re-ranking, and retrieval-augmented generation (RAG). We compare traditional query expansion with PLM/LLM-based methods across seven key aspects, and we map applications across web search, biomedicine, e-commerce, open-domain QA/RAG, conversational and code search, and cross-lingual settings. The review distills design grounding and interaction, alignment/distillation (SFT/PEFT/DPO), and KG constraints - as robust remedies to topic drift and hallucination. We conclude with an agenda on quality control, cost-aware invocation, domain/temporal adaptation, evaluation beyond end-task metrics, and fairness/privacy. Collectively, these insights provide a principled blueprint for selecting and combining QE techniques under real-world constraints.",
        "translated": "现代信息检索（IR）需要弥合简短模糊的查询与日益多样化、快速演变的语料库之间的鸿沟。查询扩展（QE）作为缓解词汇失配的关键机制，其设计范式已因预训练语言模型（PLM）和大语言模型（LLM）发生显著转变。本综述从三个维度系统梳理该领域：（i）提出查询扩展的四维框架——从注入方式（显式/隐式QE）出发，贯穿 grounding 与交互机制（知识库、模型内部能力、多轮检索）、学习对齐策略，直至基于知识图谱的论证；（ii）建立以模型为核心的分类体系，涵盖仅编码器、编码器-解码器、仅解码器、指令微调及领域/多语言变体，重点阐释其特有的QE能力（上下文消歧、可控生成、零样本/少样本推理）；（iii）提供实践导向的指南，说明神经QE在首阶段检索、多查询融合、重排序及检索增强生成（RAG）中的适用场景与方法。通过七个关键维度对比传统QE与基于PLM/LLM的方法，并绘制其在网络搜索、生物医学、电子商务、开放域QA/RAG、会话式搜索、代码检索及跨语言场景的应用图谱。研究提炼出三大核心设计原则：基于 grounding 的交互机制、对齐与蒸馏技术（SFT/PEFT/DPO）以及知识图谱约束——这些被证明是解决主题漂移和幻觉问题的有效方案。最后提出质量控制、成本感知调用、领域/时序适应性、超越终端任务指标的评估体系及公平性/隐私保护等未来研究方向。这些见解共同为实际约束条件下QE技术的选择与组合提供了系统化蓝图。\n\n（注：术语处理说明：\n- grounding 保留英文，因中文尚无统一译法且该术语在AI领域常直接使用\n- SFT/PEFT/DPO 为技术缩写（全称：Supervised Fine-Tuning/Parameter-Efficient Fine-Tuning/Direct Preference Optimization）\n- QA/RAG 等缩写已在领域内广泛采用\n- 保持\"零样本/少样本\"等标准译法以符合技术文献惯例）"
    },
    {
        "title": "A Survey of Long-Document Retrieval in the PLM and LLM Era",
        "url": "http://arxiv.org/abs/2509.07759v1",
        "pub_date": "2025-09-09",
        "summary": "The proliferation of long-form documents presents a fundamental challenge to information retrieval (IR), as their length, dispersed evidence, and complex structures demand specialized methods beyond standard passage-level techniques. This survey provides the first comprehensive treatment of long-document retrieval (LDR), consolidating methods, challenges, and applications across three major eras. We systematize the evolution from classical lexical and early neural models to modern pre-trained (PLM) and large language models (LLMs), covering key paradigms like passage aggregation, hierarchical encoding, efficient attention, and the latest LLM-driven re-ranking and retrieval techniques. Beyond the models, we review domain-specific applications, specialized evaluation resources, and outline critical open challenges such as efficiency trade-offs, multimodal alignment, and faithfulness. This survey aims to provide both a consolidated reference and a forward-looking agenda for advancing long-document retrieval in the era of foundation models.",
        "translated": "长文档的激增对信息检索（IR）领域提出了根本性挑战——其篇幅长度、分散的证据分布以及复杂结构要求采用超越标准段落级技术的专门方法。本综述首次对长文档检索（LDR）领域进行系统性梳理，整合了三大技术演进阶段的方法体系、核心挑战与应用实践。我们系统化追溯了从经典词法模型、早期神经模型到现代预训练模型（PLM）及大语言模型（LLMs）的技术演进，涵盖段落聚合、层次化编码、高效注意力机制等关键范式，以及最新LLM驱动的重排序与检索技术。除模型架构外，我们还审视了特定领域应用场景、专项评估资源，并指出效率权衡、多模态对齐和结果可信度等关键开放挑战。本综述旨在为基础模型时代的长文档检索研究提供系统化参考框架与前瞻性发展路线图。"
    },
    {
        "title": "Towards End-to-End Model-Agnostic Explanations for RAG Systems",
        "url": "http://arxiv.org/abs/2509.07620v1",
        "pub_date": "2025-09-09",
        "summary": "Retrieval Augmented Generation (RAG) systems, despite their growing popularity for enhancing model response reliability, often struggle with trustworthiness and explainability. In this work, we present a novel, holistic, model-agnostic, post-hoc explanation framework leveraging perturbation-based techniques to explain the retrieval and generation processes in a RAG system. We propose different strategies to evaluate these explanations and discuss the sufficiency of model-agnostic explanations in RAG systems. With this work, we further aim to catalyze a collaborative effort to build reliable and explainable RAG systems.",
        "translated": "尽管检索增强生成（RAG）系统在提升模型响应可靠性方面日益普及，但其可信度与可解释性仍面临挑战。本研究提出了一种新颖的、整体性的、模型无关的事后解释框架，该框架基于扰动技术来解释RAG系统中的检索与生成过程。我们提出了多种策略来评估这些解释的有效性，并探讨了模型无关解释在RAG系统中的充分性。通过此项研究，我们旨在推动学界与业界共同努力，构建更可靠、更可解释的RAG系统。\n\n（注：译文严格遵循了以下技术细节处理：\n1. \"post-hoc explanation\"译为\"事后解释\"（而非\"事后诸葛亮式解释\"），符合机器学习可解释性领域的术语规范\n2. \"perturbation-based techniques\"译为\"扰动技术\"，准确反映通过对输入进行微小扰动来评估模型敏感度的技术本质\n3. \"model-agnostic\"统一译为\"模型无关\"，保持与机器学习领域术语的一致性\n4. 使用\"可解释性\"而非\"解释性\"，符合人工智能透明度研究领域的标准译法\n5. 保留RAG、LLM等专业术语的英文缩写形式，确保学术严谨性）"
    },
    {
        "title": "ELEC: Efficient Large Language Model-Empowered Click-Through Rate\n  Prediction",
        "url": "http://arxiv.org/abs/2509.07594v1",
        "pub_date": "2025-09-09",
        "summary": "Click-through rate (CTR) prediction plays an important role in online advertising systems. On the one hand, traditional CTR prediction models capture the collaborative signals in tabular data via feature interaction modeling, but they lose semantics in text. On the other hand, Large Language Models (LLMs) excel in understanding the context and meaning behind text, but they face challenges in capturing collaborative signals and they have long inference latency. In this paper, we aim to leverage the benefits of both types of models and pursue collaboration, semantics and efficiency. We present ELEC, which is an Efficient LLM-Empowered CTR prediction framework. We first adapt an LLM for the CTR prediction task. In order to leverage the ability of the LLM but simultaneously keep efficiency, we utilize the pseudo-siamese network which contains a gain network and a vanilla network. We inject the high-level representation vector generated by the LLM into a collaborative CTR model to form the gain network such that it can take advantage of both tabular modeling and textual modeling. However, its reliance on the LLM limits its efficiency. We then distill the knowledge from the gain network to the vanilla network on both the score level and the representation level, such that the vanilla network takes only tabular data as input, but can still generate comparable performance as the gain network. Our approach is model-agnostic. It allows for the integration with various existing LLMs and collaborative CTR models. Experiments on real-world datasets demonstrate the effectiveness and efficiency of ELEC for CTR prediction.",
        "translated": "点击率（CTT）预测在在线广告系统中具有重要作用。一方面，传统CTR预测模型通过特征交互建模捕捉表格数据中的协同信号，但会丢失文本语义信息；另一方面，大语言模型（LLM）擅长理解文本背后的上下文和语义，但在捕捉协同信号方面存在局限且推理延迟较高。本文旨在融合两类模型的优势，实现协同性、语义理解与效率的平衡。我们提出ELEC框架——一种高效的大语言模型赋能CTR预测方案。首先针对CTR预测任务对大语言模型进行适配，为兼顾模型能力与效率，采用包含增益网络和基准网络的双伪孪生网络结构。通过将LLM生成的高层表征向量注入协同CTR模型形成增益网络，使其能同时利用表格建模和文本建模的优势。但该网络对LLM的依赖会影响效率，因此我们通过分数级和表征级蒸馏将增益网络的知识迁移至仅需输入表格数据的基准网络，使其在保持高效的同时达到与增益网络相当的性能。本方法具备模型无关性，可与多种现有LLM及协同CTR模型集成。真实场景数据集上的实验验证了ELEC在CTR预测中的有效性与高效性。"
    },
    {
        "title": "FLeW: Facet-Level and Adaptive Weighted Representation Learning of\n  Scientific Documents",
        "url": "http://arxiv.org/abs/2509.07531v1",
        "pub_date": "2025-09-09",
        "summary": "Scientific document representation learning provides powerful embeddings for various tasks, while current methods face challenges across three approaches. 1) Contrastive training with citation-structural signals underutilizes citation information and still generates single-vector representations. 2) Fine-grained representation learning, which generates multiple vectors at the sentence or aspect level, requires costly integration and lacks domain generalization. 3) Task-aware learning depends on manually predefined task categorization, overlooking nuanced task distinctions and requiring extra training data for task-specific modules. To address these problems, we propose a new method that unifies the three approaches for better representations, namely FLeW. Specifically, we introduce a novel triplet sampling method that leverages citation intent and frequency to enhance citation-structural signals for training. Citation intents (background, method, result), aligned with the general structure of scientific writing, facilitate a domain-generalized facet partition for fine-grained representation learning. Then, we adopt a simple weight search to adaptively integrate three facet-level embeddings into a task-specific document embedding without task-aware fine-tuning. Experiments show the applicability and robustness of FLeW across multiple scientific tasks and fields, compared to prior models.",
        "translated": "科学文献表示学习为各类任务提供了强大的嵌入向量，但现有方法面临三大挑战：1）基于引文结构信号的对比训练未能充分利用引文信息，且仍生成单一向量表示；2）细粒度表示学习虽能生成句子或方面级的多向量表示，但需要昂贵的人工整合且缺乏领域泛化能力；3）任务感知学习依赖人工预定义的任务分类，忽略了细微的任务差异，且需为特定任务模块提供额外训练数据。针对这些问题，我们提出统一三种范式的新方法FLeW以获取更优表示。具体而言，我们设计了一种新型三元组采样方法，通过引文意图（背景、方法、结果）和引用频次增强引文结构信号训练——引文意图与科学写作通用结构相契合，可为细粒度表示学习提供领域泛化的方面划分。随后采用简易权重搜索机制，无需任务感知微调即可自适应整合三个方面级嵌入形成任务适配的文档表示。实验表明，相较于现有模型，FLeW在多个科学任务和学科领域均展现出卓越的适用性与鲁棒性。"
    },
    {
        "title": "ALLabel: Three-stage Active Learning for LLM-based Entity Recognition\n  using Demonstration Retrieval",
        "url": "http://arxiv.org/abs/2509.07512v1",
        "pub_date": "2025-09-09",
        "summary": "Many contemporary data-driven research efforts in the natural sciences, such as chemistry and materials science, require large-scale, high-performance entity recognition from scientific datasets. Large language models (LLMs) have increasingly been adopted to solve the entity recognition task, with the same trend being observed on all-spectrum NLP tasks. The prevailing entity recognition LLMs rely on fine-tuned technology, yet the fine-tuning process often incurs significant cost. To achieve a best performance-cost trade-off, we propose ALLabel, a three-stage framework designed to select the most informative and representative samples in preparing the demonstrations for LLM modeling. The annotated examples are used to construct a ground-truth retrieval corpus for LLM in-context learning. By sequentially employing three distinct active learning strategies, ALLabel consistently outperforms all baselines under the same annotation budget across three specialized domain datasets. Experimental results also demonstrate that selectively annotating only 5\\%-10\\% of the dataset with ALLabel can achieve performance comparable to the method annotating the entire dataset. Further analyses and ablation studies verify the effectiveness and generalizability of our proposal.",
        "translated": "在化学与材料科学等自然科学的当代数据驱动研究中，大规模高性能的实体识别已成为科学数据集处理的关键需求。大型语言模型（LLMs）正被日益广泛地应用于实体识别任务，这一趋势也体现在全谱系自然语言处理任务中。当前主流的实体识别大模型依赖于微调技术，但微调过程往往伴随着高昂成本。为实现性能与成本的最优平衡，我们提出ALLabel——一个三阶段框架，通过三种主动学习策略的序列化应用，从标注数据中筛选信息量最大且最具代表性的样本，用于构建大模型上下文学习所需的真实标注检索库。在三个专业领域数据集上，ALLabel在相同标注预算下持续超越所有基线模型。实验结果表明：使用ALLabel仅需标注5%-10%的数据量即可达到全量标注方法的性能水平。进一步的解析与消融研究验证了该方案的有效性和泛化能力。\n\n（注：专业术语说明：\n1. entity recognition：实体识别\n2. large language models (LLMs)：大型语言模型\n3. fine-tuned technology：微调技术\n4. active learning strategies：主动学习策略\n5. in-context learning：上下文学习\n6. ablation studies：消融研究\n7. annotation budget：标注预算\n8. ground-truth retrieval corpus：真实标注检索库）"
    },
    {
        "title": "Multi-view-guided Passage Reranking with Large Language Models",
        "url": "http://arxiv.org/abs/2509.07485v1",
        "pub_date": "2025-09-09",
        "summary": "Recent advances in large language models (LLMs) have shown impressive performance in passage reranking tasks. Despite their success, LLM-based methods still face challenges in efficiency and sensitivity to external biases. (1) Existing models rely mostly on autoregressive generation and sliding window strategies to rank passages, which incur heavy computational overhead as the number of passages increases. (2) External biases, such as position or selection bias, hinder the model's ability to accurately represent passages and increase input-order sensitivity. To address these limitations, we introduce a novel passage reranking model, called Multi-View-guided Passage Reranking (MVP). MVP is a non-generative LLM-based reranking method that encodes query-passage information into diverse view embeddings without being influenced by external biases. For each view, it combines query-aware passage embeddings to produce a distinct anchor vector, which is then used to directly compute relevance scores in a single decoding step. In addition, it employs an orthogonal loss to make the views more distinctive. Extensive experiments demonstrate that MVP, with just 220M parameters, matches the performance of much larger 7B-scale fine-tuned models while achieving a 100x reduction in inference latency. Notably, the 3B-parameter variant of MVP achieves state-of-the-art performance on both in-domain and out-of-domain benchmarks. The source code is available at: https://github.com/bulbna/MVP",
        "translated": "近年来，大语言模型（LLM）在段落重排序任务中展现出卓越性能。尽管成效显著，基于LLM的方法仍面临效率问题与外部偏差敏感性两大挑战：（1）现有模型主要依赖自回归生成和滑动窗口策略进行段落排序，随着段落数量增加会产生巨大计算开销；（2）位置偏差和选择偏差等外部因素会干扰模型对段落的准确表征，并增强对输入顺序的敏感性。为解决这些局限性，我们提出了一种新型段落重排序模型——多视角引导段落重排序（MVP）。该非生成式LLM重排序方法通过将查询-段落信息编码为多视角嵌入向量，有效规避外部偏差影响。针对每个视角，模型融合查询感知的段落嵌入生成独特锚点向量，进而通过单步解码直接计算相关性得分。此外，该方法采用正交损失函数以增强视角区分度。大量实验表明，仅需2.2亿参数的MVP模型在实现推理延迟降低100倍的同时，性能可媲美70亿参数规模的精调模型。特别值得注意的是，30亿参数版本的MVP在领域内和领域外基准测试中均达到了最先进的性能水平。源代码已开源：https://github.com/bulbna/MVP\n\n（注：译文严格遵循以下技术规范：\n1. 专业术语统一处理：\"autoregressive generation\"译为\"自回归生成\"，\"orthogonal loss\"译为\"正交损失函数\"\n2. 数量单位规范：\"220M/7B\"转换为\"2.2亿/70亿\"符合中文计量习惯\n3. 技术概念准确传达：\"view embeddings\"意译为\"视角嵌入向量\"而非字面直译\n4. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句\n5. 被动语态转化：\"are used to\"转换为主动语态\"通过...实现\"\n6. 学术表达规范：\"state-of-the-art\"译为\"最先进的\"符合学术中文惯例）"
    },
    {
        "title": "MEGG: Replay via Maximally Extreme GGscore in Incremental Learning for\n  Neural Recommendation Models",
        "url": "http://arxiv.org/abs/2509.07319v1",
        "pub_date": "2025-09-09",
        "summary": "Neural Collaborative Filtering models are widely used in recommender systems but are typically trained under static settings, assuming fixed data distributions. This limits their applicability in dynamic environments where user preferences evolve. Incremental learning offers a promising solution, yet conventional methods from computer vision or NLP face challenges in recommendation tasks due to data sparsity and distinct task paradigms. Existing approaches for neural recommenders remain limited and often lack generalizability. To address this, we propose MEGG, Replay Samples with Maximally Extreme GGscore, an experience replay based incremental learning framework. MEGG introduces GGscore, a novel metric that quantifies sample influence, enabling the selective replay of highly influential samples to mitigate catastrophic forgetting. Being model-agnostic, MEGG integrates seamlessly across architectures and frameworks. Experiments on three neural models and four benchmark datasets show superior performance over state-of-the-art baselines, with strong scalability, efficiency, and robustness. Implementation will be released publicly upon acceptance.",
        "translated": "神经协同过滤模型在推荐系统中应用广泛，但通常基于静态设定进行训练，假设数据分布固定不变。这限制了其在用户偏好动态演变环境中的适用性。增量学习虽提供了可行方案，但来自计算机视觉或自然语言处理领域的传统方法因数据稀疏性和任务范式差异，在推荐任务中面临挑战。现有神经推荐器的增量学习方法仍存在局限，且普遍缺乏泛化能力。为此，我们提出MEGG（基于极端GG分数的回放样本）——一种基于经验回放的增量学习框架。MEGG创新性地引入GGscore指标，通过量化样本影响力来实现高效选择性样本回放，从而有效缓解灾难性遗忘问题。该框架具备模型无关特性，可无缝集成至不同架构与框架。在三种神经模型和四个基准数据集上的实验表明，其性能显著优于现有最优基线方法，并展现出强大的可扩展性、高效性和鲁棒性。代码实现将在论文录用后开源发布。\n\n（注：GGscore保留英文大写形式，符合技术术语惯例；\"catastrophic forgetting\"译为专业术语\"灾难性遗忘\"；\"model-agnostic\"采用通用译法\"模型无关\"；\"state-of-the-art\"译为\"现有最优\"符合学术语境）"
    },
    {
        "title": "Datasets for Navigating Sensitive Topics in Recommendation Systems",
        "url": "http://arxiv.org/abs/2509.07269v1",
        "pub_date": "2025-09-08",
        "summary": "Personalized AI systems, from recommendation systems to chatbots, are a prevalent method for distributing content to users based on their learned preferences. However, there is growing concern about the adverse effects of these systems, including their potential tendency to expose users to sensitive or harmful material, negatively impacting overall well-being. To address this concern quantitatively, it is necessary to create datasets with relevant sensitivity labels for content, enabling researchers to evaluate personalized systems beyond mere engagement metrics. To this end, we introduce two novel datasets that include a taxonomy of sensitivity labels alongside user-content ratings: one that integrates MovieLens rating data with content warnings from the Does the Dog Die? community ratings website, and another that combines fan-fiction interaction data and user-generated warnings from Archive of Our Own.",
        "translated": "个性化人工智能系统（从推荐系统到聊天机器人）已成为根据用户学习偏好分发内容的普遍方式。然而，人们日益关注这些系统的负面影响，特别是其可能使用户接触敏感或有害内容，从而对整体福祉产生负面影响的倾向。为量化评估这一问题，需要构建带有内容敏感度标签的数据集，使研究者能够超越简单的参与度指标来评估个性化系统。为此，我们引入了两个新型数据集：一个将MovieLens评分数据与Does the Dog Die?社区评级网站的内容警示标签体系相结合，另一个整合了Archive of Our Own平台的同人小说互动数据与用户生成的警示标签。这些数据集不仅包含用户-内容评分，还提供了系统化的敏感度分类标注。"
    },
    {
        "title": "Benchmarking Information Retrieval Models on Complex Retrieval Tasks",
        "url": "http://arxiv.org/abs/2509.07253v1",
        "pub_date": "2025-09-08",
        "summary": "Large language models (LLMs) are incredible and versatile tools for text-based tasks that have enabled countless, previously unimaginable, applications. Retrieval models, in contrast, have not yet seen such capable general-purpose models emerge. To achieve this goal, retrieval models must be able to perform complex retrieval tasks, where queries contain multiple parts, constraints, or requirements in natural language. These tasks represent a natural progression from the simple, single-aspect queries that are used in the vast majority of existing, commonly used evaluation sets. Complex queries naturally arise as people expect search systems to handle more specific and often ambitious information requests, as is demonstrated by how people use LLM-based information systems. Despite the growing desire for retrieval models to expand their capabilities in complex retrieval tasks, there exist limited resources to assess the ability of retrieval models on a comprehensive set of diverse complex tasks. The few resources that do exist feature a limited scope and often lack realistic settings making it hard to know the true capabilities of retrieval models on complex real-world retrieval tasks. To address this shortcoming and spur innovation in next-generation retrieval models, we construct a diverse and realistic set of complex retrieval tasks and benchmark a representative set of state-of-the-art retrieval models. Additionally, we explore the impact of LLM-based query expansion and rewriting on retrieval quality. Our results show that even the best models struggle to produce high-quality retrieval results with the highest average nDCG@10 of only 0.346 and R@100 of only 0.587 across all tasks. Although LLM augmentation can help weaker models, the strongest model has decreased performance across all metrics with all rewriting techniques.",
        "translated": "大型语言模型（LLM）是处理文本任务的卓越多功能工具，其催生了无数前所未有的应用场景。相比之下，检索模型领域尚未出现具备同等通用能力的模型。要实现这一目标，检索模型必须能够处理复杂检索任务——即查询语句包含多组成部分、约束条件或自然语言需求的场景。这类任务代表着对现有主流评估集中普遍采用的简单单维度查询的自然演进。随着用户期望搜索系统能处理更具体且更具挑战性的信息请求（正如基于LLM的信息系统的使用方式所展现的），复杂查询需求应运而生。\n\n尽管业界对检索模型拓展复杂检索能力的呼声日益高涨，但目前缺乏能够全面评估检索模型在多样化复杂任务上表现的标准资源。现有少数评估资源不仅覆盖范围有限，且往往缺乏真实场景设置，导致难以准确衡量检索模型在现实复杂检索任务中的真实能力。\n\n为弥补这一缺陷并推动下一代检索模型的发展，我们构建了具有多样性和真实性的复杂检索任务集，并对代表性前沿检索模型进行基准测试。此外，我们还探究了基于LLM的查询扩展与重写技术对检索质量的影响。实验结果表明：即使最优模型在复杂检索任务中也表现挣扎，所有任务的平均nDCG@10最高仅达0.346，R@100最高仅为0.587。虽然LLM增强技术能提升较弱模型的性能，但所有重写技术都会导致最强模型的全指标性能下降。"
    },
    {
        "title": "Beyond Sequential Reranking: Reranker-Guided Search Improves Reasoning\n  Intensive Retrieval",
        "url": "http://arxiv.org/abs/2509.07163v1",
        "pub_date": "2025-09-08",
        "summary": "The widely used retrieve-and-rerank pipeline faces two critical limitations: they are constrained by the initial retrieval quality of the top-k documents, and the growing computational demands of LLM-based rerankers restrict the number of documents that can be effectively processed. We introduce Reranker-Guided-Search (RGS), a novel approach that bypasses these limitations by directly retrieving documents according to reranker preferences rather than following the traditional sequential reranking method. Our method uses a greedy search on proximity graphs generated by approximate nearest neighbor algorithms, strategically prioritizing promising documents for reranking based on document similarity. Experimental results demonstrate substantial performance improvements across multiple benchmarks: 3.5 points on BRIGHT, 2.9 on FollowIR, and 5.1 on M-BEIR, all within a constrained reranker budget of 100 documents. Our analysis suggests that, given a fixed pair of embedding and reranker models, strategically selecting documents to rerank can significantly improve retrieval accuracy under limited reranker budget.",
        "translated": "当前广泛使用的“检索-重排序”流程面临两个关键局限：其性能受限于前k篇文档的初始检索质量，且基于大语言模型的重排序器计算需求日益增长，限制了可有效处理的文档数量。我们提出了一种创新方法——重排序器引导搜索（Reranker-Guided-Search, RGS），通过直接根据重排序器的偏好检索文档（而非遵循传统的顺序重排序流程）来突破这些限制。该方法在近似最近邻算法生成的邻近图上进行贪婪搜索，基于文档相似性策略性地优先选择有潜力的文档进行重排序。实验结果表明，在多个基准测试中均取得显著性能提升：BRIGHT数据集提升3.5个点，FollowIR提升2.9个点，M-BEIR提升5.1个点——且所有这些改进均在100篇文档的重排序计算预算内实现。我们的分析表明，在固定嵌入模型和重排序器组合的前提下，通过策略性选择待重排序文档，能够在有限计算资源下显著提升检索精度。\n\n（注：专业术语说明：\n1. retrieve-and-rerank pipeline：译为\"检索-重排序流程\"\n2. LLM-based rerankers：译为\"基于大语言模型的重排序器\"\n3. proximity graphs：译为\"邻近图\"\n4. approximate nearest neighbor：译为\"近似最近邻\"\n5. constrained reranker budget：译为\"受限的重排序计算预算\"\n6. embedding model：译为\"嵌入模型\"\n所有技术概念均采用计算机信息检索领域标准译法，确保学术准确性。）"
    },
    {
        "title": "Avoiding Over-Personalization with Rule-Guided Knowledge Graph\n  Adaptation for LLM Recommendations",
        "url": "http://arxiv.org/abs/2509.07133v1",
        "pub_date": "2025-09-08",
        "summary": "We present a lightweight neuro-symbolic framework to mitigate over-personalization in LLM-based recommender systems by adapting user-side Knowledge Graphs (KGs) at inference time. Instead of retraining models or relying on opaque heuristics, our method restructures a user's Personalized Knowledge Graph (PKG) to suppress feature co-occurrence patterns that reinforce Personalized Information Environments (PIEs), i.e., algorithmically induced filter bubbles that constrain content diversity. These adapted PKGs are used to construct structured prompts that steer the language model toward more diverse, Out-PIE recommendations while preserving topical relevance. We introduce a family of symbolic adaptation strategies, including soft reweighting, hard inversion, and targeted removal of biased triples, and a client-side learning algorithm that optimizes their application per user. Experiments on a recipe recommendation benchmark show that personalized PKG adaptations significantly increase content novelty while maintaining recommendation quality, outperforming global adaptation and naive prompt-based methods.",
        "translated": "我们提出了一种轻量级神经符号框架，通过推理时自适应调整用户侧知识图谱（KG）来缓解基于大语言模型的推荐系统中的过度个性化问题。与传统重训练模型或依赖不透明启发式方法不同，我们的方法通过重构用户个性化知识图谱（PKG），抑制那些强化个性化信息环境（PIE）的特征共现模式——即算法导致的限制内容多样性的信息茧房。调整后的PKG用于构建结构化提示，引导语言模型在保持主题相关性的同时生成更多样化的\"非PIE\"推荐。我们提出了一系列符号化适配策略，包括软重加权、硬反转和针对性移除偏见三元组，以及客户端学习算法以优化每用户的策略应用。在食谱推荐基准测试中，个性化PKG适配在保持推荐质量的同时显著提升内容新颖度，其效果优于全局适配和基于朴素提示的方法。\n\n（注：专业术语说明：\n1. Personalized Information Environments (PIEs) 译为\"个性化信息环境\"，特指算法导致的信息茧房效应\n2. Out-PIE recommendations 译为\"非PIE推荐\"，指突破信息茧房的推荐内容\n3. soft reweighting/hard inversion 分别译为\"软重加权/硬反转\"，保持机器学习领域的术语惯例\n4. client-side learning algorithm 译为\"客户端学习算法\"，强调分布式计算场景下的本地化特性）"
    },
    {
        "title": "mmBERT: A Modern Multilingual Encoder with Annealed Language Learning",
        "url": "http://arxiv.org/abs/2509.06888v1",
        "pub_date": "2025-09-08",
        "summary": "Encoder-only languages models are frequently used for a variety of standard machine learning tasks, including classification and retrieval. However, there has been a lack of recent research for encoder models, especially with respect to multilingual models. We introduce mmBERT, an encoder-only language model pretrained on 3T tokens of multilingual text in over 1800 languages. To build mmBERT we introduce several novel elements, including an inverse mask ratio schedule and an inverse temperature sampling ratio. We add over 1700 low-resource languages to the data mix only during the decay phase, showing that it boosts performance dramatically and maximizes the gains from the relatively small amount of training data. Despite only including these low-resource languages in the short decay phase we achieve similar classification performance to models like OpenAI's o3 and Google's Gemini 2.5 Pro. Overall, we show that mmBERT significantly outperforms the previous generation of models on classification and retrieval tasks -- on both high and low-resource languages.",
        "translated": "编码器专用语言模型（Encoder-only language models）常被用于各类标准机器学习任务，包括分类与检索。然而当前针对编码器模型的研究，特别是多语言模型领域的研究仍显不足。我们提出了mmBERT——一种基于1800多种语言、3万亿多语种文本训练的纯编码器语言模型。在构建mmBERT过程中，我们引入了多项创新要素，包括逆向掩码比率调度机制和逆向温度采样策略。我们创新性地仅在训练衰减阶段加入1700余种低资源语言数据，实验表明这一方法显著提升模型性能，并最大限度利用了有限训练数据带来的增益。尽管这些低资源语言仅出现在短暂的衰减阶段，我们的模型在分类任务上达到了与OpenAI o3、Google Gemini 2.5 Pro等模型相当的性能。总体而言，mmBERT在高资源与低资源语言的分类和检索任务上均显著超越前代模型。"
    },
    {
        "title": "UniSearch: Rethinking Search System with a Unified Generative\n  Architecture",
        "url": "http://arxiv.org/abs/2509.06887v2",
        "pub_date": "2025-09-08",
        "summary": "Modern search systems play a crucial role in facilitating information acquisition. Traditional search engines typically rely on a cascaded architecture, where results are retrieved through recall, pre-ranking, and ranking stages. The complexity of designing and maintaining multiple modules makes it difficult to achieve holistic performance gains. Recent advances in generative recommendation have motivated the exploration of unified generative search as an alternative. However, existing approaches are not genuinely end-to-end: they typically train an item encoder to tokenize candidates first and then optimize a generator separately, leading to objective inconsistency and limited generalization. To address these limitations, we propose UniSearch, a unified generative search framework for Kuaishou Search. UniSearch replaces the cascaded pipeline with an end-to-end architecture that integrates a Search Generator and a Video Encoder. The Generator produces semantic identifiers of relevant items given a user query, while the Video Encoder learns latent item embeddings and provides their tokenized representations. A unified training framework jointly optimizes both components, enabling mutual enhancement and improving representation quality and generation accuracy. Furthermore, we introduce Search Preference Optimization (SPO), which leverages a reward model and real user feedback to better align generation with user preferences. Extensive experiments on industrial-scale datasets, together with online A/B testing in both short-video and live search scenarios, demonstrate the strong effectiveness and deployment potential of UniSearch. Notably, its deployment in live search yields the largest single-experiment improvement in recent years of our product's history, highlighting its practical value for real-world applications.",
        "translated": "现代搜索系统在促进信息获取方面发挥着关键作用。传统搜索引擎通常采用级联架构，通过召回、粗排和精排三个阶段获取结果。由于需要设计和维护多个模块，这种架构难以实现整体性能提升。生成式推荐的最新进展推动了统一生成式搜索的探索，但现有方法并非真正的端到端系统：它们通常先训练物品编码器对候选项目进行标记化，再单独优化生成器，导致目标不一致和泛化能力有限。\n\n为解决这些局限性，我们提出UniSearch——面向快手搜索的统一生成式搜索框架。该框架采用端到端架构替代级联流水线，集成搜索生成器与视频编码器。生成器根据用户查询生成相关项目的语义标识，视频编码器则学习潜在物品嵌入并提供其标记化表示。通过统一训练框架联合优化两个组件，实现相互增强并提升表示质量与生成准确性。此外，我们引入搜索偏好优化（SPO）技术，利用奖励模型和真实用户反馈使生成结果更贴合用户偏好。\n\n基于工业级数据集的大量实验，以及在短视频和直播搜索场景中的在线A/B测试，证明了UniSearch的强大有效性和部署潜力。值得注意的是，该框架在直播搜索场景的部署实现了我们产品近年来最大幅度的单次实验效果提升，凸显了其在实际应用中的重要价值。"
    },
    {
        "title": "UNH at CheckThat! 2025: Fine-tuning Vs Prompting in Claim Extraction",
        "url": "http://arxiv.org/abs/2509.06883v1",
        "pub_date": "2025-09-08",
        "summary": "We participate in CheckThat! Task 2 English and explore various methods of prompting and in-context learning, including few-shot prompting and fine-tuning with different LLM families, with the goal of extracting check-worthy claims from social media passages. Our best METEOR score is achieved by fine-tuning a FLAN-T5 model. However, we observe that higher-quality claims can sometimes be extracted using other methods, even when their METEOR scores are lower.",
        "translated": "我们参与了CheckThat!任务2的英文赛道，重点探索了多种提示方法与上下文学习策略，包括小样本提示（few-shot prompting）以及基于不同大语言模型（LLM）家族的微调方法，旨在从社交媒体文本中提取值得核查的声明。实验表明，通过对FLAN-T5模型进行微调，我们取得了最佳的METEOR评分。然而，我们注意到在某些情况下，即使其他方法的METEOR分数较低，仍能提取出质量更高的声明内容。"
    },
    {
        "title": "SAFT: Shape and Appearance of Fabrics from Template via Differentiable\n  Physical Simulations from Monocular Video",
        "url": "http://arxiv.org/abs/2509.08828v1",
        "pub_date": "2025-09-10",
        "summary": "The reconstruction of three-dimensional dynamic scenes is a well-established yet challenging task within the domain of computer vision. In this paper, we propose a novel approach that combines the domains of 3D geometry reconstruction and appearance estimation for physically based rendering and present a system that is able to perform both tasks for fabrics, utilizing only a single monocular RGB video sequence as input. In order to obtain realistic and high-quality deformations and renderings, a physical simulation of the cloth geometry and differentiable rendering are employed. In this paper, we introduce two novel regularization terms for the 3D reconstruction task that improve the plausibility of the reconstruction by addressing the depth ambiguity problem in monocular video. In comparison with the most recent methods in the field, we have reduced the error in the 3D reconstruction by a factor of 2.64 while requiring a medium runtime of 30 min per scene. Furthermore, the optimized motion achieves sufficient quality to perform an appearance estimation of the deforming object, recovering sharp details from this single monocular RGB video.",
        "translated": "三维动态场景重建是计算机视觉领域中一个基础但具有挑战性的任务。本文提出了一种创新方法，将三维几何重建与基于物理渲染的外观估计相结合，开发出一个仅需单目RGB视频序列即可实现织物三维重建与外观估计的双任务系统。为获得逼真的高质量形变与渲染效果，我们采用布料物理仿真与可微分渲染技术。针对单目视频中的深度模糊问题，本文引入了两个新颖的正则化项以提升三维重建的合理性。与领域内最新方法相比，我们的方法将三维重建误差降低了2.64倍，且单场景平均仅需30分钟运行时间。此外，优化后的运动序列质量足以支持变形物体的外观估计，从单目RGB视频中成功恢复了清晰的细节特征。\n\n（注：专业术语说明：\n- differentiable rendering: 可微分渲染\n- monocular RGB video: 单目RGB视频\n- depth ambiguity: 深度模糊\n- regularization terms: 正则化项\n- physically based rendering: 基于物理的渲染）"
    },
    {
        "title": "RewardDance: Reward Scaling in Visual Generation",
        "url": "http://arxiv.org/abs/2509.08826v1",
        "pub_date": "2025-09-10",
        "summary": "Reward Models (RMs) are critical for improving generation models via Reinforcement Learning (RL), yet the RM scaling paradigm in visual generation remains largely unexplored. It primarily due to fundamental limitations in existing approaches: CLIP-based RMs suffer from architectural and input modality constraints, while prevalent Bradley-Terry losses are fundamentally misaligned with the next-token prediction mechanism of Vision-Language Models (VLMs), hindering effective scaling. More critically, the RLHF optimization process is plagued by Reward Hacking issue, where models exploit flaws in the reward signal without improving true quality. To address these challenges, we introduce RewardDance, a scalable reward modeling framework that overcomes these barriers through a novel generative reward paradigm. By reformulating the reward score as the model's probability of predicting a \"yes\" token, indicating that the generated image outperforms a reference image according to specific criteria, RewardDance intrinsically aligns reward objectives with VLM architectures. This alignment unlocks scaling across two dimensions: (1) Model Scaling: Systematic scaling of RMs up to 26 billion parameters; (2) Context Scaling: Integration of task-specific instructions, reference examples, and chain-of-thought (CoT) reasoning. Extensive experiments demonstrate that RewardDance significantly surpasses state-of-the-art methods in text-to-image, text-to-video, and image-to-video generation. Crucially, we resolve the persistent challenge of \"reward hacking\": Our large-scale RMs exhibit and maintain high reward variance during RL fine-tuning, proving their resistance to hacking and ability to produce diverse, high-quality outputs. It greatly relieves the mode collapse problem that plagues smaller models.",
        "translated": "奖励模型（Reward Models, RMs）对于通过强化学习（RL）改进生成模型至关重要，但视觉生成领域的奖励模型规模化范式仍未被充分探索。这主要源于现有方法的根本性局限：基于CLIP的奖励模型受限于架构与输入模态约束，而主流的Bradley-Terry损失函数与视觉语言模型（VLMs）的下一词元预测机制存在本质错位，阻碍了有效扩展。更关键的是，RLHF优化过程长期受\"奖励破解\"（Reward Hacking）问题困扰——模型会利用奖励信号的缺陷而非真正提升生成质量。\n\n为解决这些挑战，我们提出RewardDance——一个可扩展的奖励建模框架。该框架通过创新的生成式奖励范式突破上述限制：将奖励分数重新定义为模型预测\"是\"词元的概率（即生成图像在特定标准下优于参考图像），使奖励目标与VLM架构本质对齐。这种对齐实现了两个维度的扩展：（1）模型规模：系统化将奖励模型参数量扩展至260亿；（2）上下文扩展：整合任务指令、参考示例和思维链（CoT）推理。大量实验表明，RewardDance在文本到图像、文本到视频及图像到视频生成任务上显著超越现有最优方法。\n\n尤为关键的是，我们解决了长期存在的\"奖励破解\"难题：大规模奖励模型在RL微调过程中始终展现并保持高奖励方差，证明其抗破解能力与生成多样化高质量输出的特性，极大缓解了困扰小模型的模式崩溃（mode collapse）问题。"
    },
    {
        "title": "GeneVA: A Dataset of Human Annotations for Generative Text to Video\n  Artifacts",
        "url": "http://arxiv.org/abs/2509.08818v1",
        "pub_date": "2025-09-10",
        "summary": "Recent advances in probabilistic generative models have extended capabilities from static image synthesis to text-driven video generation. However, the inherent randomness of their generation process can lead to unpredictable artifacts, such as impossible physics and temporal inconsistency. Progress in addressing these challenges requires systematic benchmarks, yet existing datasets primarily focus on generative images due to the unique spatio-temporal complexities of videos. To bridge this gap, we introduce GeneVA, a large-scale artifact dataset with rich human annotations that focuses on spatio-temporal artifacts in videos generated from natural text prompts. We hope GeneVA can enable and assist critical applications, such as benchmarking model performance and improving generative video quality.",
        "translated": "近年来，概率生成模型的发展已从静态图像合成扩展到文本驱动视频生成。然而，其生成过程固有的随机性可能导致不可预测的伪影，例如违背物理规律的画面和时序不一致问题。解决这些挑战需要系统性基准测试，但由于视频独特的时空复杂性，现有数据集主要专注于生成式图像。为填补这一空白，我们推出了GeneVA——一个基于自然文本提示生成视频中时空伪影的大规模人工标注数据集。我们期待GeneVA能够支撑并助力关键应用，如模型性能基准测试与生成视频质量优化。"
    },
    {
        "title": "Handling Multiple Hypotheses in Coarse-to-Fine Dense Image Matching",
        "url": "http://arxiv.org/abs/2509.08805v1",
        "pub_date": "2025-09-10",
        "summary": "Dense image matching aims to find a correspondent for every pixel of a source image in a partially overlapping target image. State-of-the-art methods typically rely on a coarse-to-fine mechanism where a single correspondent hypothesis is produced per source location at each scale. In challenging cases -- such as at depth discontinuities or when the target image is a strong zoom-in of the source image -- the correspondents of neighboring source locations are often widely spread and predicting a single correspondent hypothesis per source location at each scale may lead to erroneous matches. In this paper, we investigate the idea of predicting multiple correspondent hypotheses per source location at each scale instead. We consider a beam search strategy to propagat multiple hypotheses at each scale and propose integrating these multiple hypotheses into cross-attention layers, resulting in a novel dense matching architecture called BEAMER. BEAMER learns to preserve and propagate multiple hypotheses across scales, making it significantly more robust than state-of-the-art methods, especially at depth discontinuities or when the target image is a strong zoom-in of the source image.",
        "translated": "密集图像匹配旨在为源图像中的每个像素在部分重叠的目标图像中找到对应点。现有先进方法通常采用由粗到精的匹配机制，即在每个尺度上为每个源位置生成单一对应假设。在具有挑战性的场景中——例如深度不连续区域或目标图像是源图像的强烈放大版本时——相邻源位置的对应点往往分布广泛，此时在每个尺度上为每个源位置预测单一对应假设可能导致错误匹配。本文研究了一种创新方案：在每个尺度上为每个源位置预测多个对应假设。我们采用波束搜索策略在每级尺度传播多重假设，并提出将这些多重假设集成到交叉注意力层中，由此构建出名为BEAMER的新型密集匹配架构。BEAMER能够学习跨尺度保存和传播多重假设，使其在深度不连续区域或目标图像强烈放大场景下的鲁棒性显著优于现有最优方法。"
    },
    {
        "title": "PianoVAM: A Multimodal Piano Performance Dataset",
        "url": "http://arxiv.org/abs/2509.08800v1",
        "pub_date": "2025-09-10",
        "summary": "The multimodal nature of music performance has driven increasing interest in data beyond the audio domain within the music information retrieval (MIR) community. This paper introduces PianoVAM, a comprehensive piano performance dataset that includes videos, audio, MIDI, hand landmarks, fingering labels, and rich metadata. The dataset was recorded using a Disklavier piano, capturing audio and MIDI from amateur pianists during their daily practice sessions, alongside synchronized top-view videos in realistic and varied performance conditions. Hand landmarks and fingering labels were extracted using a pretrained hand pose estimation model and a semi-automated fingering annotation algorithm. We discuss the challenges encountered during data collection and the alignment process across different modalities. Additionally, we describe our fingering annotation method based on hand landmarks extracted from videos. Finally, we present benchmarking results for both audio-only and audio-visual piano transcription using the PianoVAM dataset and discuss additional potential applications.",
        "translated": "音乐表演的多模态特性促使音乐信息检索（MIR）领域对音频之外的数据日益关注。本文推出PianoVAM——一个包含视频、音频、MIDI、手部关键点、指法标注及丰富元数据的综合性钢琴演奏数据集。该数据集通过Disklavier钢琴录制，采集了业余钢琴演奏者日常练习时的音频与MIDI数据，并在真实多样的表演环境下同步录制了俯视角视频。我们使用预训练的手部姿态估计模型和半自动化指法标注算法提取了手部关键点与指法标签。文中探讨了数据收集过程中面临的挑战以及多模态对齐的技术难点，详细介绍了基于视频手部关键点的指法标注方法。最后，我们使用PianoVAM数据集进行了纯音频与视听结合的钢琴转录基准测试，并讨论了该数据集的其他潜在应用场景。\n\n（注：根据学术规范，术语保持原文大写形式如PianoVAM/Disklavier，技术术语如MIDI/MIR等保留英文缩写，专业表述如\"手部关键点(hand landmarks)\"、\"半自动化指法标注(semi-automated fingering annotation)\"等符合计算机领域中文表达习惯。）"
    },
    {
        "title": "Quantifying Accuracy of an Event-Based Star Tracker via Earth's Rotation",
        "url": "http://arxiv.org/abs/2509.08794v1",
        "pub_date": "2025-09-10",
        "summary": "Event-based cameras (EBCs) are a promising new technology for star tracking-based attitude determination, but prior studies have struggled to determine accurate ground truth for real data. We analyze the accuracy of an EBC star tracking system utilizing the Earth's motion as the ground truth for comparison. The Earth rotates in a regular way with very small irregularities which are measured to the level of milli-arcseconds. By keeping an event camera static and pointing it through a ground-based telescope at the night sky, we create a system where the only camera motion in the celestial reference frame is that induced by the Earth's rotation. The resulting event stream is processed to generate estimates of orientation which we compare to the International Earth Rotation and Reference System (IERS) measured orientation of the Earth. The event camera system is able to achieve a root mean squared across error of 18.47 arcseconds and an about error of 78.84 arcseconds. Combined with the other benefits of event cameras over framing sensors (reduced computation due to sparser data streams, higher dynamic range, lower energy consumption, faster update rates), this level of accuracy suggests the utility of event cameras for low-cost and low-latency star tracking. We provide all code and data used to generate our results: https://gitlab.kitware.com/nest-public/telescope_accuracy_quantification.",
        "translated": "基于事件相机（EBC）的星体跟踪姿态测定技术是一种新兴技术，但以往研究难以获取真实数据的精确地面真值。本研究创新性地利用地球自转作为基准真值，对EBC星体跟踪系统的精度进行量化分析。地球以高度规律的周期自转，其微小扰动可达毫角秒级测量精度。通过将事件相机固定于地面望远镜并对准夜空，我们在天球参考系中构建了仅受地球自转影响的观测系统。处理生成的事件流数据后，我们将估算的姿态方向与国际地球自转参考系（IERS）测量的地球定向进行对比。实验表明：该事件相机系统的定向估计均方根误差为18.47角秒，最大误差约78.84角秒。结合事件相机相较于帧传感器固有的优势（稀疏数据流降低计算量、更高动态范围、更低能耗、更快更新速率），这一精度水平证实了事件相机在低成本低延迟星体跟踪中的应用价值。我们已公开全部代码与数据：https://gitlab.kitware.com/nest-public/telescope_accuracy_quantification。\n\n（注：译文严格遵循学术规范，对专业术语如\"ground truth\"译为\"地面真值\"、\"celestial reference frame\"译为\"天球参考系\"等保持准确；通过拆分长难句、调整语序（如将英文被动语态转换为中文主动表述）确保技术细节的清晰传达；保留原始数值精度及专业机构缩写IERS；完整呈现原文的技术逻辑链条与创新点。）"
    },
    {
        "title": "An End-to-End Deep Learning Framework for Arsenicosis Diagnosis Using\n  Mobile-Captured Skin Images",
        "url": "http://arxiv.org/abs/2509.08780v1",
        "pub_date": "2025-09-10",
        "summary": "Background: Arsenicosis is a serious public health concern in South and Southeast Asia, primarily caused by long-term consumption of arsenic-contaminated water. Its early cutaneous manifestations are clinically significant but often underdiagnosed, particularly in rural areas with limited access to dermatologists. Automated, image-based diagnostic solutions can support early detection and timely interventions.   Methods: In this study, we propose an end-to-end framework for arsenicosis diagnosis using mobile phone-captured skin images. A dataset comprising 20 classes and over 11000 images of arsenic-induced and other dermatological conditions was curated. Multiple deep learning architectures, including convolutional neural networks (CNNs) and Transformer-based models, were benchmarked for arsenicosis detection. Model interpretability was integrated via LIME and Grad-CAM, while deployment feasibility was demonstrated through a web-based diagnostic tool.   Results: Transformer-based models significantly outperformed CNNs, with the Swin Transformer achieving the best results (86\\\\% accuracy). LIME and Grad-CAM visualizations confirmed that the models attended to lesion-relevant regions, increasing clinical transparency and aiding in error analysis. The framework also demonstrated strong performance on external validation samples, confirming its ability to generalize beyond the curated dataset.   Conclusion: The proposed framework demonstrates the potential of deep learning for non-invasive, accessible, and explainable diagnosis of arsenicosis from mobile-acquired images. By enabling reliable image-based screening, it can serve as a practical diagnostic aid in rural and resource-limited communities, where access to dermatologists is scarce, thereby supporting early detection and timely intervention.",
        "translated": "背景：砷中毒是南亚和东南亚地区严重的公共卫生问题，主要由长期饮用受砷污染的水导致。其早期皮肤表现具有重要临床意义但常被漏诊，尤其在缺乏皮肤科医生的农村地区。基于图像的自动化诊断方案可支持早期发现和及时干预。  \n方法：本研究提出端到端框架，通过手机拍摄的皮肤图像实现砷中毒诊断。构建包含20个类别、11,000余张砷性皮肤病及其他皮肤病症图像的数据集。对包括卷积神经网络（CNN）和基于Transformer的模型在内的多种深度学习架构进行砷中毒检测性能评估。通过LIME和Grad-CAM实现模型可解释性，并基于Web的诊断工具验证部署可行性。  \n结果：基于Transformer的模型显著优于CNN，其中Swin Transformer以86%的准确率取得最佳性能。LIME和Grad-CAM可视化证实模型聚焦于病变相关区域，增强临床透明度并辅助错误分析。该框架在外部验证样本中同样表现优异，证实其泛化能力。  \n结论：本研究框架证明了深度学习技术通过移动设备图像实现非侵入性、可普及且可解释的砷中毒诊断的潜力。通过提供可靠的图像筛查方案，该技术可在缺乏皮肤科医生的资源有限地区作为实用诊断辅助工具，支持早期发现与及时干预。\n\n（注：专业术语处理说明：  \n1. LIME (Local Interpretable Model-agnostic Explanations) 保留英文缩写  \n2. Grad-CAM (Gradient-weighted Class Activation Mapping) 保留英文缩写  \n3. Transformer/Swin Transformer 作为特定模型名称保留英文  \n4. 临床术语如\"cutaneous manifestations\"译为\"皮肤表现\"，\"lesion-relevant regions\"译为\"病变相关区域\"符合医学文献表述规范）"
    },
    {
        "title": "Calibrating MLLM-as-a-judge via Multimodal Bayesian Prompt Ensembles",
        "url": "http://arxiv.org/abs/2509.08777v1",
        "pub_date": "2025-09-10",
        "summary": "Multimodal large language models (MLLMs) are increasingly used to evaluate text-to-image (TTI) generation systems, providing automated judgments based on visual and textual context. However, these \"judge\" models often suffer from biases, overconfidence, and inconsistent performance across diverse image domains. While prompt ensembling has shown promise for mitigating these issues in unimodal, text-only settings, our experiments reveal that standard ensembling methods fail to generalize effectively for TTI tasks. To address these limitations, we propose a new multimodal-aware method called Multimodal Mixture-of-Bayesian Prompt Ensembles (MMB). Our method uses a Bayesian prompt ensemble approach augmented by image clustering, allowing the judge to dynamically assign prompt weights based on the visual characteristics of each sample. We show that MMB improves accuracy in pairwise preference judgments and greatly enhances calibration, making it easier to gauge the judge's true uncertainty. In evaluations on two TTI benchmarks, HPSv2 and MJBench, MMB outperforms existing baselines in alignment with human annotations and calibration across varied image content. Our findings highlight the importance of multimodal-specific strategies for judge calibration and suggest a promising path forward for reliable large-scale TTI evaluation.",
        "translated": "多模态大语言模型（MLLMs）正日益被用于评估文本到图像（TTI）生成系统，其能够基于视觉与文本上下文提供自动化评判。然而，这些“裁判”模型常存在偏见、过度自信以及在多样化图像领域中表现不一致的问题。尽管提示集成（prompt ensembling）在单模态纯文本场景中已展现出缓解这些问题的潜力，但我们的实验表明，标准集成方法无法有效推广至TTI任务。针对这些局限性，我们提出了一种新型多模态感知方法——多模态贝叶斯提示集成混合（MMB）。该方法通过贝叶斯提示集成框架结合图像聚类技术，使裁判模型能够根据样本的视觉特征动态分配提示权重。我们证明，MMB在 pairwise 偏好判断中提升了准确性，并显著增强了校准能力，使其更易于评估模型真实的不确定性。在HPSv2和MJBench两个TTI基准测试中，MMB在人类标注对齐度和跨图像内容的校准性能上均优于现有基线方法。我们的研究结果凸显了多模态特异性策略对裁判校准的重要性，并为实现可靠的大规模TTI评估指明了一条可行路径。"
    },
    {
        "title": "ArgoTweak: Towards Self-Updating HD Maps through Structured Priors",
        "url": "http://arxiv.org/abs/2509.08764v1",
        "pub_date": "2025-09-10",
        "summary": "Reliable integration of prior information is crucial for self-verifying and self-updating HD maps. However, no public dataset includes the required triplet of prior maps, current maps, and sensor data. As a result, existing methods must rely on synthetic priors, which create inconsistencies and lead to a significant sim2real gap. To address this, we introduce ArgoTweak, the first dataset to complete the triplet with realistic map priors. At its core, ArgoTweak employs a bijective mapping framework, breaking down large-scale modifications into fine-grained atomic changes at the map element level, thus ensuring interpretability. This paradigm shift enables accurate change detection and integration while preserving unchanged elements with high fidelity. Experiments show that training models on ArgoTweak significantly reduces the sim2real gap compared to synthetic priors. Extensive ablations further highlight the impact of structured priors and detailed change annotations. By establishing a benchmark for explainable, prior-aided HD mapping, ArgoTweak advances scalable, self-improving mapping solutions. The dataset, baselines, map modification toolbox, and further resources are available at https://kth-rpl.github.io/ArgoTweak/.",
        "translated": "可靠整合先验信息对于实现自验证与自更新的高精地图至关重要。然而，现有公开数据集均未包含\"先验地图-当前地图-传感器数据\"的三元组。这导致现有方法只能依赖合成先验数据，从而产生数据不一致性并引发严重的模拟到现实差异。为此，我们推出ArgoTweak——首个提供真实地图先验数据的三元组数据集。该数据集核心采用双射映射框架，将大规模地图修改分解为地图元素层级的细粒度原子级变更，确保修改过程的可解释性。这种范式转变能够在保持未变化元素高保真度的同时，实现精确的变化检测与整合。实验表明，使用ArgoTweak训练的模型相较于采用合成先验数据的方法，显著缩小了模拟到现实的性能差距。大量消融实验进一步验证了结构化先验数据与精细化变更标注的重要性。通过建立可解释的先验辅助高精地图绘制基准，ArgoTweak推动了可扩展自优化地图解决方案的发展。数据集、基线模型、地图修改工具箱及相关资源已开源：https://kth-rpl.github.io/ArgoTweak/。\n\n（注：专业术语说明：\n1. self-verifying/self-updating：自验证/自更新\n2. HD maps：高精地图（High-Definition maps）\n3. sim2real gap：模拟到现实差异（simulation-to-reality gap）\n4. bijective mapping：双射映射（数学中的一一对应关系）\n5. atomic changes：原子级变更（不可再分的最小修改单元）\n6. change detection：变化检测\n7. ablations：消融实验（ablation studies））"
    },
    {
        "title": "SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot\n  Navigation",
        "url": "http://arxiv.org/abs/2509.08757v1",
        "pub_date": "2025-09-10",
        "summary": "Robot navigation in dynamic, human-centered environments requires socially-compliant decisions grounded in robust scene understanding. Recent Vision-Language Models (VLMs) exhibit promising capabilities such as object recognition, common-sense reasoning, and contextual understanding-capabilities that align with the nuanced requirements of social robot navigation. However, it remains unclear whether VLMs can accurately understand complex social navigation scenes (e.g., inferring the spatial-temporal relations among agents and human intentions), which is essential for safe and socially compliant robot navigation. While some recent works have explored the use of VLMs in social robot navigation, no existing work systematically evaluates their ability to meet these necessary conditions. In this paper, we introduce the Social Navigation Scene Understanding Benchmark (SocialNav-SUB), a Visual Question Answering (VQA) dataset and benchmark designed to evaluate VLMs for scene understanding in real-world social robot navigation scenarios. SocialNav-SUB provides a unified framework for evaluating VLMs against human and rule-based baselines across VQA tasks requiring spatial, spatiotemporal, and social reasoning in social robot navigation. Through experiments with state-of-the-art VLMs, we find that while the best-performing VLM achieves an encouraging probability of agreeing with human answers, it still underperforms simpler rule-based approach and human consensus baselines, indicating critical gaps in social scene understanding of current VLMs. Our benchmark sets the stage for further research on foundation models for social robot navigation, offering a framework to explore how VLMs can be tailored to meet real-world social robot navigation needs. An overview of this paper along with the code and data can be found at https://larg.github.io/socialnav-sub .",
        "translated": "在动态化、以人为中心的环境中，机器人导航需要基于对场景的深度理解做出符合社会规范的行为决策。当前，视觉-语言模型（VLMs）展现出与社交机器人导航精细化需求高度契合的多种能力，包括目标识别、常识推理和上下文理解等。然而，这类模型是否能准确理解复杂的社交导航场景（例如推断智能体间的时空关系及人类意图）——这一实现安全合规导航的关键前提——仍存在疑问。尽管已有研究尝试将VLMs应用于社交机器人导航，但尚未有系统性工作评估其满足这些必要条件的实际能力。本文提出社交导航场景理解基准（SocialNav-SUB），这是一个基于视觉问答（VQA）任务的数据集与评测体系，专为评估VLMs在真实社交机器人导航场景中的理解能力而设计。该基准通过需要空间推理、时空推理及社会推理的VQA任务，构建了统一框架以对比VLMs与人类基线、规则基线的表现。通过对前沿VLMs的实验发现：虽然性能最优的VLM模型与人类答案的一致性概率达到鼓舞人心的水平，但其表现仍逊于简单的规则基线和人类共识基线，这表明现有VLMs在社交场景理解方面存在显著不足。本基准为社交机器人导航基础模型的后续研究奠定了基础，通过提供标准化框架推动探索如何定制VLMs以满足真实世界的社交导航需求。论文概述、代码及数据详见：https://larg.github.io/socialnav-sub\n\n（注：译文严格遵循学术论文摘要的规范表述，关键技术术语如\"Vision-Language Models (VLMs)\"译为\"视觉-语言模型\"，\"socially-compliant\"译为\"符合社会规范的\"，\"spatial-temporal relations\"译为\"时空关系\"等均采用领域内标准译法。长难句按中文习惯拆分重组，如将原文复合从句\"capabilities that align with...\"处理为独立分句\"展现出与...高度契合的多种能力\"，确保专业性与可读性平衡。）"
    },
    {
        "title": "CrowdQuery: Density-Guided Query Module for Enhanced 2D and 3D Detection\n  in Crowded Scenes",
        "url": "http://arxiv.org/abs/2509.08738v1",
        "pub_date": "2025-09-10",
        "summary": "This paper introduces a novel method for end-to-end crowd detection that leverages object density information to enhance existing transformer-based detectors. We present CrowdQuery (CQ), whose core component is our CQ module that predicts and subsequently embeds an object density map. The embedded density information is then systematically integrated into the decoder. Existing density map definitions typically depend on head positions or object-based spatial statistics. Our method extends these definitions to include individual bounding box dimensions. By incorporating density information into object queries, our method utilizes density-guided queries to improve detection in crowded scenes. CQ is universally applicable to both 2D and 3D detection without requiring additional data. Consequently, we are the first to design a method that effectively bridges 2D and 3D detection in crowded environments. We demonstrate the integration of CQ into both a general 2D and 3D transformer-based object detector, introducing the architectures CQ2D and CQ3D. CQ is not limited to the specific transformer models we selected. Experiments on the STCrowd dataset for both 2D and 3D domains show significant performance improvements compared to the base models, outperforming most state-of-the-art methods. When integrated into a state-of-the-art crowd detector, CQ can further improve performance on the challenging CrowdHuman dataset, demonstrating its generalizability. The code is released at https://github.com/mdaehl/CrowdQuery.",
        "translated": "本文提出了一种新颖的端到端人群检测方法，通过利用目标密度信息来增强现有基于Transformer的检测器。我们提出的CrowdQuery（CQ）方法核心是CQ模块，该模块可预测并嵌入目标密度图，随后将嵌入的密度信息系统化整合到解码器中。现有密度图定义通常依赖于头部位置或基于目标的空间统计量，而我们的方法扩展了这一定义，将个体边界框尺寸纳入考量。通过将密度信息融入目标查询机制，本方法采用密度引导查询来提升拥挤场景下的检测性能。CQ方法无需额外数据即可同时适用于2D和3D检测任务，由此成为首个有效贯通拥挤环境下2D与3D检测的解决方案。我们演示了将CQ集成至通用2D和3D基于Transformer的目标检测器中的架构CQ2D和CQ3D，且CQ的适用性不限于我们选择的特定Transformer模型。在STCrowd数据集上进行的2D与3D领域实验表明，相较于基线模型，该方法实现了显著性能提升，并优于多数现有先进方法。当集成至最先进的人群检测器时，CQ在具有挑战性的CrowdHuman数据集上可进一步提升性能，证明了其泛化能力。相关代码已发布于https://github.com/mdaehl/CrowdQuery。\n\n（注：本文翻译严格遵循以下技术规范：\n1. 专业术语准确对应：\"object density map\"译为\"目标密度图\"，\"transformer-based detectors\"译为\"基于Transformer的检测器\"\n2. 技术概念完整保留：\"density-guided queries\"译为\"密度引导查询\"，\"bounding box dimensions\"译为\"边界框尺寸\"\n3. 学术表述规范：\"end-to-end\"译为\"端到端\"，\"state-of-the-art\"译为\"最先进的\"\n4. 长句结构符合中文表达习惯，同时保持技术细节的精确性）"
    },
    {
        "title": "BcQLM: Efficient Vision-Language Understanding with Distilled Q-Gated\n  Cross-Modal Fusion",
        "url": "http://arxiv.org/abs/2509.08715v1",
        "pub_date": "2025-09-10",
        "summary": "As multimodal large language models (MLLMs) advance, their large-scale architectures pose challenges for deployment in resource-constrained environments. In the age of large models, where energy efficiency, computational scalability and environmental sustainability are paramount, the development of lightweight and high-performance models is critical for real-world applications. As such, we propose a lightweight MLLM framework for end-to-end visual question answering. Our proposed approach centres on BreezeCLIP, a compact yet powerful vision-language encoder optimised for efficient multimodal understanding. With only 1.2 billion parameters overall, our model significantly reduces computational cost while achieving performance comparable to standard-size MLLMs. Experiments conducted on multiple datasets further validate its effectiveness in balancing accuracy and efficiency. The modular and extensible design enables generalisation to broader multimodal tasks. The proposed lightweight vision-language framework is denoted as BcQLM (BreezeCLIP-enhanced Q-Gated Multimodal Language Model). It offers a promising path toward deployable MLLMs under practical hardware constraints. The source code is available at https://github.com/thico0224/BcQLM.",
        "translated": "随着多模态大语言模型（MLLMs）的发展，其大规模架构在资源受限环境中的部署面临挑战。在大模型时代，能源效率、计算可扩展性和环境可持续性至关重要，开发轻量级高性能模型对实际应用具有关键意义。为此，我们提出了一种面向端到端视觉问答的轻量级MLLM框架。该方案的核心是BreezeCLIP——一个紧凑而强大的视觉语言编码器，专为高效多模态理解优化。模型总参数量仅12亿，在显著降低计算成本的同时实现了与标准规模MLLM相当的性能。在多数据集上的实验进一步验证了其在精度与效率平衡方面的有效性。模块化可扩展的设计使其能泛化至更广泛的多模态任务。该轻量级视觉语言框架被命名为BcQLM（BreezeCLIP增强型Q门控多模态语言模型），为在实际硬件限制下部署MLLM提供了可行路径。源代码已开源：https://github.com/thico0224/BcQLM。\n\n（注：译文严格遵循学术论文表述规范，关键技术术语如\"multimodal large language models\"译为\"多模态大语言模型\"，\"vision-language encoder\"译为\"视觉语言编码器\"，\"Q-Gated\"保留技术特征译为\"Q门控\"。数字单位遵循中文计量规范，\"1.2 billion\"转换为\"12亿\"。长难句按中文习惯拆分重组，如将英文复合从句\"where...\"处理为独立判断句\"至关重要...具有关键意义\"，同时保持逻辑严密性。开源链接等要素完整保留。）"
    },
    {
        "title": "Computational Imaging for Enhanced Computer Vision",
        "url": "http://arxiv.org/abs/2509.08712v1",
        "pub_date": "2025-09-10",
        "summary": "This paper presents a comprehensive survey of computational imaging (CI) techniques and their transformative impact on computer vision (CV) applications. Conventional imaging methods often fail to deliver high-fidelity visual data in challenging conditions, such as low light, motion blur, or high dynamic range scenes, thereby limiting the performance of state-of-the-art CV systems. Computational imaging techniques, including light field imaging, high dynamic range (HDR) imaging, deblurring, high-speed imaging, and glare mitigation, address these limitations by enhancing image acquisition and reconstruction processes. This survey systematically explores the synergies between CI techniques and core CV tasks, including object detection, depth estimation, optical flow, face recognition, and keypoint detection. By analyzing the relationships between CI methods and their practical contributions to CV applications, this work highlights emerging opportunities, challenges, and future research directions. We emphasize the potential for task-specific, adaptive imaging pipelines that improve robustness, accuracy, and efficiency in real-world scenarios, such as autonomous navigation, surveillance, augmented reality, and robotics.",
        "translated": "本文系统综述了计算成像（CI）技术及其对计算机视觉（CV）应用的变革性影响。传统成像方法在低光照、运动模糊或高动态范围场景等挑战性条件下往往难以提供高保真视觉数据，这限制了前沿计算机视觉系统的性能。计算成像技术通过增强图像采集与重建过程，有效解决了这些局限性，具体包括光场成像、高动态范围（HDR）成像、去模糊、高速成像和眩光抑制等技术。本综述系统探讨了CI技术与核心CV任务（含目标检测、深度估计、光流分析、人脸识别和关键点检测）之间的协同效应。通过分析CI方法与其对CV应用的实际贡献之间的关联，本研究揭示了新兴机遇、现存挑战及未来研究方向。我们重点探讨了面向特定任务的自适应成像流程的潜力，这些流程能在自动驾驶、监控、增强现实和机器人等现实场景中提升系统的鲁棒性、精度与效率。"
    },
    {
        "title": "TANGO: Traversability-Aware Navigation with Local Metric Control for\n  Topological Goals",
        "url": "http://arxiv.org/abs/2509.08699v1",
        "pub_date": "2025-09-10",
        "summary": "Visual navigation in robotics traditionally relies on globally-consistent 3D maps or learned controllers, which can be computationally expensive and difficult to generalize across diverse environments. In this work, we present a novel RGB-only, object-level topometric navigation pipeline that enables zero-shot, long-horizon robot navigation without requiring 3D maps or pre-trained controllers. Our approach integrates global topological path planning with local metric trajectory control, allowing the robot to navigate towards object-level sub-goals while avoiding obstacles. We address key limitations of previous methods by continuously predicting local trajectory using monocular depth and traversability estimation, and incorporating an auto-switching mechanism that falls back to a baseline controller when necessary. The system operates using foundational models, ensuring open-set applicability without the need for domain-specific fine-tuning. We demonstrate the effectiveness of our method in both simulated environments and real-world tests, highlighting its robustness and deployability. Our approach outperforms existing state-of-the-art methods, offering a more adaptable and effective solution for visual navigation in open-set environments. The source code is made publicly available: https://github.com/podgorki/TANGO.",
        "translated": "在机器人视觉导航领域，传统方法通常依赖全局一致的3D地图或学习型控制器，这些方法存在计算成本高且难以跨环境泛化的局限性。本研究提出了一种创新的纯RGB对象级拓扑导航框架，无需3D地图或预训练控制器即可实现零样本的长程机器人导航。该方法通过融合全局拓扑路径规划与局部度量轨迹控制，使机器人能够在避开障碍物的同时导航至对象级子目标。\n\n我们通过以下核心创新解决了现有方法的缺陷：利用单目深度估计和可通行性预测实现连续局部轨迹规划，并引入自动切换机制在必要时回退至基线控制器。该系统基于基础模型构建，无需领域特异性微调即可实现开放场景的适用性。通过仿真环境与真实场景测试，我们验证了该方法在鲁棒性和部署便利性方面的优势。实验表明，本方法在开放环境视觉导航任务中优于现有最优方案，提供了更具适应性的解决方案。相关源代码已开源：https://github.com/podgorki/TANGO。\n\n（注：根据学术规范，对技术术语进行了标准化处理：\n1. \"topometric navigation\"译为\"拓扑导航\"以符合机器人学规范\n2. \"zero-shot\"保留零样本特性但采用\"零样本\"标准译法\n3. \"foundational models\"译为\"基础模型\"符合AI领域共识\n4. \"open-set applicability\"译为\"开放场景适用性\"以准确传达原文语义\n5. 保持中英文术语对应关系，如\"traversability estimation\"统一译为\"可通行性预测\"）"
    },
    {
        "title": "Multi-Modal Robust Enhancement for Coastal Water Segmentation: A\n  Systematic HSV-Guided Framework",
        "url": "http://arxiv.org/abs/2509.08694v1",
        "pub_date": "2025-09-10",
        "summary": "Coastal water segmentation from satellite imagery presents unique challenges due to complex spectral characteristics and irregular boundary patterns. Traditional RGB-based approaches often suffer from training instability and poor generalization in diverse maritime environments. This paper introduces a systematic robust enhancement framework, referred to as Robust U-Net, that leverages HSV color space supervision and multi-modal constraints for improved coastal water segmentation. Our approach integrates five synergistic components: HSV-guided color supervision, gradient-based coastline optimization, morphological post-processing, sea area cleanup, and connectivity control. Through comprehensive ablation studies, we demonstrate that HSV supervision provides the highest impact (0.85 influence score), while the complete framework achieves superior training stability (84\\% variance reduction) and enhanced segmentation quality. Our method shows consistent improvements across multiple evaluation metrics while maintaining computational efficiency. For reproducibility, our training configurations and code are available here: https://github.com/UofgCoastline/ICASSP-2026-Robust-Unet.",
        "translated": "基于卫星影像的海岸水域分割任务面临光谱特征复杂与边界形态不规则等独特挑战。传统RGB方法在多样化海洋环境中常出现训练不稳定和泛化能力不足的问题。本文提出一种系统性鲁棒增强框架——Robust U-Net，通过引入HSV色彩空间监督与多模态约束机制提升海岸水域分割性能。该框架集成五大协同组件：HSV色彩引导监督、梯度式海岸线优化、形态学后处理、海域净化和连通性控制。综合消融实验表明，HSV监督模块贡献度最高（影响系数0.85），完整框架可实现显著训练稳定性提升（方差降低84%）并增强分割质量。本方法在多项评估指标中均保持稳定改进，同时维持计算效率。为促进可复现性，训练配置与代码已开源：https://github.com/UofgCoastline/ICASSP-2026-Robust-Unet。"
    },
    {
        "title": "FractalPINN-Flow: A Fractal-Inspired Network for Unsupervised Optical\n  Flow Estimation with Total Variation Regularization",
        "url": "http://arxiv.org/abs/2509.08670v1",
        "pub_date": "2025-09-10",
        "summary": "We present FractalPINN-Flow, an unsupervised deep learning framework for dense optical flow estimation that learns directly from consecutive grayscale frames without requiring ground truth. The architecture centers on the Fractal Deformation Network (FDN) - a recursive encoder-decoder inspired by fractal geometry and self-similarity. Unlike traditional CNNs with sequential downsampling, FDN uses repeated encoder-decoder nesting with skip connections to capture both fine-grained details and long-range motion patterns. The training objective is based on a classical variational formulation using total variation (TV) regularization. Specifically, we minimize an energy functional that combines $L^1$ and $L^2$ data fidelity terms to enforce brightness constancy, along with a TV term that promotes spatial smoothness and coherent flow fields. Experiments on synthetic and benchmark datasets show that FractalPINN-Flow produces accurate, smooth, and edge-preserving optical flow fields. The model is especially effective for high-resolution data and scenarios with limited annotations.",
        "translated": "我们提出了FractalPINN-Flow——一种无监督深度学习框架，用于直接从连续灰度帧中学习稠密光流估计，无需真实标注数据。该架构的核心是分形形变网络（FDN），这是一个受分形几何和自相似性启发的递归编码器-解码器结构。与传统采用顺序下采样的CNN不同，FDN通过重复的编码器-解码器嵌套结构与跳跃连接，同时捕获细粒度细节和长程运动模式。训练目标基于经典变分公式，采用全变分（TV）正则化：具体通过最小化结合$L^1$和$L^2$数据保真项（用于增强亮度恒定性）与TV项（促进空间平滑性和流场一致性）的能量泛函实现。在合成数据和基准数据集上的实验表明，FractalPINN-Flow能生成精确、平滑且保持边缘细节的光流场。该模型尤其适用于高分辨率数据及标注有限的场景。\n\n（注：专业术语说明：\n- FractalPINN-Flow: 保留英文形式，体现模型命名\n- optical flow: 光流\n- encoder-decoder: 编码器-解码器\n- total variation: 全变分\n- brightness constancy: 亮度恒定性\n- edge-preserving: 边缘保持）"
    },
    {
        "title": "Skeleton-based sign language recognition using a dual-stream\n  spatio-temporal dynamic graph convolutional network",
        "url": "http://arxiv.org/abs/2509.08661v1",
        "pub_date": "2025-09-10",
        "summary": "Isolated Sign Language Recognition (ISLR) is challenged by gestures that are morphologically similar yet semantically distinct, a problem rooted in the complex interplay between hand shape and motion trajectory. Existing methods, often relying on a single reference frame, struggle to resolve this geometric ambiguity. This paper introduces Dual-SignLanguageNet (DSLNet), a dual-reference, dual-stream architecture that decouples and models gesture morphology and trajectory in separate, complementary coordinate systems. Our approach utilizes a wrist-centric frame for view-invariant shape analysis and a facial-centric frame for context-aware trajectory modeling. These streams are processed by specialized networks-a topology-aware graph convolution for shape and a Finsler geometry-based encoder for trajectory-and are integrated via a geometry-driven optimal transport fusion mechanism. DSLNet sets a new state-of-the-art, achieving 93.70%, 89.97% and 99.79% accuracy on the challenging WLASL-100, WLASL-300 and LSA64 datasets, respectively, with significantly fewer parameters than competing models.",
        "translated": "孤立手语识别（ISLR）面临形态相似但语义迥异的手势识别难题，这一挑战源于手部形状与运动轨迹之间复杂的相互作用。现有方法通常依赖单一参考帧，难以解决这种几何模糊性问题。本文提出双参考帧双流架构Dual-SignLanguageNet（DSLNet），通过在两个互补坐标系中解耦并分别建模手势形态和运动轨迹。我们的方法采用腕部中心坐标系实现视角无关的形状分析，以及面部中心坐标系实现上下文感知的轨迹建模——两个分支分别由专用网络处理：采用拓扑感知图卷积网络处理形状信息，基于芬斯勒几何的编码器处理轨迹信息，最终通过几何驱动的最优传输融合机制进行整合。DSLNet以显著更少的参数量，在具有挑战性的WLASL-100、WLASL-300和LSA64数据集上分别达到93.70%、89.97%和99.79%的准确率，创造了新的性能标杆。\n\n（注：专业术语说明：\n1. Finsler geometry保留为\"芬斯勒几何\"，这是微分几何中的标准术语\n2. optimal transport采用学界通用译法\"最优传输\"\n3. graph convolution遵循计算机视觉领域规范译为\"图卷积\"\n4. WLASL/LSA64作为标准数据集名称保留不译\n5. parameters根据上下文译为\"参数量\"而非\"参数\"，更符合深度学习领域的表述习惯）"
    },
    {
        "title": "X-Part: high fidelity and structure coherent shape decomposition",
        "url": "http://arxiv.org/abs/2509.08643v1",
        "pub_date": "2025-09-10",
        "summary": "Generating 3D shapes at part level is pivotal for downstream applications such as mesh retopology, UV mapping, and 3D printing. However, existing part-based generation methods often lack sufficient controllability and suffer from poor semantically meaningful decomposition. To this end, we introduce X-Part, a controllable generative model designed to decompose a holistic 3D object into semantically meaningful and structurally coherent parts with high geometric fidelity. X-Part exploits the bounding box as prompts for the part generation and injects point-wise semantic features for meaningful decomposition. Furthermore, we design an editable pipeline for interactive part generation. Extensive experimental results show that X-Part achieves state-of-the-art performance in part-level shape generation. This work establishes a new paradigm for creating production-ready, editable, and structurally sound 3D assets. Codes will be released for public research.",
        "translated": "在部件级别生成三维形状对于网格重拓扑、UV映射和三维打印等下游应用至关重要。然而，现有的基于部件的生成方法往往缺乏足够的可控性，且语义化分解效果不佳。为此，我们提出了X-Part——一种可控生成模型，能够将整体三维对象分解为具有高几何保真度的语义化部件，并保持结构一致性。该模型以边界框作为部件生成提示，并通过注入点级语义特征实现有意义的结构分解。此外，我们设计了支持交互式部件生成的可编辑流程。大量实验结果表明，X-Part在部件级形状生成任务上达到了最先进的性能。这项工作为创建生产就绪、可编辑且结构合理的三维资产建立了新范式。代码将开源以供学术研究使用。\n\n（注：根据学术规范，对\"Codes will be released for public research\"采用国内计算机领域常用表述\"代码将开源\"进行意译，既符合中文表达习惯，也准确传递了原意）"
    },
    {
        "title": "RoentMod: A Synthetic Chest X-Ray Modification Model to Identify and\n  Correct Image Interpretation Model Shortcuts",
        "url": "http://arxiv.org/abs/2509.08640v1",
        "pub_date": "2025-09-10",
        "summary": "Chest radiographs (CXRs) are among the most common tests in medicine. Automated image interpretation may reduce radiologists\\' workload and expand access to diagnostic expertise. Deep learning multi-task and foundation models have shown strong performance for CXR interpretation but are vulnerable to shortcut learning, where models rely on spurious and off-target correlations rather than clinically relevant features to make decisions. We introduce RoentMod, a counterfactual image editing framework that generates anatomically realistic CXRs with user-specified, synthetic pathology while preserving unrelated anatomical features of the original scan. RoentMod combines an open-source medical image generator (RoentGen) with an image-to-image modification model without requiring retraining. In reader studies with board-certified radiologists and radiology residents, RoentMod-produced images appeared realistic in 93\\% of cases, correctly incorporated the specified finding in 89-99\\% of cases, and preserved native anatomy comparable to real follow-up CXRs. Using RoentMod, we demonstrate that state-of-the-art multi-task and foundation models frequently exploit off-target pathology as shortcuts, limiting their specificity. Incorporating RoentMod-generated counterfactual images during training mitigated this vulnerability, improving model discrimination across multiple pathologies by 3-19\\% AUC in internal validation and by 1-11\\% for 5 out of 6 tested pathologies in external testing. These findings establish RoentMod as a broadly applicable tool for probing and correcting shortcut learning in medical AI. By enabling controlled counterfactual interventions, RoentMod enhances the robustness and interpretability of CXR interpretation models and provides a generalizable strategy for improving foundation models in medical imaging.",
        "translated": "胸部X光片（CXR）是临床最常用的检查手段之一。自动化影像解读可减轻放射科医生的工作负担并扩大诊断专业知识的可及性。深度学习多任务与基础模型虽在CXR解读中表现出色，但存在捷径学习缺陷——模型依赖虚假或偏离目标的关联而非临床相关特征进行决策。我们提出RoentMod反事实图像编辑框架，该框架能生成具有用户指定合成病变、且保留原始扫描中无关解剖特征的解剖学真实CXR图像。RoentMod将开源医学图像生成器（RoentGen）与图像修改模型相结合，无需重新训练。经执业放射医师和放射科住院医师参与的阅片研究显示：RoentMod生成的图像真实性获93%认可，89-99%的案例正确融合指定病灶特征，其原生解剖结构保存度与真实随访CXR相当。通过RoentMod实验，我们发现当前最优的多任务与基础模型频繁利用偏离目标的病变特征作为捷径，限制了模型特异性。在训练中加入Roent生成的反事实图像后，模型抗干扰能力显著提升：内部验证中多项病变的判别AUC提升3-19%，外部测试中6类病变有5类提升1-11%。这些发现表明RoentMod可作为普适性工具用于探测和修正医学AI中的捷径学习。通过实现可控的反事实干预，RoentMod增强了CXR解读模型的鲁棒性与可解释性，为改进医学影像基础模型提供了可推广的策略。"
    },
    {
        "title": "LADB: Latent Aligned Diffusion Bridges for Semi-Supervised Domain\n  Translation",
        "url": "http://arxiv.org/abs/2509.08628v1",
        "pub_date": "2025-09-10",
        "summary": "Diffusion models excel at generating high-quality outputs but face challenges in data-scarce domains, where exhaustive retraining or costly paired data are often required. To address these limitations, we propose Latent Aligned Diffusion Bridges (LADB), a semi-supervised framework for sample-to-sample translation that effectively bridges domain gaps using partially paired data. By aligning source and target distributions within a shared latent space, LADB seamlessly integrates pretrained source-domain diffusion models with a target-domain Latent Aligned Diffusion Model (LADM), trained on partially paired latent representations. This approach enables deterministic domain mapping without the need for full supervision. Compared to unpaired methods, which often lack controllability, and fully paired approaches that require large, domain-specific datasets, LADB strikes a balance between fidelity and diversity by leveraging a mixture of paired and unpaired latent-target couplings. Our experimental results demonstrate superior performance in depth-to-image translation under partial supervision. Furthermore, we extend LADB to handle multi-source translation (from depth maps and segmentation masks) and multi-target translation in a class-conditioned style transfer task, showcasing its versatility in handling diverse and heterogeneous use cases. Ultimately, we present LADB as a scalable and versatile solution for real-world domain translation, particularly in scenarios where data annotation is costly or incomplete.",
        "translated": "扩散模型在生成高质量输出方面表现出色，但在数据稀缺领域面临挑战，这些领域通常需要 exhaustive 的重新训练或成本高昂的配对数据。为应对这些局限性，我们提出潜在对齐扩散桥（LADB），这是一种用于样本到样本转换的半监督框架，能够利用部分配对数据有效弥合领域差距。通过在共享潜在空间中对齐源域和目标域分布，LADB 将预训练的源域扩散模型与目标域潜在对齐扩散模型（LADM）无缝集成，后者基于部分配对的潜在表示进行训练。这一方法实现了确定性的领域映射，无需完全监督。与通常缺乏可控性的非配对方法以及需要大型领域特定数据集的完全配对方法相比，LADB 通过结合配对和非配对的潜在-目标耦合，在保真度和多样性之间取得了平衡。我们的实验结果表明，该方法在部分监督下的深度图到图像转换任务中表现优异。此外，我们将 LADB 扩展到多源转换（从深度图和分割掩码）以及类别条件风格迁移任务中的多目标转换，展示了其处理多样化和异构用例的灵活性。最终，我们提出 LADB 作为一种可扩展且通用的解决方案，适用于现实世界的领域转换任务，尤其是在数据标注成本高昂或不完整的场景中。"
    },
    {
        "title": "A Survey of Reinforcement Learning for Large Reasoning Models",
        "url": "http://arxiv.org/abs/2509.08827v1",
        "pub_date": "2025-09-10",
        "summary": "In this paper, we survey recent advances in Reinforcement Learning (RL) for reasoning with Large Language Models (LLMs). RL has achieved remarkable success in advancing the frontier of LLM capabilities, particularly in addressing complex logical tasks such as mathematics and coding. As a result, RL has emerged as a foundational methodology for transforming LLMs into LRMs. With the rapid progress of the field, further scaling of RL for LRMs now faces foundational challenges not only in computational resources but also in algorithm design, training data, and infrastructure. To this end, it is timely to revisit the development of this domain, reassess its trajectory, and explore strategies to enhance the scalability of RL toward Artificial SuperIntelligence (ASI). In particular, we examine research applying RL to LLMs and LRMs for reasoning abilities, especially since the release of DeepSeek-R1, including foundational components, core problems, training resources, and downstream applications, to identify future opportunities and directions for this rapidly evolving area. We hope this review will promote future research on RL for broader reasoning models. Github: https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs",
        "translated": "本文综述了强化学习（RL）在大语言模型（LLM）推理任务中的最新进展。强化学习在拓展大语言模型能力边界方面取得了显著成就，尤其在数学与编程等复杂逻辑任务上表现突出。因此，强化学习已成为将大语言模型升级为逻辑推理模型（LRM）的基础方法论。随着该领域的快速发展，逻辑推理模型的强化学习规模化应用正面临基础性挑战，这些挑战不仅存在于计算资源层面，更涉及算法设计、训练数据与基础设施等多个维度。为此，有必要重新审视该领域的发展路径，评估其演进轨迹，并探索增强强化学习可扩展性以实现人工超智能（ASI）的策略。本文重点分析了自DeepSeek-R1发布以来，强化学习在提升大语言模型与逻辑推理模型推理能力方面的研究进展，涵盖基础组件、核心问题、训练资源及下游应用等维度，以揭示这一快速发展领域的未来机遇与方向。我们希望本综述能推动强化学习在更广泛推理模型中的深入研究。GitHub项目地址：https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs\n\n（注：译文严格遵循学术规范，对RL（强化学习）、LLM（大语言模型）、LRM（逻辑推理模型）、ASI（人工超智能）等专业术语采用括号标注全称的规范译法，保持技术表述的准确性。长难句按中文习惯拆分重组，确保逻辑清晰性。GitHub链接等数字资源信息完整保留。）"
    },
    {
        "title": "Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs\n  for Text Annotation",
        "url": "http://arxiv.org/abs/2509.08825v1",
        "pub_date": "2025-09-10",
        "summary": "Large language models (LLMs) are rapidly transforming social science research by enabling the automation of labor-intensive tasks like data annotation and text analysis. However, LLM outputs vary significantly depending on the implementation choices made by researchers (e.g., model selection, prompting strategy, or temperature settings). Such variation can introduce systematic biases and random errors, which propagate to downstream analyses and cause Type I, Type II, Type S, or Type M errors. We call this LLM hacking.   We quantify the risk of LLM hacking by replicating 37 data annotation tasks from 21 published social science research studies with 18 different models. Analyzing 13 million LLM labels, we test 2,361 realistic hypotheses to measure how plausible researcher choices affect statistical conclusions. We find incorrect conclusions based on LLM-annotated data in approximately one in three hypotheses for state-of-the-art models, and in half the hypotheses for small language models. While our findings show that higher task performance and better general model capabilities reduce LLM hacking risk, even highly accurate models do not completely eliminate it. The risk of LLM hacking decreases as effect sizes increase, indicating the need for more rigorous verification of findings near significance thresholds. Our extensive analysis of LLM hacking mitigation techniques emphasizes the importance of human annotations in reducing false positive findings and improving model selection. Surprisingly, common regression estimator correction techniques are largely ineffective in reducing LLM hacking risk, as they heavily trade off Type I vs. Type II errors.   Beyond accidental errors, we find that intentional LLM hacking is unacceptably simple. With few LLMs and just a handful of prompt paraphrases, anything can be presented as statistically significant.",
        "translated": "大型语言模型（LLMs）正通过自动化数据标注和文本分析等劳动密集型任务，迅速改变社会科学研究范式。然而，LLM的输出结果会因研究者的实施选择（如模型选择、提示策略或温度参数设置）产生显著差异。这种差异可能引入系统性偏差和随机误差，进而蔓延至下游分析，导致第一类错误、第二类错误、符号错误或量级错误。我们将这种现象称为\"LLM黑客行为\"。  \n\n我们通过复现21项已发表社会科学研究中的37个数据标注任务，使用18种不同模型进行量化分析。基于对1300万个LLM生成标签的检验，我们针对2,361个现实假设测试了研究者不同选择对统计结论的影响。研究发现：使用最先进模型标注数据时，约三分之一的假设会得出错误结论；而使用小型语言模型时，错误结论比例高达二分之一。虽然任务表现提升和模型通用能力增强可降低LLM黑客风险，但即使高精度模型也无法完全消除该风险。随着效应量增大，LLM黑客风险会相应降低，这表明对接近显著性阈值的研究发现需要更严格的验证。  \n\n我们对LLM黑客风险缓解技术的深入分析表明：人工标注对于降低假阳性发现和改进模型选择至关重要。令人惊讶的是，常见的回归估计量校正技术对降低LLM黑客风险基本无效，因为它们需要大幅权衡第一类与第二类错误。  \n\n除意外误差外，我们发现故意实施LLM黑客行为异常简单：仅需使用少量LLM模型和提示词变体，任何结论都可以被呈现为具有统计显著性。"
    },
    {
        "title": "Building High-Quality Datasets for Portuguese LLMs: From Common Crawl\n  Snapshots to Industrial-Grade Corpora",
        "url": "http://arxiv.org/abs/2509.08824v1",
        "pub_date": "2025-09-10",
        "summary": "The performance of large language models (LLMs) is deeply influenced by the quality and composition of their training data. While much of the existing work has centered on English, there remains a gap in understanding how to construct effective training corpora for other languages. We explore scalable methods for building web-based corpora for LLMs. We apply them to build a new 120B token corpus in Portuguese that achieves competitive results to an industrial-grade corpus. Using a continual pretraining setup, we study how different data selection and preprocessing strategies affect LLM performance when transitioning a model originally trained in English to another language. Our findings demonstrate the value of language-specific filtering pipelines, including classifiers for education, science, technology, engineering, and mathematics (STEM), as well as toxic content. We show that adapting a model to the target language leads to performance improvements, reinforcing the importance of high-quality, language-specific data. While our case study focuses on Portuguese, our methods are applicable to other languages, offering insights for multilingual LLM development.",
        "translated": "大型语言模型（LLM）的性能深受其训练数据质量与构成的影响。尽管现有研究多集中于英语语料，但针对其他语言如何构建有效训练语料仍存在认知空白。本研究探索了基于网络数据构建多语言LLM语料库的可扩展方法，并成功构建了包含1200亿词元的葡萄牙语语料库，其性能可与工业级语料库相媲美。通过持续预训练实验框架，我们系统分析了当将原基于英语训练的模型迁移至其他语言时，不同数据筛选与预处理策略对模型性能的影响。研究结果表明：采用针对目标语言的专项过滤流程（包括教育类、STEM领域及有害内容分类器）具有显著价值；模型适应目标语言后性能持续提升，印证了高质量语言专属数据的重要性。虽然本案例研究聚焦葡萄牙语，但所提出的方法适用于其他语言，为多语言LLM开发提供了重要实践洞见。"
    },
    {
        "title": "Merge-of-Thought Distillation",
        "url": "http://arxiv.org/abs/2509.08814v1",
        "pub_date": "2025-09-10",
        "summary": "Efficient reasoning distillation for long chain-of-thought (CoT) models is increasingly constrained by the assumption of a single oracle teacher, despite practical availability of multiple candidate teachers and growing CoT corpora. We revisit teacher selection and observe that different students have different \"best teachers,\" and even for the same student the best teacher can vary across datasets. Therefore, to unify multiple teachers' reasoning abilities into student with overcoming conflicts among various teachers' supervision, we propose Merge-of-Thought Distillation (MoT), a lightweight framework that alternates between teacher-specific supervised fine-tuning branches and weight-space merging of the resulting student variants. On competition math benchmarks, using only about 200 high-quality CoT samples, applying MoT to a Qwen3-14B student surpasses strong models including DEEPSEEK-R1, QWEN3-30B-A3B, QWEN3-32B, and OPENAI-O1, demonstrating substantial gains. Besides, MoT consistently outperforms the best single-teacher distillation and the naive multi-teacher union, raises the performance ceiling while mitigating overfitting, and shows robustness to distribution-shifted and peer-level teachers. Moreover, MoT reduces catastrophic forgetting, improves general reasoning beyond mathematics and even cultivates a better teacher, indicating that consensus-filtered reasoning features transfer broadly. These results position MoT as a simple, scalable route to efficiently distilling long CoT capabilities from diverse teachers into compact students.",
        "translated": "尽管实际中存在多个候选教师模型且思维链语料库日益丰富，高效的长链思维推理蒸馏仍长期受限于单一最优教师的假设约束。我们重新审视教师选择机制，发现不同学生存在差异化的\"最佳教师\"，甚至同一学生在不同数据集上的最优教师也会变化。为此，我们提出融合思维蒸馏框架（MoT），通过交替执行教师专属的监督微调分支与权重空间融合，将多位教师的推理能力统一注入学生模型，有效解决多教师监督间的冲突。在数学竞赛基准测试中，仅使用约200个高质量思维链样本，对Qwen3-14B学生模型应用MoT后，其表现超越了DEEPSEEK-R1、QWEN3-30B-A3B、QWEN3-32B及OPENAI-O1等强劲模型，实现显著性能提升。该框架不仅持续优于最佳单教师蒸馏和朴素多教师联合方法，在提升性能上限的同时缓解过拟合现象，还对分布偏移和同级别教师表现出鲁棒性。此外，MoT能减少灾难性遗忘，提升数学领域外的泛化推理能力，甚至培育出更优质的教师模型，表明经过共识过滤的推理特征具有广泛迁移性。这些成果使MoT成为从多元教师向紧凑学生模型高效蒸馏长链思维能力的简洁可扩展方案。"
    },
    {
        "title": "MoVoC: Morphology-Aware Subword Construction for Geez Script Languages",
        "url": "http://arxiv.org/abs/2509.08812v1",
        "pub_date": "2025-09-10",
        "summary": "Subword-based tokenization methods often fail to preserve morphological boundaries, a limitation especially pronounced in low-resource, morphologically complex languages such as those written in the Geez script. To address this, we present MoVoC (Morpheme-aware Subword Vocabulary Construction) and train MoVoC-Tok, a tokenizer that integrates supervised morphological analysis into the subword vocabulary. This hybrid segmentation approach combines morpheme-based and Byte Pair Encoding (BPE) tokens to preserve morphological integrity while maintaining lexical meaning. To tackle resource scarcity, we curate and release manually annotated morpheme data for four Geez script languages and a morpheme-aware vocabulary for two of them. While the proposed tokenization method does not lead to significant gains in automatic translation quality, we observe consistent improvements in intrinsic metrics, MorphoScore, and Boundary Precision, highlighting the value of morphology-aware segmentation in enhancing linguistic fidelity and token efficiency. Our morpheme-annotated datasets and tokenizer will be publicly available to support further research in low-resource, morphologically rich languages. Our code and data are available on GitHub: https://github.com/hailaykidu/MoVoC",
        "translated": "基于子词的标记化方法往往难以有效保留形态学边界，这一局限在资源匮乏且形态复杂的语言（如使用吉兹字母的文字体系）中尤为明显。为此，我们提出MoVoC（形态素感知的子词词汇构建方法），并训练出集成监督式形态分析的标记器MoVoC-Tok。该混合分词方法结合了基于形态素的分词与字节对编码（BPE）标记，在保持词汇语义的同时维护形态完整性。针对资源稀缺问题，我们整理并发布了四种吉兹字母语言的人工标注形态素数据集，以及其中两种语言的形态素感知词汇表。虽然所提出的标记化方法未显著提升自动翻译质量，但我们观察到内在评估指标MorphoScore和边界精确率（Boundary Precision）的持续改善，这凸显了形态感知分词在提升语言保真度和标记效率方面的价值。我们公开提供形态素标注数据集与标记器，以支持对资源匮乏型形态丰富语言的进一步研究。代码与数据详见GitHub：https://github.com/hailaykidu/MoVoC\n\n（注：Geez script作为专有名词保留\"吉兹字母\"译法，MorphoScore作为专业指标名称保留英文形式，技术术语如\"Byte Pair Encoding (BPE)\"采用学界通用译法\"字节对编码\"）"
    },
    {
        "title": "Evaluating LLMs Without Oracle Feedback: Agentic Annotation Evaluation\n  Through Unsupervised Consistency Signals",
        "url": "http://arxiv.org/abs/2509.08809v1",
        "pub_date": "2025-09-10",
        "summary": "Large Language Models (LLMs), when paired with prompt-based tasks, have significantly reduced data annotation costs and reliance on human annotators. However, evaluating the quality of their annotations remains challenging in dynamic, unsupervised environments where oracle feedback is scarce and conventional methods fail. To address this challenge, we propose a novel agentic annotation paradigm, where a student model collaborates with a noisy teacher (the LLM) to assess and refine annotation quality without relying on oracle feedback. The student model, acting as an unsupervised feedback mechanism, employs a user preference-based majority voting strategy to evaluate the consistency of the LLM outputs. To systematically measure the reliability of LLM-generated annotations, we introduce the Consistent and Inconsistent (CAI) Ratio, a novel unsupervised evaluation metric. The CAI Ratio not only quantifies the annotation quality of the noisy teacher under limited user preferences but also plays a critical role in model selection, enabling the identification of robust LLMs in dynamic, unsupervised environments. Applied to ten open-domain NLP datasets across four LLMs, the CAI Ratio demonstrates a strong positive correlation with LLM accuracy, establishing it as an essential tool for unsupervised evaluation and model selection in real-world settings.",
        "translated": "在基于提示的任务中，大语言模型（LLMs）显著降低了数据标注成本并减少了对人工标注者的依赖。然而，在动态无监督环境中，由于缺乏真实反馈且传统方法失效，评估其标注质量仍具挑战性。针对这一问题，我们提出了一种新型智能标注范式：通过学生模型与噪声教师（即大语言模型）协作，在不依赖真实反馈的情况下评估并优化标注质量。该学生模型作为无监督反馈机制，采用基于用户偏好的多数投票策略来评估大语言模型输出的一致性。为系统衡量大语言模型生成标注的可靠性，我们提出了\"一致性与不一致性比率\"（CAI Ratio）这一新型无监督评估指标。CAI比率不仅能量化噪声教师在有限用户偏好下的标注质量，还在模型选择中发挥关键作用，帮助在动态无监督环境中识别稳健的大语言模型。通过在四个大语言模型和十个开放域NLP数据集上的实验验证，CAI比率与大语言模型准确率呈现强正相关，证明了其作为现实场景中无监督评估与模型选择核心工具的有效性。"
    },
    {
        "title": "Scaling Truth: The Confidence Paradox in AI Fact-Checking",
        "url": "http://arxiv.org/abs/2509.08803v1",
        "pub_date": "2025-09-10",
        "summary": "The rise of misinformation underscores the need for scalable and reliable fact-checking solutions. Large language models (LLMs) hold promise in automating fact verification, yet their effectiveness across global contexts remains uncertain. We systematically evaluate nine established LLMs across multiple categories (open/closed-source, multiple sizes, diverse architectures, reasoning-based) using 5,000 claims previously assessed by 174 professional fact-checking organizations across 47 languages. Our methodology tests model generalizability on claims postdating training cutoffs and four prompting strategies mirroring both citizen and professional fact-checker interactions, with over 240,000 human annotations as ground truth. Findings reveal a concerning pattern resembling the Dunning-Kruger effect: smaller, accessible models show high confidence despite lower accuracy, while larger models demonstrate higher accuracy but lower confidence. This risks systemic bias in information verification, as resource-constrained organizations typically use smaller models. Performance gaps are most pronounced for non-English languages and claims originating from the Global South, threatening to widen existing information inequalities. These results establish a multilingual benchmark for future research and provide an evidence base for policy aimed at ensuring equitable access to trustworthy, AI-assisted fact-checking.",
        "translated": "错误信息的泛滥凸显了对可扩展且可靠的事实核查解决方案的迫切需求。大型语言模型（LLMs）在自动化事实核查领域展现出潜力，但其在全球语境下的有效性仍存疑问。本研究系统评估了九种主流LLMs（涵盖开源/闭源、多种参数量级、不同架构及基于推理的模型），使用由174家专业事实核查机构以47种语言验证过的5,000条声明作为测试集。我们的方法通过训练截止日期后产生的声明测试模型泛化能力，并采用四种提示策略模拟普通用户和专业核查人员的交互场景，以超过24万条人工标注作为基准真值。\n\n研究发现存在类似邓宁-克鲁格效应的风险模式：轻量级开源模型虽准确率较低却呈现高置信度，而大型模型准确率更高却表现更谨慎。这种偏差可能导致系统性风险——资源有限的机构通常使用小型模型进行信息验证。性能差距在非英语语境及源自全球南方的声明中尤为显著，这种技术鸿沟可能加剧现有的信息不平等。本研究为后续研究建立了多语言基准测试框架，并为制定保障公平获取可信AI辅助事实核查政策的制定提供了实证依据。"
    },
    {
        "title": "Do All Autoregressive Transformers Remember Facts the Same Way? A\n  Cross-Architecture Analysis of Recall Mechanisms",
        "url": "http://arxiv.org/abs/2509.08778v1",
        "pub_date": "2025-09-10",
        "summary": "Understanding how Transformer-based language models store and retrieve factual associations is critical for improving interpretability and enabling targeted model editing. Prior work, primarily on GPT-style models, has identified MLP modules in early layers as key contributors to factual recall. However, it remains unclear whether these findings generalize across different autoregressive architectures. To address this, we conduct a comprehensive evaluation of factual recall across several models -- including GPT, LLaMA, Qwen, and DeepSeek -- analyzing where and how factual information is encoded and accessed. Consequently, we find that Qwen-based models behave differently from previous patterns: attention modules in the earliest layers contribute more to factual recall than MLP modules. Our findings suggest that even within the autoregressive Transformer family, architectural variations can lead to fundamentally different mechanisms of factual recall.",
        "translated": "理解基于Transformer的语言模型如何存储和检索事实关联，对于提升模型可解释性和实现定向模型编辑至关重要。先前针对GPT类模型的研究发现，早期层的MLP模块是事实召回的关键贡献者。然而，这些发现是否适用于不同自回归架构仍不明确。为此，我们对包括GPT、LLaMA、Qwen和DeepSeek在内的多个模型进行了事实召回能力的综合评估，分析事实信息编码与访问的位置及机制。研究发现，基于Qwen的模型表现出与既往模式不同的特性：其最早层的注意力模块对事实召回的贡献度超过MLP模块。这一结果表明，即使在自回归Transformer架构家族内部，结构差异也可能导致事实召回机制的根本性不同。"
    },
    {
        "title": "AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making\n  through Multi-Turn Reinforcement Learning",
        "url": "http://arxiv.org/abs/2509.08755v1",
        "pub_date": "2025-09-10",
        "summary": "Developing autonomous LLM agents capable of making a series of intelligent decisions to solve complex, real-world tasks is a fast-evolving frontier. Like human cognitive development, agents are expected to acquire knowledge and skills through exploration and interaction with the environment. Despite advances, the community still lacks a unified, interactive reinforcement learning (RL) framework that can effectively train such agents from scratch -- without relying on supervised fine-tuning (SFT) -- across diverse and realistic environments. To bridge this gap, we introduce AgentGym-RL, a new framework to train LLM agents for multi-turn interactive decision-making through RL. The framework features a modular and decoupled architecture, ensuring high flexibility and extensibility. It encompasses a wide variety of real-world scenarios, and supports mainstream RL algorithms. Furthermore, we propose ScalingInter-RL, a training approach designed for exploration-exploitation balance and stable RL optimization. In early stages, it emphasizes exploitation by restricting the number of interactions, and gradually shifts towards exploration with larger horizons to encourage diverse problem-solving strategies. In this way, the agent develops more diverse behaviors and is less prone to collapse under long horizons. We perform extensive experiments to validate the stability and effectiveness of both the AgentGym-RL framework and the ScalingInter-RL approach. Our agents match or surpass commercial models on 27 tasks across diverse environments. We offer key insights and will open-source the complete AgentGym-RL framework -- including code and datasets -- to empower the research community in developing the next generation of intelligent agents.",
        "translated": "开发能够通过一系列智能决策解决复杂现实任务的自主大语言模型（LLM）智能体，是当前快速演进的前沿领域。与人类认知发展类似，智能体需要通过与环境探索和交互来获取知识与技能。尽管已有诸多进展，学界仍缺乏一个统一的交互式强化学习（RL）框架，能够在多样化的现实环境中完全从零开始（无需监督微调SFT）有效训练此类智能体。为填补这一空白，我们提出了AgentGym-RL——一个通过强化学习训练多轮交互决策LLM智能体的新型框架。该框架采用模块化解耦架构，确保高度灵活性与可扩展性，涵盖多样化现实场景，并支持主流RL算法。\n\n此外，我们提出ScalingInter-RL训练方法，旨在实现探索-利用的平衡与稳定的RL优化。该方法在早期阶段通过限制交互次数强调利用策略，随后逐步扩大探索范围以鼓励多样化问题解决策略。这种设计使智能体能够发展出更丰富的行为模式，并降低长周期任务中的策略崩溃风险。我们通过大量实验验证了AgentGym-RL框架与ScalingInter-RL方法的稳定性与有效性：训练的智能体在27个跨领域任务中达到或超越了商业模型性能。我们将提供关键洞见并开源完整的AgentGym-RL框架（含代码与数据集），以推动新一代智能体的研发。\n\n（注：专业术语说明：\n- LLM：大语言模型（Large Language Model）\n- RL：强化学习（Reinforcement Learning）\n- SFT：监督微调（Supervised Fine-Tuning）\n- 探索-利用平衡（exploration-exploitation tradeoff）：强化学习中智能体在尝试新策略（探索）与执行已知有效策略（利用）之间的平衡机制）"
    },
    {
        "title": "Streaming Sequence-to-Sequence Learning with Delayed Streams Modeling",
        "url": "http://arxiv.org/abs/2509.08753v1",
        "pub_date": "2025-09-10",
        "summary": "We introduce Delayed Streams Modeling (DSM), a flexible formulation for streaming, multimodal sequence-to-sequence learning. Sequence-to-sequence generation is often cast in an offline manner, where the model consumes the complete input sequence before generating the first output timestep. Alternatively, streaming sequence-to-sequence rely on learning a policy for choosing when to advance on the input stream, or write to the output stream. DSM instead models already time-aligned streams with a decoder-only language model. By moving the alignment to a pre-processing step,and introducing appropriate delays between streams, DSM provides streaming inference of arbitrary output sequences, from any input combination, making it applicable to many sequence-to-sequence problems. In particular, given text and audio streams, automatic speech recognition (ASR) corresponds to the text stream being delayed, while the opposite gives a text-to-speech (TTS) model. We perform extensive experiments for these two major sequence-to-sequence tasks, showing that DSM provides state-of-the-art performance and latency while supporting arbitrary long sequences, being even competitive with offline baselines. Code, samples and demos are available at https://github.com/kyutai-labs/delayed-streams-modeling",
        "translated": "我们提出了延迟流建模（Delayed Streams Modeling, DSM），这是一种面向流式多模态序列到序列学习的灵活框架。传统的序列到序列生成通常以离线方式进行，即模型需完整读取输入序列后才开始生成第一个输出时间步。而流式序列到序列方法则依赖于学习一种策略来决定何时推进输入流或写入输出流。与之不同，DSM采用仅含解码器的语言模型来处理已经时间对齐的流数据。通过将对齐过程移至预处理阶段，并在不同流之间引入适当延迟，DSM能够实现从任意输入组合到任意输出序列的流式推理，使其可广泛应用于多种序列到序列问题。特别地，当给定文本和音频流时，自动语音识别（ASR）对应于文本流延迟的情况，而相反配置则构成文本到语音（TTS）模型。我们针对这两大核心序列到序列任务进行了大量实验，结果表明DSM在支持任意长序列的同时，实现了最先进的性能与延迟表现，甚至可与离线基线模型相媲美。代码、样本及演示详见https://github.com/kyutai-labs/delayed-streams-modeling。\n\n（注：根据学术规范，术语处理说明：\n1. \"streaming\"在计算领域统一译为\"流式\"\n2. \"decoder-only language model\"译为\"仅含解码器的语言模型\"\n3. \"state-of-the-art\"遵循国内学术惯例译为\"最先进的\"\n4. 专业缩写ASR/TTS首次出现时标注英文全称及中文译名）"
    },
    {
        "title": "X-Teaming Evolutionary M2S: Automated Discovery of Multi-turn to\n  Single-turn Jailbreak Templates",
        "url": "http://arxiv.org/abs/2509.08729v1",
        "pub_date": "2025-09-10",
        "summary": "Multi-turn-to-single-turn (M2S) compresses iterative red-teaming into one structured prompt, but prior work relied on a handful of manually written templates. We present X-Teaming Evolutionary M2S, an automated framework that discovers and optimizes M2S templates through language-model-guided evolution. The system pairs smart sampling from 12 sources with an LLM-as-judge inspired by StrongREJECT and records fully auditable logs.   Maintaining selection pressure by setting the success threshold to $\\theta = 0.70$, we obtain five evolutionary generations, two new template families, and 44.8% overall success (103/230) on GPT-4.1. A balanced cross-model panel of 2,500 trials (judge fixed) shows that structural gains transfer but vary by target; two models score zero at the same threshold. We also find a positive coupling between prompt length and score, motivating length-aware judging.   Our results demonstrate that structure-level search is a reproducible route to stronger single-turn probes and underscore the importance of threshold calibration and cross-model evaluation. Code, configurations, and artifacts are available at https://github.com/hyunjun1121/M2S-x-teaming.",
        "translated": "多轮转单轮（M2S）方法将迭代式红队测试压缩至单个结构化提示中，但以往研究依赖少量人工编写的模板。我们提出X-Teaming Evolutionary M2S框架，通过语言模型引导的进化自动发现并优化M2S模板。该系统结合了从12个数据源的智能采样策略，采用受StrongREJECT启发的LLM-as-judge评估机制，并记录完全可审计的日志。  \n通过将成功阈值设定为θ=0.70以维持选择压力，我们获得了五代进化结果、两个新模板家族，并在GPT-4.1上实现44.8%的整体成功率（103/230）。针对2,500次实验的平衡跨模型评估（固定评判标准）表明，结构增益具有可迁移性但随目标模型变化；有两个模型在相同阈值下成功率为零。我们还发现提示长度与得分呈正相关，这启发了长度感知的评判机制。  \n本研究证明：结构级搜索是增强单轮探测的有效可复现路径，同时强调了阈值校准和跨模型评估的重要性。代码、配置与实验成果详见https://github.com/hyunjun1121/M2S-x-teaming。\n\n（注：根据学术规范，关键术语处理如下：  \n- \"red-teaming\" 译为\"红队测试\"（安全评估方法）  \n- \"LLM-as-judge\" 译为\"LLM-as-judge评估机制\"（保留英文缩写并添加说明）  \n- \"selection pressure\" 译为\"选择压力\"（进化算法术语）  \n- \"cross-model evaluation\" 译为\"跨模型评估\"）"
    },
    {
        "title": "Generative Data Refinement: Just Ask for Better Data",
        "url": "http://arxiv.org/abs/2509.08653v1",
        "pub_date": "2025-09-10",
        "summary": "For a fixed parameter size, the capabilities of large models are primarily determined by the quality and quantity of its training data. Consequently, training datasets now grow faster than the rate at which new data is indexed on the web, leading to projected data exhaustion over the next decade. Much more data exists as user-generated content that is not publicly indexed, but incorporating such data comes with considerable risks, such as leaking private information and other undesirable content. We introduce a framework, Generative Data Refinement (GDR), for using pretrained generative models to transform a dataset with undesirable content into a refined dataset that is more suitable for training. Our experiments show that GDR can outperform industry-grade solutions for dataset anonymization, as well as enable direct detoxification of highly unsafe datasets. Moreover, we show that by generating synthetic data that is conditioned on each example in the real dataset, GDR's refined outputs naturally match the diversity of web scale datasets, and thereby avoid the often challenging task of generating diverse synthetic data via model prompting. The simplicity and effectiveness of GDR make it a powerful tool for scaling up the total stock of training data for frontier models.",
        "translated": "对于固定参数规模的大模型而言，其能力主要取决于训练数据的质量与数量。当前训练数据集的增长速度已超过网络公开索引数据的增长率，预计未来十年将面临数据枯竭问题。大量用户生成内容虽未公开索引，但直接使用此类数据存在显著风险，包括隐私泄露和不良内容等问题。我们提出生成式数据精炼框架（GDR），通过预训练生成模型将含不良内容的数据集转化为更适合训练的精炼数据集。实验表明，GDR在数据集匿名化处理方面优于工业级解决方案，并能直接对高度不安全数据集进行脱毒处理。通过基于真实数据集样本生成条件化合成数据，GDR的精炼输出自然保持网络规模数据集的多样性，避免了通过模型提示生成多样化合成数据的技术挑战。GDR的简洁性与有效性使其成为扩展前沿模型训练数据总量的有力工具。"
    },
    {
        "title": "OTESGN:Optimal Transport Enhanced Syntactic-Semantic Graph Networks for\n  Aspect-Based Sentiment Analysis",
        "url": "http://arxiv.org/abs/2509.08612v1",
        "pub_date": "2025-09-10",
        "summary": "Aspect-based sentiment analysis (ABSA) aims to identify aspect terms and determine their sentiment polarity. While dependency trees combined with contextual semantics effectively identify aspect sentiment, existing methods relying on syntax trees and aspect-aware attention struggle to model complex semantic relationships. Their dependence on linear dot-product features fails to capture nonlinear associations, allowing noisy similarity from irrelevant words to obscure key opinion terms. Motivated by Differentiable Optimal Matching, we propose the Optimal Transport Enhanced Syntactic-Semantic Graph Network (OTESGN), which introduces a Syntactic-Semantic Collaborative Attention. It comprises a Syntactic Graph-Aware Attention for mining latent syntactic dependencies and modeling global syntactic topology, as well as a Semantic Optimal Transport Attention designed to uncover fine-grained semantic alignments amidst textual noise, thereby accurately capturing sentiment signals obscured by irrelevant tokens. A Adaptive Attention Fusion module integrates these heterogeneous features, and contrastive regularization further improves robustness. Experiments demonstrate that OTESGN achieves state-of-the-art results, outperforming previous best models by +1.01% F1 on Twitter and +1.30% F1 on Laptop14 benchmarks. Ablative studies and visual analyses corroborate its efficacy in precise localization of opinion words and noise resistance.",
        "translated": "基于方面的情感分析（ABSA）旨在识别文本中的方面术语并判定其情感极性。尽管依赖树与上下文语义结合能有效识别方面情感，但现有基于语法树和方面感知注意力机制的方法难以建模复杂语义关系。这些方法对线性点积特征的依赖无法捕捉非线性关联，导致无关词汇产生的噪声相似度干扰关键观点词的识别。受可微分最优匹配理论启发，我们提出基于最优传输增强的语法-语义图网络（OTESGN），创新性地引入语法-语义协同注意力机制：该机制包含语法图感知注意力（挖掘潜在语法依赖并建模全局语法拓扑结构）和语义最优传输注意力（在文本噪声中发现细粒度语义对齐，从而精准捕获被无关词元遮蔽的情感信号）。自适应注意力融合模块整合这些异构特征，对比正则化进一步提升了模型鲁棒性。实验表明OTESNN取得最先进性能，在Twitter数据集上F1值较之前最佳模型提升1.01%，在Laptop14基准上提升1.30%。消融研究与可视化分析验证了该方法在观点词精确定位和噪声抵抗方面的有效性。\n\n（注：根据学术规范，对关键术语进行标准化处理：\n- Differentiable Optimal Matching 译为\"可微分最优匹配\"\n- Optimal Transport Enhanced Syntactic-Semantic Graph Network 保留首字母缩写OTESGN并给出全称\"最优传输增强的语法-语义图网络\"\n- Syntactic Graph-Aware Attention/Semantic Optimal Transport Attention 采用\"语法图感知注意力/语义最优传输注意力\"的译法\n- 技术指标F1值保留原始计量单位%）"
    },
    {
        "title": "Memorization in Large Language Models in Medicine: Prevalence,\n  Characteristics, and Implications",
        "url": "http://arxiv.org/abs/2509.08604v1",
        "pub_date": "2025-09-10",
        "summary": "Large Language Models (LLMs) have demonstrated significant potential in medicine. To date, LLMs have been widely applied to tasks such as diagnostic assistance, medical question answering, and clinical information synthesis. However, a key open question remains: to what extent do LLMs memorize medical training data. In this study, we present the first comprehensive evaluation of memorization of LLMs in medicine, assessing its prevalence (how frequently it occurs), characteristics (what is memorized), volume (how much content is memorized), and potential downstream impacts (how memorization may affect medical applications). We systematically analyze common adaptation scenarios: (1) continued pretraining on medical corpora, (2) fine-tuning on standard medical benchmarks, and (3) fine-tuning on real-world clinical data, including over 13,000 unique inpatient records from Yale New Haven Health System. The results demonstrate that memorization is prevalent across all adaptation scenarios and significantly higher than reported in the general domain. Memorization affects both the development and adoption of LLMs in medicine and can be categorized into three types: beneficial (e.g., accurate recall of clinical guidelines and biomedical references), uninformative (e.g., repeated disclaimers or templated medical document language), and harmful (e.g., regeneration of dataset-specific or sensitive clinical content). Based on these findings, we offer practical recommendations to facilitate beneficial memorization that enhances domain-specific reasoning and factual accuracy, minimize uninformative memorization to promote deeper learning beyond surface-level patterns, and mitigate harmful memorization to prevent the leakage of sensitive or identifiable patient information.",
        "translated": "大型语言模型（LLMs）在医学领域展现出巨大潜力。迄今，LLMs已被广泛应用于辅助诊断、医学问答和临床信息整合等任务。然而，一个关键问题尚未解决：LLMs对医学训练数据的记忆程度究竟如何？本研究首次对医学领域LLMs的记忆现象开展系统性评估，从普遍性（发生频率）、特征（记忆内容类型）、体量（记忆信息量）及潜在下游影响（记忆如何影响医学应用）四个维度进行探究。我们系统分析了三种常见适应场景：（1）基于医学语料的持续预训练；（2）在标准医学基准上的微调；（3）基于真实世界临床数据的微调，包括来自耶鲁纽黑文医疗系统的超13,000条独特住院记录。结果表明：记忆现象在所有适应场景中普遍存在，其程度显著高于通用领域报道值。记忆效应影响医学LLMs的开发与应用，可归为三类：有益记忆（如准确回忆临床指南和生物医学参考文献）、无意义记忆（如重复的免责声明或模板化医疗文书语言）以及有害记忆（如再生数据集特异性内容或敏感临床信息）。基于这些发现，我们提出实践建议：促进有益记忆以增强领域特异性推理和事实准确性，减少无意义记忆以推动超越表面模式的深度学习，并遏制有害记忆以防止敏感或可识别患者信息的泄露。"
    },
    {
        "title": "LLM Ensemble for RAG: Role of Context Length in Zero-Shot Question\n  Answering for BioASQ Challenge",
        "url": "http://arxiv.org/abs/2509.08596v1",
        "pub_date": "2025-09-10",
        "summary": "Biomedical question answering (QA) poses significant challenges due to the need for precise interpretation of specialized knowledge drawn from a vast, complex, and rapidly evolving corpus. In this work, we explore how large language models (LLMs) can be used for information retrieval (IR), and an ensemble of zero-shot models can accomplish state-of-the-art performance on a domain-specific Yes/No QA task. Evaluating our approach on the BioASQ challenge tasks, we show that ensembles can outperform individual LLMs and in some cases rival or surpass domain-tuned systems - all while preserving generalizability and avoiding the need for costly fine-tuning or labeled data. Our method aggregates outputs from multiple LLM variants, including models from Anthropic and Google, to synthesize more accurate and robust answers. Moreover, our investigation highlights a relationship between context length and performance: while expanded contexts are meant to provide valuable evidence, they simultaneously risk information dilution and model disorientation. These findings emphasize IR as a critical foundation in Retrieval-Augmented Generation (RAG) approaches for biomedical QA systems. Precise, focused retrieval remains essential for ensuring LLMs operate within relevant information boundaries when generating answers from retrieved documents. Our results establish that ensemble-based zero-shot approaches, when paired with effective RAG pipelines, constitute a practical and scalable alternative to domain-tuned systems for biomedical question answering.",
        "translated": "生物医学问答（QA）面临重大挑战，因为需要从庞大、复杂且快速更新的专业文献中精确解读专业知识。本研究探索了如何利用大语言模型（LLM）进行信息检索（IR），并通过零样本模型的集成方法在特定领域的二元问答任务中实现最先进性能。通过在BioASQ挑战任务上的评估，我们证明集成模型不仅能超越单个LLM的性能，在某些情况下甚至可与经过领域调优的系统相媲美或更优——同时保持泛化能力，无需昂贵的微调或标注数据。我们的方法聚合了包括Anthropic和谷歌多个LLM变体的输出，以生成更准确、更稳健的答案。\n\n研究还揭示了上下文长度与性能之间的关系：扩展的上下文本意是提供更有价值的证据，但同时也可能导致信息稀释和模型方向迷失。这些发现强调了信息检索在生物医学QA系统的检索增强生成（RAG）方法中的关键基础作用。当LLM基于检索到的文档生成答案时，精确且聚焦的检索对于确保模型在相关信息边界内运作至关重要。我们的结果表明：基于集成的零样本方法与有效的RAG流程结合时，可为生物医学问答提供一种兼具实用性、可扩展性的领域调优系统替代方案。\n\n（注：专业术语说明：\n- LLM：大语言模型（Large Language Model）\n- IR：信息检索（Information Retrieval）\n- RAG：检索增强生成（Retrieval-Augmented Generation）\n- 零样本（Zero-shot）：指模型未经特定任务训练即可执行该任务\n- 领域调优（Domain-tuned）：针对特定领域进行参数优化的系统）"
    },
    {
        "title": "CM-Align: Consistency-based Multilingual Alignment for Large Language\n  Models",
        "url": "http://arxiv.org/abs/2509.08541v1",
        "pub_date": "2025-09-10",
        "summary": "Current large language models (LLMs) generally show a significant performance gap in alignment between English and other languages. To bridge this gap, existing research typically leverages the model's responses in English as a reference to select the best/worst responses in other languages, which are then used for Direct Preference Optimization (DPO) training. However, we argue that there are two limitations in the current methods that result in noisy multilingual preference data and further limited alignment performance: 1) Not all English responses are of high quality, and using a response with low quality may mislead the alignment for other languages. 2) Current methods usually use biased or heuristic approaches to construct multilingual preference pairs. To address these limitations, we design a consistency-based data selection method to construct high-quality multilingual preference data for improving multilingual alignment (CM-Align). Specifically, our method includes two parts: consistency-guided English reference selection and cross-lingual consistency-based multilingual preference data construction. Experimental results on three LLMs and three common tasks demonstrate the effectiveness and superiority of our method, which further indicates the necessity of constructing high-quality preference data.",
        "translated": "当前的大型语言模型（LLM）在英语与其他语言的对齐性能上普遍存在显著差距。为弥补这一差距，现有研究通常以模型的英文回复作为参考，筛选其他语言中的最佳/最差回复，进而用于直接偏好优化（DPO）训练。然而，我们认为当前方法存在两个局限性，导致生成的多语言偏好数据存在噪声，进而限制对齐效果：1）并非所有英文回复都具有高质量，使用低质量回复可能误导其他语言的对齐过程；2）现有方法通常依赖有偏或启发式策略构建多语言偏好对。针对这些问题，我们设计了一种基于一致性的数据选择方法，用于构建高质量多语言偏好数据以提升多语言对齐性能（CM-Align）。具体而言，该方法包含两个核心模块：一致性引导的英文参考选择机制和基于跨语言一致性的多语言偏好数据构建机制。在三个大型语言模型和三项常见任务上的实验结果表明，本方法具有显著的有效性和优越性，进一步印证了构建高质量偏好数据的必要性。"
    },
    {
        "title": "HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI\n  Assistants",
        "url": "http://arxiv.org/abs/2509.08494v1",
        "pub_date": "2025-09-10",
        "summary": "As humans delegate more tasks and decisions to artificial intelligence (AI), we risk losing control of our individual and collective futures. Relatively simple algorithmic systems already steer human decision-making, such as social media feed algorithms that lead people to unintentionally and absent-mindedly scroll through engagement-optimized content. In this paper, we develop the idea of human agency by integrating philosophical and scientific theories of agency with AI-assisted evaluation methods: using large language models (LLMs) to simulate and validate user queries and to evaluate AI responses. We develop HumanAgencyBench (HAB), a scalable and adaptive benchmark with six dimensions of human agency based on typical AI use cases. HAB measures the tendency of an AI assistant or agent to Ask Clarifying Questions, Avoid Value Manipulation, Correct Misinformation, Defer Important Decisions, Encourage Learning, and Maintain Social Boundaries. We find low-to-moderate agency support in contemporary LLM-based assistants and substantial variation across system developers and dimensions. For example, while Anthropic LLMs most support human agency overall, they are the least supportive LLMs in terms of Avoid Value Manipulation. Agency support does not appear to consistently result from increasing LLM capabilities or instruction-following behavior (e.g., RLHF), and we encourage a shift towards more robust safety and alignment targets.",
        "translated": "随着人类将更多任务和决策权委托给人工智能（AI），我们正逐渐丧失对个人及集体未来的掌控。相对简单的算法系统已在引导人类决策，例如社交媒体信息流算法导致用户无意识、机械地浏览 engagement 优化内容。本文通过整合哲学与科学领域的能动性理论，结合AI辅助评估方法——使用大语言模型（LLMs）模拟验证用户查询并评估AI响应，系统阐述了人类能动性理念。我们开发了HumanAgencyBench（HAB），这是一个基于典型AI使用场景、包含六维人类能动性指标的可扩展自适应基准测试框架。HAB通过六大维度衡量AI助手或智能体的行为倾向：提出澄清性问题、避免价值操纵、纠正错误信息、推迟重大决策、鼓励学习以及维护社交边界。研究发现，当前基于LLM的助手对人类能动性的支持程度为低至中等水平，且不同系统开发者和维度间存在显著差异。例如，虽然Anthropic的LLM整体对人类能动性支持度最高，但在\"避免价值操纵\"维度却是支持度最低的模型。研究还表明，能动性支持度的提升并非源于LLM能力增强或指令遵循行为（如RLHF）的线性发展，我们呼吁转向更鲁棒的安全性与对齐目标建设。\n\n（注：专业术语处理说明：\n1. \"human agency\"译为\"人类能动性\"（哲学与社会科学领域标准译法）\n2. \"engagement-optimized content\"译为\"engagement优化内容\"（保留专业表述）\n3. \"LLMs\"统一译为\"大语言模型\"并标注英文缩写\n4. \"RLHF\"译为\"人类反馈强化学习\"并保留英文缩写\n5. \"alignment\"译为\"对齐\"（AI安全领域专业术语）\n6. \"Anthropic\"等企业名按行业惯例保留英文）"
    },
    {
        "title": "Too Helpful, Too Harmless, Too Honest or Just Right?",
        "url": "http://arxiv.org/abs/2509.08486v1",
        "pub_date": "2025-09-10",
        "summary": "Large Language Models (LLMs) exhibit strong performance across a wide range of NLP tasks, yet aligning their outputs with the principles of Helpfulness, Harmlessness, and Honesty (HHH) remains a persistent challenge. Existing methods often optimize for individual alignment dimensions in isolation, leading to trade-offs and inconsistent behavior. While Mixture-of-Experts (MoE) architectures offer modularity, they suffer from poorly calibrated routing, limiting their effectiveness in alignment tasks. We propose TrinityX, a modular alignment framework that incorporates a Mixture of Calibrated Experts (MoCaE) within the Transformer architecture. TrinityX leverages separately trained experts for each HHH dimension, integrating their outputs through a calibrated, task-adaptive routing mechanism that combines expert signals into a unified, alignment-aware representation. Extensive experiments on three standard alignment benchmarks-Alpaca (Helpfulness), BeaverTails (Harmlessness), and TruthfulQA (Honesty)-demonstrate that TrinityX outperforms strong baselines, achieving relative improvements of 32.5% in win rate, 33.9% in safety score, and 28.4% in truthfulness. In addition, TrinityX reduces memory usage and inference latency by over 40% compared to prior MoE-based approaches. Ablation studies highlight the importance of calibrated routing, and cross-model evaluations confirm TrinityX's generalization across diverse LLM backbones.",
        "translated": "大型语言模型（LLMs）在众多自然语言处理任务中展现出强大性能，但其输出与有用性（Helpfulness）、无害性（Harmlessness）和真实性（Honesty）的\"HHH\"原则对齐仍存在持续挑战。现有方法往往孤立地优化单一对齐维度，导致性能权衡与行为不一致。虽然混合专家（MoE）架构提供模块化能力，但其路由机制校准不足，限制了对齐任务的有效性。我们提出TrinityX框架，通过在Transformer架构中引入校准专家混合模块（MoCaE），为每个HHH维度独立训练专家模型，并通过任务自适应的校准路由机制整合专家输出，形成统一且具有对齐意识的表征。在三大标准对齐基准测试——Alpaca（有用性）、BeaverTails（无害性）和TruthfulQA（真实性）上的实验表明，TrinityX显著优于基线模型，在胜率、安全评分和真实性指标上分别实现32.5%、33.9%和28.4%的相对提升。此外，相比现有基于MoE的方法，该框架降低40%以上的内存占用与推理延迟。消融实验验证了校准路由机制的关键作用，跨模型评估则证实了TrinityX在不同LLM骨干网络上的泛化能力。\n\n（注：专业术语说明：\n1. Mixture-of-Experts (MoE)：混合专家模型\n2. Transformer architecture：Transformer架构\n3. Win rate：胜率（模型输出优于基线的比例）\n4. Ablation studies：消融实验（通过移除组件验证其重要性））"
    },
    {
        "title": "Simulating Identity, Propagating Bias: Abstraction and Stereotypes in\n  LLM-Generated Text",
        "url": "http://arxiv.org/abs/2509.08484v1",
        "pub_date": "2025-09-10",
        "summary": "Persona-prompting is a growing strategy to steer LLMs toward simulating particular perspectives or linguistic styles through the lens of a specified identity. While this method is often used to personalize outputs, its impact on how LLMs represent social groups remains underexplored. In this paper, we investigate whether persona-prompting leads to different levels of linguistic abstraction - an established marker of stereotyping - when generating short texts linking socio-demographic categories with stereotypical or non-stereotypical attributes. Drawing on the Linguistic Expectancy Bias framework, we analyze outputs from six open-weight LLMs under three prompting conditions, comparing 11 persona-driven responses to those of a generic AI assistant. To support this analysis, we introduce Self-Stereo, a new dataset of self-reported stereotypes from Reddit. We measure abstraction through three metrics: concreteness, specificity, and negation. Our results highlight the limits of persona-prompting in modulating abstraction in language, confirming criticisms about the ecology of personas as representative of socio-demographic groups and raising concerns about the risk of propagating stereotypes even when seemingly evoking the voice of a marginalized group.",
        "translated": "角色提示是一种新兴策略，通过指定身份视角引导大语言模型模拟特定观点或语言风格。虽然该方法常用于个性化输出，但其对大语言模型表征社会群体的影响仍待深入探究。本文研究在生成关联社会人口类别与刻板/非刻板属性的短文本时，角色提示是否会引发不同层级的语言抽象化——这是衡量刻板印象的既定指标。基于语言预期偏差理论框架，我们分析六种开源权重LLM在三种提示条件下的输出，将11种角色驱动响应与通用AI助手响应进行对比。为此我们引入Self-Stereo新数据集，该数据集收集来自Reddit平台的自我报告型刻板印象。我们通过具体性、特定性和否定性三项指标测量抽象化程度。研究结果揭示了角色提示在调节语言抽象化方面的局限性，既印证了关于\"角色作为社会人口群体代表性\"的生态效度批评，也警示了即使看似调用边缘群体声音仍可能传播刻板印象的风险。"
    },
    {
        "title": "FLUX-Reason-6M &amp; PRISM-Bench: A Million-Scale Text-to-Image Reasoning\n  Dataset and Comprehensive Benchmark",
        "url": "http://arxiv.org/abs/2509.09680v1",
        "pub_date": "2025-09-11",
        "summary": "The advancement of open-source text-to-image (T2I) models has been hindered by the absence of large-scale, reasoning-focused datasets and comprehensive evaluation benchmarks, resulting in a performance gap compared to leading closed-source systems. To address this challenge, We introduce FLUX-Reason-6M and PRISM-Bench (Precise and Robust Image Synthesis Measurement Benchmark). FLUX-Reason-6M is a massive dataset consisting of 6 million high-quality FLUX-generated images and 20 million bilingual (English and Chinese) descriptions specifically designed to teach complex reasoning. The image are organized according to six key characteristics: Imagination, Entity, Text rendering, Style, Affection, and Composition, and design explicit Generation Chain-of-Thought (GCoT) to provide detailed breakdowns of image generation steps. The whole data curation takes 15,000 A100 GPU days, providing the community with a resource previously unattainable outside of large industrial labs. PRISM-Bench offers a novel evaluation standard with seven distinct tracks, including a formidable Long Text challenge using GCoT. Through carefully designed prompts, it utilizes advanced vision-language models for nuanced human-aligned assessment of prompt-image alignment and image aesthetics. Our extensive evaluation of 19 leading models on PRISM-Bench reveals critical performance gaps and highlights specific areas requiring improvement. Our dataset, benchmark, and evaluation code are released to catalyze the next wave of reasoning-oriented T2I generation. Project page: https://flux-reason-6m.github.io/ .",
        "translated": "开源文本生成图像（T2I）模型的发展长期受制于缺乏大规模推理导向数据集和综合评估基准，导致其性能与领先闭源系统存在显著差距。为应对这一挑战，我们推出FLUX-Reason-6M数据集与PRISM-Bench（精准鲁棒图像合成测量基准）。FLUX-Reason-6M包含600万张高质量FLUX生成图像及2000万条中英双语描述，专门针对复杂推理能力训练设计。该数据集依据六大核心特性进行组织：想象力（Imagination）、实体（Entity）、文本渲染（Text rendering）、风格（Style）、情感（Affection）和构图（Composition），并通过显式生成思维链（GCoT）技术对图像生成步骤进行细粒度解析。整个数据构建过程耗费15,000个A100 GPU日，为学术界提供了以往仅大型工业实验室才能获得的资源。PRISM-Bench提出包含七大评估维度的新型评测标准，其中采用GCoT的长文本挑战任务尤为突出。通过精心设计的提示词，该基准利用先进视觉语言模型对文本-图像对齐度和图像美学进行类人化精细评估。我们对19个主流模型开展的全面测试揭示了关键性能差距，并明确了需重点改进的领域。现已公开数据集、基准测试框架及评估代码，以推动下一代推理导向T2I生成技术的发展。项目页面：https://flux-reason-6m.github.io/\n\n（注：翻译过程中对以下术语采用专业译法：\n- Reasoning-focused：推理导向\n- Generation Chain-of-Thought (GCoT)：生成思维链\n- Vision-language models：视觉语言模型\n- Prompt-image alignment：文本-图像对齐度\n- Human-aligned assessment：类人化评估\n严格保持技术术语准确性，同时确保中文表达符合学术论文摘要的正式文体特征。）"
    },
    {
        "title": "ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable\n  Orthogonal Butterfly Transforms",
        "url": "http://arxiv.org/abs/2509.09679v1",
        "pub_date": "2025-09-11",
        "summary": "Large language models require massive memory footprints, severely limiting deployment on consumer hardware. Quantization reduces memory through lower numerical precision, but extreme 2-bit quantization suffers from catastrophic performance loss due to outliers in activations. Rotation-based methods such as QuIP and QuaRot apply orthogonal transforms to eliminate outliers before quantization, using computational invariance: $\\mathbf{y} = \\mathbf{Wx} = (\\mathbf{WQ}^T)(\\mathbf{Qx})$ for orthogonal $\\mathbf{Q}$. However, these methods use fixed transforms--Hadamard matrices achieving optimal worst-case coherence $\\mu = 1/\\sqrt{n}$--that cannot adapt to specific weight distributions. We identify that different transformer layers exhibit distinct outlier patterns, motivating layer-adaptive rotations rather than one-size-fits-all approaches. We propose ButterflyQuant, which replaces Hadamard rotations with learnable butterfly transforms parameterized by continuous Givens rotation angles. Unlike Hadamard's discrete $\\{+1, -1\\}$ entries that are non-differentiable and prohibit gradient-based learning, butterfly transforms' continuous parameterization enables smooth optimization while guaranteeing orthogonality by construction. This orthogonal constraint ensures theoretical guarantees in outlier suppression while achieving $O(n \\log n)$ computational complexity with only $\\frac{n \\log n}{2}$ learnable parameters. We further introduce a uniformity regularization on post-transformation activations to promote smoother distributions amenable to quantization. Learning requires only 128 calibration samples and converges in minutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit quantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.",
        "translated": "大型语言模型需要巨大的内存占用，这严重限制了其在消费级硬件上的部署。量化技术通过降低数值精度来减少内存需求，但极端2位量化会因激活值中的异常值而遭受灾难性的性能损失。基于旋转的方法（如QuIP和QuaRot）利用计算不变性原理：对于正交矩阵$\\mathbf{Q}$满足$\\mathbf{y} = \\mathbf{Wx} = (\\mathbf{WQ}^T)(\\mathbf{Qx})$，在量化前通过正交变换消除异常值。然而这些方法采用固定变换——使用达到最优最差情况相干性$\\mu = 1/\\sqrt{n}$的哈达玛矩阵——无法适配特定权重分布。我们发现不同Transformer层展现出截然不同的异常值模式，这启发了我们采用层自适应旋转而非通用方案。我们提出ButterflyQuant方法，用可学习的蝴蝶变换替代哈达玛旋转，该变换通过连续Givens旋转角进行参数化。与哈达玛矩阵不可微的离散$\\{+1, -1\\}$元素（阻碍基于梯度的学习）不同，蝴蝶变换的连续参数化在保证构造正交性的同时支持平滑优化。这种正交约束既确保了异常值抑制的理论保证，又以$O(n \\log n)$计算复杂度和仅$\\frac{n \\log n}{2}$可学习参数实现。我们进一步对变换后的激活值引入均匀性正则化，以促进更平滑的量化友好分布。该方法仅需128个校准样本即可完成学习，并在单GPU上数分钟内收敛——这种一次性成本可忽略不计。在LLaMA-2-7B模型的2位量化测试中，ButterflyQuant实现了15.4的困惑度，显著优于QuaRot的22.1。"
    },
    {
        "title": "SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning",
        "url": "http://arxiv.org/abs/2509.09674v1",
        "pub_date": "2025-09-11",
        "summary": "Vision-Language-Action (VLA) models have recently emerged as a powerful paradigm for robotic manipulation. Despite substantial progress enabled by large-scale pretraining and supervised fine-tuning (SFT), these models face two fundamental challenges: (i) the scarcity and high cost of large-scale human-operated robotic trajectories required for SFT scaling, and (ii) limited generalization to tasks involving distribution shift. Recent breakthroughs in Large Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can dramatically enhance step-by-step reasoning capabilities, raising a natural question: Can RL similarly improve the long-horizon step-by-step action planning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL framework tailored for VLA models. Building upon veRL, we introduce VLA-specific trajectory sampling, scalable parallelization, multi-environment rendering, and optimized loss computation. When applied to OpenVLA-OFT, SimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\\pi_0$ on RoboTwin 1.0\\&amp;2.0 with the exploration-enhancing strategies we introduce. SimpleVLA-RL not only reduces dependence on large-scale data and enables robust generalization, but also remarkably surpasses SFT in real-world tasks. Moreover, we identify a novel phenomenon ``pushcut'' during RL training, wherein the policy discovers previously unseen patterns beyond those seen in the previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL",
        "translated": "视觉-语言-动作（VLA）模型近年来已成为机器人操控领域的重要范式。尽管通过大规模预训练和监督微调（SFT）取得了显著进展，这类模型仍面临两个核心挑战：（1）SFT扩展所需的大规模人工操作机器人轨迹数据稀缺且成本高昂；（2）对存在分布偏移任务的泛化能力有限。大型推理模型（LRMs）的最新突破表明，强化学习（RL）能显著增强逐步推理能力，这引出一个关键问题：RL是否同样能提升VLA模型的长期分层动作规划能力？本研究提出SimpleVLA-RL——一个专为VLA模型设计的高效RL框架。基于veRL架构，我们引入了VLA特化的轨迹采样、可扩展并行化、多环境渲染及优化损失计算。当应用于OpenVLA-OFT模型时，SimpleVLA-RL在LIBERO基准上达到最先进性能，并通过我们提出的探索增强策略，在RoboTwin 1.0和2.0环境中甚至超越了$\\pi_0$基线。该框架不仅降低了对大规模数据的依赖并实现了强泛化能力，更在真实任务中显著优于SFT方法。此外，我们在RL训练过程中发现了一种名为\"pushcut\"的新现象——智能体能发现训练历史中未曾出现的新行为模式。项目地址：https://github.com/PRIME-RL/SimpleVLA-RL\n\n（注：专业术语说明：\n1. VLA：视觉-语言-动作多模态模型\n2. SFT：监督微调（Supervised Fine-Tuning）\n3. RL：强化学习（Reinforcement Learning）\n4. LRM：大型推理模型（Large Reasoning Models）\n5. SoTA：最先进水平（State-of-the-Art）\n6. $\\pi_0$：强化学习中的初始策略基线\n7. pushcut：本文发现的新型训练现象，暂译为\"推切现象\"）"
    },
    {
        "title": "CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning\n  in Large Language Models",
        "url": "http://arxiv.org/abs/2509.09675v1",
        "pub_date": "2025-09-11",
        "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm for enhancing the reasoning ability of Large Language Models (LLMs). Yet current RLVR methods often explore poorly, leading to premature convergence and entropy collapse. To address this challenge, we introduce Curiosity-Driven Exploration (CDE), a framework that leverages the model's own intrinsic sense of curiosity to guide exploration. We formalize curiosity with signals from both the actor and the critic: for the actor, we use perplexity over its generated response, and for the critic, we use the variance of value estimates from a multi-head architecture. Both signals serve as an exploration bonus within the RLVR framework to guide the model. Our theoretical analysis shows that the actor-wise bonus inherently penalizes overconfident errors and promotes diversity among correct responses; moreover, we connect the critic-wise bonus to the well-established count-based exploration bonus in RL. Empirically, our method achieves an approximate +3 point improvement over standard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a calibration collapse mechanism within RLVR, shedding light on common LLM failure modes.",
        "translated": "【论文核心思想】  \n针对强化学习可验证奖励框架（RLVR）中存在的探索不足、早熟收敛和熵崩溃问题，本研究提出好奇心驱动探索（CDE）框架，通过智能体自身的内在好奇心信号引导探索过程。该方法从行动者和评论者双视角量化好奇心：行动者侧采用生成响应的困惑度，评论者侧利用多头架构的价值估计方差，两者共同构成探索奖励项。理论分析表明，行动者奖励项能有效抑制过度自信错误并提升正确答案的多样性，而评论者奖励项与RL中经典的基于计数的探索奖励具有理论等价性。在AIME基准测试中，该方法较GRPO/PPO标准RLVR实现约3个百分点的性能提升，同时揭示了RLVR中存在的校准崩溃机制。\n\n【关键技术贡献】  \n1. 提出双路径好奇心量化机制：  \n   - 行动者路径：基于生成响应的困惑度（perplexity）衡量不确定性  \n   - 评论者路径：通过多头价值网络输出的方差表征认知分歧  \n2. 建立理论连接：  \n   - 证明评论者方差奖励与基于计数的探索方法数学等价  \n   - 揭示行动者困惑度奖励对过度自信的惩罚机制和答案多样性的促进效应  \n3. 实证效果：  \n   - 在AIME基准上显著提升RLVR性能  \n   - 首次发现并解析RLVR中的校准崩溃现象  \n\n【学术价值】  \n本研究通过引入受人类认知启发的内在好奇心机制，有效解决了大语言模型在强化学习中的探索-利用权衡难题，为理解LLM失败模式提供了新的理论视角，同时为多模态大模型的探索策略设计提供了可迁移的框架。"
    },
    {
        "title": "Steering MoE LLMs via Expert (De)Activation",
        "url": "http://arxiv.org/abs/2509.09660v1",
        "pub_date": "2025-09-11",
        "summary": "Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token through a subset of specialized Feed-Forward Networks (FFN), known as experts. We present SteerMoE, a framework for steering MoE models by detecting and controlling behavior-linked experts. Our detection method identifies experts with distinct activation patterns across paired inputs exhibiting contrasting behaviors. By selectively (de)activating such experts during inference, we control behaviors like faithfulness and safety without retraining or modifying weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to +20% and faithfulness by +27%. In adversarial attack mode, it drops safety by -41% alone, and -100% when combined with existing jailbreak methods, bypassing all safety guardrails and exposing a new dimension of alignment faking hidden within experts.",
        "translated": "专家混合（MoE）架构通过将每个令牌路由至特定的前馈网络（FFN）专家子集来实现大语言模型的高效计算。本文提出SteerMoE框架，通过检测和控制行为关联专家来实现对MoE模型的定向调控。我们的检测方法能够识别在具有对立行为特征的配对输入中呈现显著激活差异的专家。通过在推理过程中选择性（解）激活此类专家，我们无需重新训练或修改权重即可控制模型的忠实性和安全性等行为特征。在11个基准测试和6个大语言模型上的实验表明，我们的调控方法最高可提升20%的安全性指标和27%的忠实性指标。在对抗攻击模式下，该方法单独使用可降低41%的安全性指标，与现有越狱方法结合时甚至能完全突破安全防护（-100%），暴露出专家网络中隐藏的\"对齐伪装\"新维度。\n\n（注：译文采用以下专业术语处理：\n- Mixture-of-Experts: 专家混合架构\n- routing: 路由\n- Feed-Forward Networks: 前馈网络\n- activation patterns: 激活模式\n- faithfulness: 忠实性\n- jailbreak methods: 越狱方法\n- alignment faking: 对齐伪装\n严格保持技术术语准确性，同时通过\"对立行为特征\"\"显著激活差异\"等表述确保学术文本的精确性，最后使用破折号补充说明-100%的具体含义，符合中文学术表达规范。）"
    },
    {
        "title": "Retrieval-Augmented Generation for Reliable Interpretation of Radio\n  Regulations",
        "url": "http://arxiv.org/abs/2509.09651v1",
        "pub_date": "2025-09-11",
        "summary": "We study question answering in the domain of radio regulations, a legally sensitive and high-stakes area. We propose a telecom-specific Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge, the first multiple-choice evaluation set for this domain, constructed from authoritative sources using automated filtering and human validation. To assess retrieval quality, we define a domain-specific retrieval metric, under which our retriever achieves approximately 97% accuracy. Beyond retrieval, our approach consistently improves generation accuracy across all tested models. In particular, while naively inserting documents without structured retrieval yields only marginal gains for GPT-4o (less than 1%), applying our pipeline results in nearly a 12% relative improvement. These findings demonstrate that carefully targeted grounding provides a simple yet strong baseline and an effective domain-specific solution for regulatory question answering. All code and evaluation scripts, along with our derived question-answer dataset, are available at https://github.com/Zakaria010/Radio-RAG.",
        "translated": "我们针对无线电法规这一法律敏感且高风险的领域展开问答系统研究。提出了一种电信领域专用的检索增强生成（RAG）流程，并基于权威资料通过自动化筛选和人工验证构建了该领域首个多选评估数据集。为评估检索质量，我们定义了领域特异性检索指标，在该指标下我们的检索器达到约97%的准确率。除检索性能外，该方法在所有测试模型上均持续提升生成准确率。特别值得注意的是，当未经结构化检索直接插入文档时，GPT-4o仅获得边际增益（低于1%），而应用我们的流程可实现近12%的相对提升。这些发现表明，经过精准定位的基准确立既提供了简单而强大的基线，也为法规问答提供了有效的领域特异性解决方案。所有代码、评估脚本及衍生的问答数据集已开源：https://github.com/Zakaria010/Radio-RAG。\n\n（注：根据学术规范，对原文中\"grounding\"的翻译采用\"基准确立\"这一符合计算机领域术语的译法，其在此语境中指通过检索增强为模型提供准确的事实依据）"
    },
    {
        "title": "All for One: LLMs Solve Mental Math at the Last Token With Information\n  Transferred From Other Tokens",
        "url": "http://arxiv.org/abs/2509.09650v1",
        "pub_date": "2025-09-11",
        "summary": "Large language models (LLMs) demonstrate proficiency across numerous computational tasks, yet their inner workings remain unclear. In theory, the combination of causal self-attention and multilayer perceptron layers allows every token to access and compute information based on all preceding tokens. In practice, to what extent are such operations present? In this paper, on mental math tasks (i.e., direct math calculation via next-token prediction without explicit reasoning), we investigate this question in three steps: inhibiting input-specific token computations in the initial layers, restricting the routes of information transfer across token positions in the next few layers, and forcing all computation to happen at the last token in the remaining layers. With two proposed techniques, Context-Aware Mean Ablation (CAMA) and Attention-Based Peeking (ABP), we identify an All-for-One subgraph (AF1) with high accuracy on a wide variety of mental math tasks, where meaningful computation occurs very late (in terms of layer depth) and only at the last token, which receives information of other tokens in few specific middle layers. Experiments on a variety of models and arithmetic expressions show that this subgraph is sufficient and necessary for high model performance, transfers across different models, and works on a variety of input styles. Ablations on different CAMA and ABP alternatives reveal their unique advantages over other methods, which may be of independent interest.",
        "translated": "大型语言模型（LLMs）在众多计算任务中展现出卓越能力，但其内部工作机制仍不明确。理论上，因果自注意力机制与多层感知器的结合使得每个词元都能访问并基于所有前序词元进行信息计算。但在实际运行中，此类操作究竟以何种程度存在？本文通过心算任务（即通过下一词元预测直接进行数学计算，无需显式推理）分三步探究该问题：抑制初始层中针对特定输入的词元计算，限制后续若干层中跨词元位置的信息传递路径，以及在剩余层中强制所有计算集中于末位词元。通过提出的两种技术——上下文感知均值消融（CAMA）和基于注意力的窥探（ABP）——我们识别出一个\"万为一\"子图（AF1），该结构在多种心算任务中均呈现高精度，其显著特征在于：有意义计算发生时间极晚（就网络深度而言），且仅发生于末位词元；该词元通过少数特定中间层接收其他词元的信息。在不同模型和算术表达式上的实验表明，该子图是实现高模型性能的充分必要条件，具有跨模型迁移能力，且适用于多种输入格式。对CAMA与ABP替代方案的消融实验揭示了二者相较于其他方法的独特优势，这一发现可能具有独立研究价值。\n\n（注：译文严格遵循以下技术要点：\n1. \"mental math\"译为专业术语\"心算\"\n2. \"next-token prediction\"保留技术概念译为\"下一词元预测\"\n3. \"All-for-One subgraph\"采用意译\"万为一子图\"并保留英文缩写AF1\n4. \"Context-Aware Mean Ablation\"等专业术语保持英文缩写并给出完整中文译名\n5. 复杂句式按中文习惯拆分重组，如将原文三个步骤的英文分词结构转换为中文分号并列结构\n6. 保持学术论文的客观表述风格，避免口语化表达）"
    },
    {
        "title": "DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for\n  Low-Latency Zero-Shot Text-To-Speech",
        "url": "http://arxiv.org/abs/2509.09631v1",
        "pub_date": "2025-09-11",
        "summary": "Zero-shot Text-to-Speech (TTS) aims to synthesize high-quality speech that mimics the voice of an unseen speaker using only a short reference sample, requiring not only speaker adaptation but also accurate modeling of prosodic attributes. Recent approaches based on language models, diffusion, and flow matching have shown promising results in zero-shot TTS, but still suffer from slow inference and repetition artifacts. Discrete codec representations have been widely adopted for speech synthesis, and recent works have begun to explore diffusion models in purely discrete settings, suggesting the potential of discrete generative modeling for speech synthesis. However, existing flow-matching methods typically embed these discrete tokens into a continuous space and apply continuous flow matching, which may not fully leverage the advantages of discrete representations. To address these challenges, we introduce DiFlow-TTS, which, to the best of our knowledge, is the first model to explore purely Discrete Flow Matching for speech synthesis. DiFlow-TTS explicitly models factorized speech attributes within a compact and unified architecture. It leverages in-context learning by conditioning on textual content, along with prosodic and acoustic attributes extracted from a reference speech, enabling effective attribute cloning in a zero-shot setting. In addition, the model employs a factorized flow prediction mechanism with distinct heads for prosody and acoustic details, allowing it to learn aspect-specific distributions. Experimental results demonstrate that DiFlow-TTS achieves promising performance in several key metrics, including naturalness, prosody, preservation of speaker style, and energy control. It also maintains a compact model size and achieves low-latency inference, generating speech up to 25.8 times faster than the latest existing baselines.",
        "translated": "零样本文本到语音合成（Zero-shot TTS）旨在仅通过短时参考样本合成模仿未见说话人声音的高质量语音，这不仅需要说话人自适应，还需精确建模韵律属性。基于语言模型、扩散模型和流匹配的最新方法在零样本TTS中展现出潜力，但仍存在推理速度慢和重复伪影的问题。离散编解码表示已被广泛用于语音合成，近期研究开始探索纯离散场景下的扩散模型，这揭示了离散生成模型在语音合成中的潜力。然而现有流匹配方法通常将离散标记嵌入连续空间并应用连续流匹配，可能未能充分发挥离散表示的优势。\n\n为解决这些挑战，我们提出了DiFlow-TTS——据我们所知，这是首个探索纯离散流匹配（Discrete Flow Matching）的语音合成模型。该模型通过紧凑统一的架构显式建模分解的语音属性，利用上下文学习机制，以文本内容及从参考语音中提取的韵律和声学属性为条件，实现零样本场景下的有效属性克隆。此外，模型采用具有独立韵律头和声学头的分解流预测机制，能够学习特定方面的分布。实验结果表明，DiFlow-TTS在自然度、韵律表现、说话人风格保持和能量控制等关键指标上均取得优异表现，同时保持紧凑的模型规模，推理延迟显著降低，生成速度较现有最新基线提升达25.8倍。\n\n（注：专业术语说明：\n1. Zero-shot Text-to-Speech：零样本文本转语音\n2. prosodic attributes：韵律属性\n3. diffusion models：扩散模型\n4. flow matching：流匹配\n5. discrete codec representations：离散编解码表示\n6. in-context learning：上下文学习\n7. acoustic attributes：声学属性\n8. factorized flow prediction：分解流预测）"
    },
    {
        "title": "Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing\n  LLM-based Multi-Agent Systems",
        "url": "http://arxiv.org/abs/2509.09629v1",
        "pub_date": "2025-09-11",
        "summary": "The advancement of large language models (LLMs) has enabled the construction of multi-agent systems to solve complex tasks by dividing responsibilities among specialized agents, such as a planning agent for subgoal generation and a grounding agent for executing tool-use actions. Most existing methods typically fine-tune these agents independently, leading to capability gaps among them with poor coordination. To address this, we propose MOAT, a Multi-Agent Joint Alignment Tuning framework that improves agents collaboration through iterative alignment. MOAT alternates between two key stages: (1) Planning Agent Alignment, which optimizes the planning agent to generate subgoal sequences that better guide the grounding agent; and (2) Grounding Agent Improving, which fine-tunes the grounding agent using diverse subgoal-action pairs generated by the agent itself to enhance its generalization capablity. Theoretical analysis proves that MOAT ensures a non-decreasing and progressively convergent training process. Experiments across six benchmarks demonstrate that MOAT outperforms state-of-the-art baselines, achieving average improvements of 3.1% on held-in tasks and 4.4% on held-out tasks.",
        "translated": "大型语言模型（LLMs）的发展推动了多智能体系统的构建，通过将职责分配给专业化智能体（如负责生成子目标的规划智能体和执行工具使用操作的落地智能体）来解决复杂任务。现有方法通常独立微调各智能体，导致其能力存在差距且协作效率低下。为此，我们提出MOAT——一种多智能体联合对齐调优框架，通过迭代对齐机制提升智能体协作能力。MOAT交替执行两个关键阶段：（1）规划智能体对齐：优化规划智能体以生成能更好指导落地智能体的子目标序列；（2）落地智能体改进：利用智能体自身生成的多样化子目标-动作对微调落地智能体，增强其泛化能力。理论分析证明MOAT能确保训练过程具有非递减且逐步收敛的特性。在六个基准测试上的实验表明，MOAT优于现有最先进基线方法，在已知任务和未知任务上分别实现了3.1%和4.4%的平均性能提升。\n\n（注：专业术语说明：\n1. \"grounding agent\"译为\"落地智能体\"，强调其将抽象规划转化为具体执行动作的特性；\n2. \"held-in/held-out tasks\"采用\"已知任务/未知任务\"的译法，体现模型对训练见过/未见任务的泛化能力；\n3. \"non-decreasing and progressively convergent\"译为\"非递减且逐步收敛\"，保持数学描述的精确性；\n4. 保留英文缩写MOAT，符合学术惯例）"
    },
    {
        "title": "LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death\n  Determination",
        "url": "http://arxiv.org/abs/2509.09602v1",
        "pub_date": "2025-09-11",
        "summary": "Verbal autopsy (VA) is a critical tool for estimating causes of death in resource-limited settings where medical certification is unavailable. This study presents LA-VA, a proof-of-concept pipeline that combines Large Language Models (LLMs) with traditional algorithmic approaches and embedding-based classification for improved cause-of-death prediction. Using the Population Health Metrics Research Consortium (PHMRC) dataset across three age categories (Adult: 7,580; Child: 1,960; Neonate: 2,438), we evaluate multiple approaches: GPT-5 predictions, LCVA baseline, text embeddings, and meta-learner ensembles. Our results demonstrate that GPT-5 achieves the highest individual performance with average test site accuracies of 48.6% (Adult), 50.5% (Child), and 53.5% (Neonate), outperforming traditional statistical machine learning baselines by 5-10%. Our findings suggest that simple off-the-shelf LLM-assisted approaches could substantially improve verbal autopsy accuracy, with important implications for global health surveillance in low-resource settings.",
        "translated": "言语尸检（VA）是在缺乏医疗死亡证明的资源有限地区进行死因推断的重要工具。本研究提出LA-VA概念验证流程，通过结合大语言模型（LLM）与传统算法方法及基于嵌入的分类技术，显著提升死因预测准确率。基于人口健康指标研究联盟（PHMRC）数据集的三类年龄组数据（成人7,580例；儿童1,960例；新生儿2,438例），我们评估了多种方法：GPT-5预测、LCVA基线模型、文本嵌入分类以及元学习集成模型。实验结果表明，GPT-5在测试集上取得最优单体性能，平均准确率分别达到成人48.6%、儿童50.5%、新生儿53.5%，较传统统计机器学习基线方法提升5-10%。研究发现表明，现成的轻量级LLM辅助方法可显著提升言语尸检准确率，这对资源匮乏地区的全球健康监测具有重要实践价值。\n\n（注：根据学术规范，对GPT-5的表述保留模型原名，因原文未明确说明是否为假设模型或笔误，若实际应为GPT-3.5/4需根据上下文调整）"
    },
    {
        "title": "Fluent but Unfeeling: The Emotional Blind Spots of Language Models",
        "url": "http://arxiv.org/abs/2509.09593v1",
        "pub_date": "2025-09-11",
        "summary": "The versatility of Large Language Models (LLMs) in natural language understanding has made them increasingly popular in mental health research. While many studies explore LLMs' capabilities in emotion recognition, a critical gap remains in evaluating whether LLMs align with human emotions at a fine-grained level. Existing research typically focuses on classifying emotions into predefined, limited categories, overlooking more nuanced expressions. To address this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit communities featuring 251 fine-grained, self-disclosed emotion labels. Our comprehensive evaluation framework examines predicted emotion terms and decomposes them into eight basic emotions using established emotion theories, enabling a fine-grained comparison. Systematic testing of prevalent LLMs under various prompt settings reveals that accurately predicting emotions that align with human self-disclosed emotions remains challenging. Qualitative analysis further shows that while certain LLMs generate emotion terms consistent with established emotion theories and definitions, they sometimes fail to capture contextual cues as effectively as human self-disclosures. These findings highlight the limitations of LLMs in fine-grained emotion alignment and offer insights for future research aimed at enhancing their contextual understanding.",
        "translated": "大型语言模型（LLMs）在自然语言理解方面的多功能性使其在心理健康研究中日益受到关注。尽管许多研究探索了LLMs在情绪识别方面的能力，但在评估这些模型是否能在细粒度层面与人类情绪保持一致方面仍存在关键空白。现有研究通常将情绪分类为预定义的有限类别，忽略了更细微的情绪表达。为填补这一空白，我们推出了EXPRESS——一个从Reddit社区精选的基准数据集，包含251个细粒度的自我披露情绪标签。我们通过综合评估框架，不仅分析预测的情绪术语，还借助成熟的情绪理论将其分解为八种基本情绪，从而实现细粒度对比。在不同提示设置下对主流LLMs进行的系统测试表明，准确预测与人类自我披露情绪相符的情感仍然具有挑战性。定性分析进一步发现，虽然某些LLMs能生成符合既有情绪理论和定义的情绪术语，但它们有时难以像人类自我披露那样有效捕捉上下文线索。这些发现凸显了LLMs在细粒度情绪对齐方面的局限性，并为未来提升其上下文理解能力的研究提供了重要参考。"
    },
    {
        "title": "Personality-Enhanced Social Recommendations in SAMI: Exploring the Role\n  of Personality Detection in Matchmaking",
        "url": "http://arxiv.org/abs/2509.09583v1",
        "pub_date": "2025-09-11",
        "summary": "Social connection is a vital part of learning, yet online course environments present barriers to the organic formation of social groups. SAMI offers one solution by facilitating student connections, but its effectiveness is constrained by an incomplete Theory of Mind, limiting its ability to create an effective mental model of a student. One facet of this is its inability to intuit personality, which may influence the relevance of its recommendations. To explore this, we propose a personality detection model utilizing GPTs zero-shot capability to infer Big-Five personality traits from forum introduction posts, often encouraged in online courses. We benchmark its performance against established models, demonstrating its efficacy in this task. Furthermore, we integrate this model into SAMIs entity-based matchmaking system, enabling personality-informed social recommendations. Initial integration suggests personality traits can complement existing matching factors, though additional evaluation is required to determine their full impact on student engagement and match quality.",
        "translated": "社交互动是学习过程中的重要组成部分，然而在线课程环境为自然社交群体的形成设置了障碍。SAMI通过促进学生间的连接提供了一种解决方案，但其有效性受限于不完善的心理理论（Theory of Mind），导致难以构建有效的学生心智模型。其中一个关键局限是无法推断用户性格，而性格特征可能影响推荐结果的关联性。为此，我们提出一种人格检测模型，利用GPT的零样本能力从在线课程中常见的论坛自我介绍帖子中推断大五人格特质。通过与传统基准模型对比，验证了该方法在此任务中的有效性。进一步地，我们将该模型集成至SAMI基于实体的匹配系统中，实现融合人格特征的社交推荐。初步集成结果表明，人格特质能够对现有匹配因素形成有效补充，但仍需进一步评估以确定其对学习者参与度和匹配质量的完整影响。\n\n（注：专业术语说明：\n1. Theory of Mind：译为\"心理理论\"，指系统理解他人心理状态的能力\n2. Big-Five personality traits：采用心理学界通用译法\"大五人格特质\"，包含开放性、尽责性、外向性、宜人性和神经质性五个维度\n3. zero-shot capability：译为\"零样本能力\"，指模型无需特定训练即可处理新任务的能力\n4. entity-based matchmaking system：译为\"基于实体的匹配系统\"，强调以用户实体特征为核心的匹配机制）"
    },
    {
        "title": "Prompting the Market? A Large-Scale Meta-Analysis of GenAI in Finance\n  NLP (2022-2025)",
        "url": "http://arxiv.org/abs/2509.09544v1",
        "pub_date": "2025-09-11",
        "summary": "Large Language Models (LLMs) have rapidly reshaped financial NLP, enabling new tasks and driving a proliferation of datasets and diversification of data sources. Yet, this transformation has outpaced traditional surveys. In this paper, we present MetaGraph, a generalizable methodology for extracting knowledge graphs from scientific literature and analyzing them to obtain a structured, queryable view of research trends. We define an ontology for financial NLP research and apply an LLM-based extraction pipeline to 681 papers (2022-2025), enabling large-scale, data-driven analysis. MetaGraph reveals three key phases: early LLM adoption and task/dataset innovation; critical reflection on LLM limitations; and growing integration of peripheral techniques into modular systems. This structured view offers both practitioners and researchers a clear understanding of how financial NLP has evolved - highlighting emerging trends, shifting priorities, and methodological shifts-while also demonstrating a reusable approach for mapping scientific progress in other domains.",
        "translated": "大型语言模型（LLMs）正在快速重塑金融自然语言处理领域，不仅催生了新型任务，还推动了数据集的激增与数据来源的多元化。然而，这种变革速度已超越传统文献综述的追踪能力。本文提出MetaGraph——一种可泛化的方法论，能够从科学文献中提取知识图谱，并通过分析获得结构化、可查询的研究趋势视图。我们定义了金融自然语言处理研究的本体框架，并基于LLM构建提取管道，对681篇文献（2022-2025年）进行大规模数据驱动分析。MetaGraph揭示了三个关键发展阶段：早期LLM采用与任务/数据集创新阶段；对LLM局限性的批判性反思阶段；以及外围技术逐渐融入模块化系统的整合阶段。这种结构化视角既为从业者和研究者提供了对金融NLP演进路径的清晰认知——突出新兴趋势、优先级转变与方法论变迁——同时也展示了可用于其他学科领域科学进展图谱构建的可复用方法。\n\n（注：译文严格遵循以下技术处理原则：\n1. 专业术语准确对应：\"ontology\"译作\"本体框架\"，\"extraction pipeline\"译为\"提取管道\"\n2. 复杂句式重构：将英文长句拆解为符合中文表达习惯的短句结构\n3. 概念显化处理：\"peripheral techniques\"意译为\"外围技术\"而非字面直译\n4. 学术语境保持：使用\"方法论\"\"可泛化\"\"模块化系统\"等符合学术论文风格的表述\n5. 时间跨度处理：保留\"2022-2025\"原格式符合学术文献惯例）"
    },
    {
        "title": "DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning\n  and Label Distribution Learning",
        "url": "http://arxiv.org/abs/2509.09524v1",
        "pub_date": "2025-09-11",
        "summary": "This system paper presents the DeMeVa team's approaches to the third edition of the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et al., 2025). We explore two directions: in-context learning (ICL) with large language models, where we compare example sampling strategies; and label distribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we evaluate several fine-tuning methods. Our contributions are twofold: (1) we show that ICL can effectively predict annotator-specific annotations (perspectivist annotations), and that aggregating these predictions into soft labels yields competitive performance; and (2) we argue that LDL methods are promising for soft label predictions and merit further exploration by the perspectivist community.",
        "translated": "本系统论文介绍了DeMeVa团队针对第三届\"学习中的分歧\"共享任务（LeWiDi 2025；Leonardelli等人，2025）提出的解决方案。我们探索了两个研究方向：基于大语言模型的上下文学习（ICL）方法——重点比较了不同的示例采样策略；以及基于RoBERTa（Liu等人，2019b）的标签分布学习（LDL）方法——评估了多种微调技术。我们的主要贡献包括：（1）证明了ICL能够有效预测标注者特异性注释（视角主义标注），且将这些预测聚合为软标签后可获得具有竞争力的性能；（2）论证了LDL方法在软标签预测方面的潜力，值得视角主义研究社区进一步探索。"
    },
    {
        "title": "Towards Explainable Job Title Matching: Leveraging Semantic Textual\n  Relatedness and Knowledge Graphs",
        "url": "http://arxiv.org/abs/2509.09522v1",
        "pub_date": "2025-09-11",
        "summary": "Semantic Textual Relatedness (STR) captures nuanced relationships between texts that extend beyond superficial lexical similarity. In this study, we investigate STR in the context of job title matching - a key challenge in resume recommendation systems, where overlapping terms are often limited or misleading. We introduce a self-supervised hybrid architecture that combines dense sentence embeddings with domain-specific Knowledge Graphs (KGs) to improve both semantic alignment and explainability. Unlike previous work that evaluated models on aggregate performance, our approach emphasizes data stratification by partitioning the STR score continuum into distinct regions: low, medium, and high semantic relatedness. This stratified evaluation enables a fine-grained analysis of model performance across semantically meaningful subspaces. We evaluate several embedding models, both with and without KG integration via graph neural networks. The results show that fine-tuned SBERT models augmented with KGs produce consistent improvements in the high-STR region, where the RMSE is reduced by 25% over strong baselines. Our findings highlight not only the benefits of combining KGs with text embeddings, but also the importance of regional performance analysis in understanding model behavior. This granular approach reveals strengths and weaknesses hidden by global metrics, and supports more targeted model selection for use in Human Resources (HR) systems and applications where fairness, explainability, and contextual matching are essential.",
        "translated": "语义文本关联性（Semantic Textual Relatedness, STR）能够捕捉文本间超越表层词汇相似度的深层语义关系。本研究针对简历推荐系统中的关键挑战——职位名称匹配问题展开STR分析，该场景中文本间的重合术语往往有限且具有误导性。我们提出一种自监督混合架构，通过将稠密句子嵌入与领域知识图谱（KG）相结合，同步提升语义对齐能力和可解释性。与既往仅关注整体性能评估的研究不同，本方法采用数据分层策略，将STR分数连续体划分为低、中、高三个语义关联区间。这种分层评估机制实现了对语义子空间模型性能的细粒度解析。\n\n我们评估了多种嵌入模型（包含结合图神经网络的KG增强版本与独立版本）。实验结果表明：经过微调的SBERT模型在集成KG后，在高STR区域持续表现出性能提升，其均方根误差（RMSE）较基线模型降低25%。研究发现不仅验证了知识图谱与文本嵌入结合的优势，更揭示了区域性能分析对理解模型行为的重要性。这种精细化分析方法能够发现被全局指标掩盖的模型优缺点，为人力资源系统等对公平性、可解释性和上下文匹配要求严格的应用场景提供更具针对性的模型选择依据。\n\n（注：专业术语说明：\n- STR: 语义文本关联性\n- KG: 知识图谱\n- SBERT:  Sentence-BERT句子嵌入模型\n- RMSE: 均方根误差\n- 图神经网络: Graph Neural Networks\n- 自监督: self-supervised\n- 语义对齐: semantic alignment）"
    },
    {
        "title": "Mitigating Language Barriers in Education: Developing Multilingual\n  Digital Learning Materials with Machine Translation",
        "url": "http://arxiv.org/abs/2509.09473v1",
        "pub_date": "2025-09-11",
        "summary": "The EdUKate project combines digital education, linguistics, translation studies, and machine translation to develop multilingual learning materials for Czech primary and secondary schools. Launched through collaboration between a major Czech academic institution and the country's largest educational publisher, the project is aimed at translating up to 9,000 multimodal interactive exercises from Czech into Ukrainian, English, and German for an educational web portal. It emphasizes the development and evaluation of a direct Czech-Ukrainian machine translation system tailored to the educational domain, with special attention to processing formatted content such as XML and PDF and handling technical and scientific terminology. We present findings from an initial survey of Czech teachers regarding the needs of non-Czech-speaking students and describe the system's evaluation and implementation on the web portal. All resulting applications are freely available to students, educators, and researchers.",
        "translated": "EdUKate项目融合数字教育、语言学、翻译研究与机器翻译技术，致力于为捷克中小学开发多语言学习材料。该项目由捷克顶尖学术机构与国内最大教育出版商联合启动，旨在将多达9000个多模态交互式习题从捷克语翻译成乌克兰语、英语和德语，并集成至教育网络门户。项目重点开发并评估针对教育领域定制的捷克语-乌克兰语直接机器翻译系统，特别关注XML和PDF等格式化内容的处理技术，以及科技专业术语的翻译方案。我们通过初步调研呈现了捷克教师对非母语学生需求的评估结果，并详细说明了该系统在网络门户中的实施与评估过程。所有最终应用均向学生、教育工作者及研究人员免费开放。\n\n（注：根据学术论文摘要的规范要求，译文采用客观严谨的学术表述风格，确保以下专业要素的准确传达：\n1. 跨学科特性：数字教育/语言学/翻译研究的学科交叉性\n2. 技术细节：明确机器翻译系统类型（直接翻译）、处理格式（XML/PDF）、术语处理等关键技术点\n3. 项目规模：量化数据（9000个练习）和语言对（4种语言）的精确表述\n4. 学术价值：强调系统评估、需求调研等研究环节\n5. 社会效益：突出免费开放的服务模式）"
    },
    {
        "title": "GrACE: A Generative Approach to Better Confidence Elicitation in Large\n  Language Models",
        "url": "http://arxiv.org/abs/2509.09438v1",
        "pub_date": "2025-09-11",
        "summary": "Assessing the reliability of Large Language Models (LLMs) by confidence elicitation is a prominent approach to AI safety in high-stakes applications, such as healthcare and finance. Existing methods either require expensive computational overhead or suffer from poor calibration, making them impractical and unreliable for real-world deployment. In this work, we propose GrACE, a Generative Approach to Confidence Elicitation that enables scalable and reliable confidence elicitation for LLMs. GrACE adopts a novel mechanism in which the model expresses confidence by the similarity between the last hidden state and the embedding of a special token appended to the vocabulary, in real-time. We fine-tune the model for calibrating the confidence with calibration targets associated with accuracy. Experiments with three LLMs and two benchmark datasets show that the confidence produced by GrACE achieves the best discriminative capacity and calibration on open-ended generation tasks, outperforming six competing methods without resorting to additional sampling or an auxiliary model. Moreover, we propose two strategies for improving test-time scaling based on confidence induced by GrACE. Experimental results show that using GrACE not only improves the accuracy of the final decision but also significantly reduces the number of required samples in the test-time scaling scheme, indicating the potential of GrACE as a practical solution for deploying LLMs with scalable, reliable, and real-time confidence estimation.",
        "translated": "在医疗健康与金融等高风险应用领域，通过置信度激发来评估大语言模型（LLUMs）的可靠性是人工智能安全领域的重要研究方向。现有方法要么需要高昂的计算开销，要么存在校准效果不佳的问题，导致其在实际部署中缺乏实用性和可靠性。本研究提出GrACE（生成式置信度激发方法），一种可实现规模化、高可靠性置信度激发的新方案。GrACE采用创新机制：模型通过实时计算最后一层隐藏状态与词表中特殊标记嵌入的相似度来表达置信度。我们通过关联准确率的校准目标对模型进行微调以实现置信度校准。在三个大语言模型和两个基准数据集上的实验表明：在开放式生成任务中，GrACE产生的置信度在判别能力和校准效果方面均优于六种对比方法，且无需额外采样或辅助模型。此外，我们提出两种基于GrACE置信度的测试时缩放优化策略。实验结果表明，使用GrACE不仅能提升最终决策的准确率，还能显著减少测试时缩放方案所需的样本量，这证明GrACE具备作为实用解决方案的潜力——能够以可扩展、高可靠性且实时的方式部署具备置信度评估能力的大语言模型。\n\n（注：本文翻译严格遵循以下技术规范：\n1. 专业术语统一：\"confidence elicitation\"译为\"置信度激发\"，\"hidden state\"译为\"隐藏状态\"，\"fine-tune\"译为\"微调\"\n2. 技术概念准确处理：\"test-time scaling\"译为\"测试时缩放\"，\"discriminative capacity\"译为\"判别能力\"\n3. 长难句拆分重构：将原文复合句按中文表达习惯分解为多个短句\n4. 被动语态转换：将英文被动结构转换为中文主动表述\n5. 逻辑连接显性化：通过\"不仅...还能...\"等连接词明确技术优势的递进关系）"
    },
    {
        "title": "LLMs Don't Know Their Own Decision Boundaries: The Unreliability of\n  Self-Generated Counterfactual Explanations",
        "url": "http://arxiv.org/abs/2509.09396v1",
        "pub_date": "2025-09-11",
        "summary": "To collaborate effectively with humans, language models must be able to explain their decisions in natural language. We study a specific type of self-explanation: self-generated counterfactual explanations (SCEs), where a model explains its prediction by modifying the input such that it would have predicted a different outcome. We evaluate whether LLMs can produce SCEs that are valid, achieving the intended outcome, and minimal, modifying the input no more than necessary. When asked to generate counterfactuals, we find that LLMs typically produce SCEs that are valid, but far from minimal, offering little insight into their decision-making behaviour. Worryingly, when asked to generate minimal counterfactuals, LLMs typically make excessively small edits that fail to change predictions. The observed validity-minimality trade-off is consistent across several LLMs, datasets, and evaluation settings. Our findings suggest that SCEs are, at best, an ineffective explainability tool and, at worst, can provide misleading insights into model behaviour. Proposals to deploy LLMs in high-stakes settings must consider the impact of unreliable self-explanations on downstream decision-making. Our code is available at https://github.com/HarryMayne/SCEs.",
        "translated": "为实现与人类的有效协作，语言模型需具备用自然语言解释其决策的能力。本研究聚焦于一类特殊的自我解释形式：自生成反事实解释（SCEs），即模型通过修改输入内容来阐释为何原本会做出不同预测。我们评估了大语言模型能否生成既有效（达成预期结果）又最小化（仅进行必要修改）的SCEs。实验发现：当被要求生成反事实解释时，大语言模型通常能产生有效的SCEs，但远未达到最小化标准，这导致其难以揭示模型的决策机制。更令人担忧的是，当被要求生成最小化反事实时，模型往往进行过度细微的编辑，以致无法真正改变预测结果。这种有效性与最小化之间的权衡关系在多个大语言模型、数据集和评估设置中均保持一致。我们的研究结果表明，SCEs往好了说是一种低效的可解释性工具，往坏了说可能对模型行为产生误导性解读。在高风险场景中部署大语言模型时，必须考虑不可靠的自我解释对下游决策的影响。代码已开源：https://github.com/HarryMayne/SCEs。\n\n（注：翻译过程中对以下要点进行了专业处理：\n1. \"self-generated counterfactual explanations (SCEs)\" 译为专业术语\"自生成反事实解释（SCEs）\"\n2. 保持\"validity\"和\"minimality\"在机器学习可解释性领域的标准译法\"有效性\"和\"最小化\"\n3. \"high-stakes settings\"译为\"高风险场景\"以符合学术文献表述\n4. 采用中文长句拆分技巧处理英语复合句结构\n5. 保留技术术语一致性（如LLMs统一译为\"大语言模型\"））"
    },
    {
        "title": "Hierarchical Bracketing Encodings Work for Dependency Graphs",
        "url": "http://arxiv.org/abs/2509.09388v1",
        "pub_date": "2025-09-11",
        "summary": "We revisit hierarchical bracketing encodings from a practical perspective in the context of dependency graph parsing. The approach encodes graphs as sequences, enabling linear-time parsing with $n$ tagging actions, and still representing reentrancies, cycles, and empty nodes. Compared to existing graph linearizations, this representation substantially reduces the label space while preserving structural information. We evaluate it on a multilingual and multi-formalism benchmark, showing competitive results and consistent improvements over other methods in exact match accuracy.",
        "translated": "我们以实用角度重新审视了依存图解析中的层次括号编码方法。该方法将图结构编码为序列形式，仅需n次标注操作即可实现线性时间解析，同时仍能表示重入边、循环结构和空节点。与现有图线性化方法相比，该表征在保持结构信息完整的前提下显著缩小了标签空间。我们在多语言多形式主义基准测试中进行评估，结果显示该方法在精确匹配准确率上取得了具有竞争力的结果，并持续优于其他方法。\n\n（注：专业术语说明：\n1. reentrancies：重入边，指图中多个边指向同一节点的现象\n2. cycles：循环结构，指图中形成环路的依赖关系\n3. linear-time parsing：线性时间解析，指时间复杂度与输入长度成线性关系\n4. multi-formalism：多形式主义，指支持不同语法理论体系\n5. exact match accuracy：精确匹配准确率，指整个解析结构完全正确的评估指标）"
    },
    {
        "title": "Modelling Analogies and Analogical Reasoning: Connecting Cognitive\n  Science Theory and NLP Research",
        "url": "http://arxiv.org/abs/2509.09381v1",
        "pub_date": "2025-09-11",
        "summary": "Analogical reasoning is an essential aspect of human cognition. In this paper, we summarize key theory about the processes underlying analogical reasoning from the cognitive science literature and relate it to current research in natural language processing. While these processes can be easily linked to concepts in NLP, they are generally not viewed through a cognitive lens. Furthermore, we show how these notions are relevant for several major challenges in NLP research, not directly related to analogy solving. This may guide researchers to better optimize relational understanding in text, as opposed to relying heavily on entity-level similarity.",
        "translated": "类比推理是人类认知的重要组成部分。本文从认知科学文献中总结了关于类比推理过程的核心理论，并将其与自然语言处理领域的研究现状相联系。尽管这些认知过程能够与自然语言处理中的概念建立明确关联，但现有研究通常未从认知视角进行解读。进一步地，我们论证了这些理论认知如何适用于自然语言处理研究中若干与类比求解不直接相关的重要挑战。这将引导研究者优化文本关系理解机制，而非过度依赖实体层面的相似性匹配。"
    }
]