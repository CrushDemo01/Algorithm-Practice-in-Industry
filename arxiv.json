[
    {
        "title": "Soundtracks of Our Lives: How Age Influences Musical Preferences",
        "url": "http://arxiv.org/abs/2509.08337v1",
        "pub_date": "2025-09-10",
        "summary": "The majority of research in recommender systems, be it algorithmic improvements, context-awareness, explainability, or other areas, evaluates these systems on datasets that capture user interaction over a relatively limited time span. However, recommender systems can very well be used continuously for extended time. Similarly so, user behavior may evolve over that extended time. Although media studies and psychology offer a wealth of research on the evolution of user preferences and behavior as individuals age, there has been scant research in this regard within the realm of user modeling and recommender systems. In this study, we investigate the evolution of user preferences and behavior using the LFM-2b dataset, which, to our knowledge, is the only dataset that encompasses a sufficiently extensive time frame to permit real longitudinal studies and includes age information about its users. We identify specific usage and taste preferences directly related to the age of the user, i.e., while younger users tend to listen broadly to contemporary popular music, older users have more elaborate and personalized listening habits. The findings yield important insights that open new directions for research in recommender systems, providing guidance for future efforts.",
        "translated": "当前推荐系统领域的大多数研究——无论是算法改进、上下文感知、可解释性还是其他方向——均基于有限时间跨度的用户交互数据集进行评估。然而，推荐系统实际往往需要长期持续运行，用户行为也可能随时间推移产生演变。尽管媒体研究和心理学领域对用户偏好随年龄演变的规律已有丰富成果，但在用户建模与推荐系统领域中，针对这一问题的研究仍十分匮乏。本研究采用LFM-2b数据集（据我们所知，这是唯一兼具足够长时间跨度支持真实纵向研究、且包含用户年龄信息的数据集）深入探究用户偏好与行为的演变规律。我们发现：年轻用户倾向于广泛收听当代流行音乐，而年长用户则展现出更精细化、个性化的收听习惯——这种使用偏好与品味特征与用户年龄存在直接关联。这些发现为推荐系统研究开辟了新方向，为后续研究提供了重要指导。"
    },
    {
        "title": "Vector embedding of multi-modal texts: a tool for discovery?",
        "url": "http://arxiv.org/abs/2509.08216v1",
        "pub_date": "2025-09-10",
        "summary": "Computer science texts are particularly rich in both narrative content and illustrative charts, algorithms, images, annotated diagrams, etc. This study explores the extent to which vector-based multimodal retrieval, powered by vision-language models (VLMs), can improve discovery across multi-modal (text and images) content. Using over 3,600 digitized textbook pages largely from computer science textbooks and a Vision Language Model (VLM), we generate multi-vector representations capturing both textual and visual semantics. These embeddings are stored in a vector database. We issue a benchmark of 75 natural language queries and compare retrieval performance to ground truth and across four similarity (distance) measures. The study is intended to expose both the strengths and weakenesses of such an approach. We find that cosine similarity most effectively retrieves semantically and visually relevant pages. We further discuss the practicality of using a vector database and multi-modal embedding for operational information retrieval. Our paper is intended to offer design insights for discovery over digital libraries.   Keywords: Vector embedding, multi-modal document retrieval, vector database benchmark, digital library discovery",
        "translated": "计算机科学文献通常兼具丰富的叙述性内容与说明性图表、算法、图像及带标注的图示等。本研究探讨基于视觉语言模型（VLM）的向量多模态检索在提升跨文本与图像的多模态内容发现能力方面的效果。通过使用超过3,600页主要来自计算机科学教材的数字化页面及视觉语言模型，我们生成了能同时捕获文本与视觉语义的多向量表征。这些嵌入向量被存储于向量数据库中。我们发布了包含75个自然语言查询的基准测试集，并将检索效果与人工标注真值进行对比，同时评估了四种相似度（距离）度量方法的性能。本研究旨在揭示此类方法的优势与局限性。研究发现，余弦相似度能够最有效地检索出语义和视觉相关性较高的页面。我们进一步讨论了使用向量数据库与多模态嵌入在实际信息检索操作中的可行性。本文旨在为数字图书馆的文献发现机制提供设计参考。  \n关键词：向量嵌入，多模态文档检索，向量数据库基准测试，数字图书馆发现"
    },
    {
        "title": "Smart Fast Finish: Preventing Overdelivery via Daily Budget Pacing at\n  DoorDash",
        "url": "http://arxiv.org/abs/2509.07929v1",
        "pub_date": "2025-09-09",
        "summary": "We present a budget pacing feature called Smart Fast Finish (SFF). SFF builds upon the industry standard Fast Finish (FF) feature in budget pacing systems that depletes remaining advertising budget as quickly as possible towards the end of some fixed time period. SFF dynamically updates system parameters such as start time and throttle rate depending on historical ad-campaign data. SFF is currently in use at DoorDash, one of the largest delivery platforms in the US, and is part of its budget pacing system. We show via online budget-split experimentation data and offline simulations that SFF is a robust solution for overdelivery mitigation when pacing budget.",
        "translated": "我们提出了一种名为\"智能快速完成\"（Smart Fast Finish, SFF）的预算调控功能。该功能基于行业标准的快速完成（Fast Finish, FF）技术进行优化——在固定时间段末期将剩余广告预算以最快速度消耗完毕。SFF通过分析历史广告活动数据，动态更新系统参数（包括启动时间和调控速率）。目前该功能已应用于美国最大配送平台之一DoorDash的预算调控系统。在线预算分流实验数据和离线仿真结果表明，SFF是一种能有效缓解预算调控过程中超量投放问题的稳健解决方案。\n\n（注：根据学术论文摘要的规范要求，译文采用以下处理：\n1. 专业术语统一：\"budget pacing\"译为\"预算调控\"，\"overdelivery mitigation\"译为\"缓解超量投放\"\n2. 技术概念准确传达：\"dynamic updates\"译为\"动态更新\"，\"throttle rate\"译为\"调控速率\"\n3. 企业名称保留原文：\"DoorDash\"不译\n4. 研究论证表述规范：\"online/offline\"译为\"在线/离线\"，\"robust solution\"译为\"稳健解决方案\"\n5. 保持学术文本的客观性，避免口语化表达）"
    },
    {
        "title": "KLIPA: A Knowledge Graph and LLM-Driven QA Framework for IP Analysis",
        "url": "http://arxiv.org/abs/2509.07860v1",
        "pub_date": "2025-09-09",
        "summary": "Effectively managing intellectual property is a significant challenge. Traditional methods for patent analysis depend on labor-intensive manual searches and rigid keyword matching. These approaches are often inefficient and struggle to reveal the complex relationships hidden within large patent datasets, hindering strategic decision-making. To overcome these limitations, we introduce KLIPA, a novel framework that leverages a knowledge graph and a large language model (LLM) to significantly advance patent analysis. Our approach integrates three key components: a structured knowledge graph to map explicit relationships between patents, a retrieval-augmented generation(RAG) system to uncover contextual connections, and an intelligent agent that dynamically determines the optimal strategy for resolving user queries. We validated KLIPA on a comprehensive, real-world patent database, where it demonstrated substantial improvements in knowledge extraction, discovery of novel connections, and overall operational efficiency. This combination of technologies enhances retrieval accuracy, reduces reliance on domain experts, and provides a scalable, automated solution for any organization managing intellectual property, including technology corporations and legal firms, allowing them to better navigate the complexities of strategic innovation and competitive intelligence.",
        "translated": "有效管理知识产权是一项重大挑战。传统的专利分析方法依赖于劳动密集型的人工检索和僵化的关键词匹配。这些方法往往效率低下，难以揭示海量专利数据中隐藏的复杂关联，从而阻碍战略决策。为突破这些局限，我们提出KLIPA这一创新框架，该框架通过结合知识图谱和大语言模型（LLM）显著推进专利分析能力。我们的方法整合了三个核心组件：用于构建专利间显性关联的结构化知识图谱、用于挖掘上下文联系的检索增强生成（RAG）系统，以及能动态确定最优解策策略的智能代理。我们在真实世界的全量专利数据库上验证了KLIPA，其在知识提取、新颖关联发现和整体操作效率方面均展现出显著提升。这种技术融合增强了检索精度，降低了对领域专家的依赖，为包括科技企业和律师事务所在内的知识产权管理机构提供了可扩展的自动化解决方案，使其能更好地应对战略创新与竞争情报领域的复杂性。"
    },
    {
        "title": "SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and\n  Relation Extraction in NLP",
        "url": "http://arxiv.org/abs/2509.07801v2",
        "pub_date": "2025-09-09",
        "summary": "Structured information extraction from scientific literature is crucial for capturing core concepts and emerging trends in specialized fields. While existing datasets aid model development, most focus on specific publication sections due to domain complexity and the high cost of annotating scientific texts. To address this limitation, we introduce SciNLP - a specialized benchmark for full-text entity and relation extraction in the Natural Language Processing (NLP) domain. The dataset comprises 60 manually annotated full-text NLP publications, covering 7,072 entities and 1,826 relations. Compared to existing research, SciNLP is the first dataset providing full-text annotations of entities and their relationships in the NLP domain. To validate the effectiveness of SciNLP, we conducted comparative experiments with similar datasets and evaluated the performance of state-of-the-art supervised models on this dataset. Results reveal varying extraction capabilities of existing models across academic texts of different lengths. Cross-comparisons with existing datasets show that SciNLP achieves significant performance improvements on certain baseline models. Using models trained on SciNLP, we implemented automatic construction of a fine-grained knowledge graph for the NLP domain. Our KG has an average node degree of 3.2 per entity, indicating rich semantic topological information that enhances downstream applications. The dataset is publicly available at https://github.com/AKADDC/SciNLP.",
        "translated": "从科学文献中抽取结构化信息对于捕捉专业领域的核心概念与新兴趋势至关重要。虽然现有数据集有助于模型开发，但由于领域复杂性和科学文本标注成本高昂，多数数据集仅聚焦特定章节。为突破这一局限，我们推出SciNLP——专为自然语言处理（NLP）领域设计的全文实体与关系抽取基准数据集。该数据集包含60篇经人工标注的NLP领域全文文献，涵盖7,072个实体和1,826组关系。与现有研究相比，SciNLP是首个提供NLP领域全文级实体及其关系标注的数据集。为验证SciNLP的有效性，我们与同类数据集进行对比实验，并评估了前沿监督模型在该数据集上的表现。结果显示现有模型对不同长度学术文本的抽取能力存在显著差异。与现有数据集的交叉对比表明，SciNLP在部分基线模型上实现了显著性能提升。基于SciNLP训练的模型，我们实现了NLP领域细粒度知识图谱的自动构建。该知识图谱平均每个实体拥有3.2个节点连接度，展现出丰富的语义拓扑信息，可有效增强下游应用性能。数据集已公开于https://github.com/AKADDC/SciNLP。\n\n（注：译文严格遵循学术论文表述规范，对\"entity and relation extraction\"采用\"实体与关系抽取\"标准译法，\"knowledge graph\"译为\"知识图谱\"，\"node degree\"译为\"节点连接度\"等专业术语均符合计算机领域中文表达惯例。长难句如\"Results reveal varying...\"通过拆分重组转化为符合中文表达习惯的短句，同时保持逻辑严谨性。）"
    },
    {
        "title": "Query Expansion in the Age of Pre-trained and Large Language Models: A\n  Comprehensive Survey",
        "url": "http://arxiv.org/abs/2509.07794v1",
        "pub_date": "2025-09-09",
        "summary": "Modern information retrieval (IR) must bridge short, ambiguous queries and ever more diverse, rapidly evolving corpora. Query Expansion (QE) remains a key mechanism for mitigating vocabulary mismatch, but the design space has shifted markedly with pre-trained language models (PLMs) and large language models (LLMs). This survey synthesizes the field from three angles: (i) a four-dimensional framework of query expansion - from the point of injection (explicit vs. implicit QE), through grounding and interaction (knowledge bases, model-internal capabilities, multi-turn retrieval) and learning alignment, to knowledge graph-based argumentation; (ii) a model-centric taxonomy spanning encoder-only, encoder-decoder, decoder-only, instruction-tuned, and domain/multilingual variants, highlighting their characteristic affordances for QE (contextual disambiguation, controllable generation, zero-/few-shot reasoning); and (iii) practice-oriented guidance on where and how neural QE helps in first-stage retrieval, multi-query fusion, re-ranking, and retrieval-augmented generation (RAG). We compare traditional query expansion with PLM/LLM-based methods across seven key aspects, and we map applications across web search, biomedicine, e-commerce, open-domain QA/RAG, conversational and code search, and cross-lingual settings. The review distills design grounding and interaction, alignment/distillation (SFT/PEFT/DPO), and KG constraints - as robust remedies to topic drift and hallucination. We conclude with an agenda on quality control, cost-aware invocation, domain/temporal adaptation, evaluation beyond end-task metrics, and fairness/privacy. Collectively, these insights provide a principled blueprint for selecting and combining QE techniques under real-world constraints.",
        "translated": "现代信息检索（IR）需要弥合简短模糊的查询与日益多样化、快速演变的语料库之间的鸿沟。查询扩展（QE）作为缓解词汇失配的关键机制，其设计范式已因预训练语言模型（PLM）和大语言模型（LLM）发生显著转变。本综述从三个维度系统梳理该领域：（i）提出查询扩展的四维框架——从注入方式（显式/隐式QE）出发，贯穿 grounding 与交互机制（知识库、模型内部能力、多轮检索）、学习对齐策略，直至基于知识图谱的论证；（ii）建立以模型为核心的分类体系，涵盖仅编码器、编码器-解码器、仅解码器、指令微调及领域/多语言变体，重点阐释其特有的QE能力（上下文消歧、可控生成、零样本/少样本推理）；（iii）提供实践导向的指南，说明神经QE在首阶段检索、多查询融合、重排序及检索增强生成（RAG）中的适用场景与方法。通过七个关键维度对比传统QE与基于PLM/LLM的方法，并绘制其在网络搜索、生物医学、电子商务、开放域QA/RAG、会话式搜索、代码检索及跨语言场景的应用图谱。研究提炼出三大核心设计原则：基于 grounding 的交互机制、对齐与蒸馏技术（SFT/PEFT/DPO）以及知识图谱约束——这些被证明是解决主题漂移和幻觉问题的有效方案。最后提出质量控制、成本感知调用、领域/时序适应性、超越终端任务指标的评估体系及公平性/隐私保护等未来研究方向。这些见解共同为实际约束条件下QE技术的选择与组合提供了系统化蓝图。\n\n（注：术语处理说明：\n- grounding 保留英文，因中文尚无统一译法且该术语在AI领域常直接使用\n- SFT/PEFT/DPO 为技术缩写（全称：Supervised Fine-Tuning/Parameter-Efficient Fine-Tuning/Direct Preference Optimization）\n- QA/RAG 等缩写已在领域内广泛采用\n- 保持\"零样本/少样本\"等标准译法以符合技术文献惯例）"
    },
    {
        "title": "A Survey of Long-Document Retrieval in the PLM and LLM Era",
        "url": "http://arxiv.org/abs/2509.07759v1",
        "pub_date": "2025-09-09",
        "summary": "The proliferation of long-form documents presents a fundamental challenge to information retrieval (IR), as their length, dispersed evidence, and complex structures demand specialized methods beyond standard passage-level techniques. This survey provides the first comprehensive treatment of long-document retrieval (LDR), consolidating methods, challenges, and applications across three major eras. We systematize the evolution from classical lexical and early neural models to modern pre-trained (PLM) and large language models (LLMs), covering key paradigms like passage aggregation, hierarchical encoding, efficient attention, and the latest LLM-driven re-ranking and retrieval techniques. Beyond the models, we review domain-specific applications, specialized evaluation resources, and outline critical open challenges such as efficiency trade-offs, multimodal alignment, and faithfulness. This survey aims to provide both a consolidated reference and a forward-looking agenda for advancing long-document retrieval in the era of foundation models.",
        "translated": "长文档的激增对信息检索（IR）领域提出了根本性挑战——其篇幅长度、分散的证据分布以及复杂结构要求采用超越标准段落级技术的专门方法。本综述首次对长文档检索（LDR）领域进行系统性梳理，整合了三大技术演进阶段的方法体系、核心挑战与应用实践。我们系统化追溯了从经典词法模型、早期神经模型到现代预训练模型（PLM）及大语言模型（LLMs）的技术演进，涵盖段落聚合、层次化编码、高效注意力机制等关键范式，以及最新LLM驱动的重排序与检索技术。除模型架构外，我们还审视了特定领域应用场景、专项评估资源，并指出效率权衡、多模态对齐和结果可信度等关键开放挑战。本综述旨在为基础模型时代的长文档检索研究提供系统化参考框架与前瞻性发展路线图。"
    },
    {
        "title": "Towards End-to-End Model-Agnostic Explanations for RAG Systems",
        "url": "http://arxiv.org/abs/2509.07620v1",
        "pub_date": "2025-09-09",
        "summary": "Retrieval Augmented Generation (RAG) systems, despite their growing popularity for enhancing model response reliability, often struggle with trustworthiness and explainability. In this work, we present a novel, holistic, model-agnostic, post-hoc explanation framework leveraging perturbation-based techniques to explain the retrieval and generation processes in a RAG system. We propose different strategies to evaluate these explanations and discuss the sufficiency of model-agnostic explanations in RAG systems. With this work, we further aim to catalyze a collaborative effort to build reliable and explainable RAG systems.",
        "translated": "尽管检索增强生成（RAG）系统在提升模型响应可靠性方面日益普及，但其可信度与可解释性仍面临挑战。本研究提出了一种新颖的、整体性的、模型无关的事后解释框架，该框架基于扰动技术来解释RAG系统中的检索与生成过程。我们提出了多种策略来评估这些解释的有效性，并探讨了模型无关解释在RAG系统中的充分性。通过此项研究，我们旨在推动学界与业界共同努力，构建更可靠、更可解释的RAG系统。\n\n（注：译文严格遵循了以下技术细节处理：\n1. \"post-hoc explanation\"译为\"事后解释\"（而非\"事后诸葛亮式解释\"），符合机器学习可解释性领域的术语规范\n2. \"perturbation-based techniques\"译为\"扰动技术\"，准确反映通过对输入进行微小扰动来评估模型敏感度的技术本质\n3. \"model-agnostic\"统一译为\"模型无关\"，保持与机器学习领域术语的一致性\n4. 使用\"可解释性\"而非\"解释性\"，符合人工智能透明度研究领域的标准译法\n5. 保留RAG、LLM等专业术语的英文缩写形式，确保学术严谨性）"
    },
    {
        "title": "ELEC: Efficient Large Language Model-Empowered Click-Through Rate\n  Prediction",
        "url": "http://arxiv.org/abs/2509.07594v1",
        "pub_date": "2025-09-09",
        "summary": "Click-through rate (CTR) prediction plays an important role in online advertising systems. On the one hand, traditional CTR prediction models capture the collaborative signals in tabular data via feature interaction modeling, but they lose semantics in text. On the other hand, Large Language Models (LLMs) excel in understanding the context and meaning behind text, but they face challenges in capturing collaborative signals and they have long inference latency. In this paper, we aim to leverage the benefits of both types of models and pursue collaboration, semantics and efficiency. We present ELEC, which is an Efficient LLM-Empowered CTR prediction framework. We first adapt an LLM for the CTR prediction task. In order to leverage the ability of the LLM but simultaneously keep efficiency, we utilize the pseudo-siamese network which contains a gain network and a vanilla network. We inject the high-level representation vector generated by the LLM into a collaborative CTR model to form the gain network such that it can take advantage of both tabular modeling and textual modeling. However, its reliance on the LLM limits its efficiency. We then distill the knowledge from the gain network to the vanilla network on both the score level and the representation level, such that the vanilla network takes only tabular data as input, but can still generate comparable performance as the gain network. Our approach is model-agnostic. It allows for the integration with various existing LLMs and collaborative CTR models. Experiments on real-world datasets demonstrate the effectiveness and efficiency of ELEC for CTR prediction.",
        "translated": "点击率（CTT）预测在在线广告系统中具有重要作用。一方面，传统CTR预测模型通过特征交互建模捕捉表格数据中的协同信号，但会丢失文本语义信息；另一方面，大语言模型（LLM）擅长理解文本背后的上下文和语义，但在捕捉协同信号方面存在局限且推理延迟较高。本文旨在融合两类模型的优势，实现协同性、语义理解与效率的平衡。我们提出ELEC框架——一种高效的大语言模型赋能CTR预测方案。首先针对CTR预测任务对大语言模型进行适配，为兼顾模型能力与效率，采用包含增益网络和基准网络的双伪孪生网络结构。通过将LLM生成的高层表征向量注入协同CTR模型形成增益网络，使其能同时利用表格建模和文本建模的优势。但该网络对LLM的依赖会影响效率，因此我们通过分数级和表征级蒸馏将增益网络的知识迁移至仅需输入表格数据的基准网络，使其在保持高效的同时达到与增益网络相当的性能。本方法具备模型无关性，可与多种现有LLM及协同CTR模型集成。真实场景数据集上的实验验证了ELEC在CTR预测中的有效性与高效性。"
    },
    {
        "title": "FLeW: Facet-Level and Adaptive Weighted Representation Learning of\n  Scientific Documents",
        "url": "http://arxiv.org/abs/2509.07531v1",
        "pub_date": "2025-09-09",
        "summary": "Scientific document representation learning provides powerful embeddings for various tasks, while current methods face challenges across three approaches. 1) Contrastive training with citation-structural signals underutilizes citation information and still generates single-vector representations. 2) Fine-grained representation learning, which generates multiple vectors at the sentence or aspect level, requires costly integration and lacks domain generalization. 3) Task-aware learning depends on manually predefined task categorization, overlooking nuanced task distinctions and requiring extra training data for task-specific modules. To address these problems, we propose a new method that unifies the three approaches for better representations, namely FLeW. Specifically, we introduce a novel triplet sampling method that leverages citation intent and frequency to enhance citation-structural signals for training. Citation intents (background, method, result), aligned with the general structure of scientific writing, facilitate a domain-generalized facet partition for fine-grained representation learning. Then, we adopt a simple weight search to adaptively integrate three facet-level embeddings into a task-specific document embedding without task-aware fine-tuning. Experiments show the applicability and robustness of FLeW across multiple scientific tasks and fields, compared to prior models.",
        "translated": "科学文献表示学习为各类任务提供了强大的嵌入向量，但现有方法面临三大挑战：1）基于引文结构信号的对比训练未能充分利用引文信息，且仍生成单一向量表示；2）细粒度表示学习虽能生成句子或方面级的多向量表示，但需要昂贵的人工整合且缺乏领域泛化能力；3）任务感知学习依赖人工预定义的任务分类，忽略了细微的任务差异，且需为特定任务模块提供额外训练数据。针对这些问题，我们提出统一三种范式的新方法FLeW以获取更优表示。具体而言，我们设计了一种新型三元组采样方法，通过引文意图（背景、方法、结果）和引用频次增强引文结构信号训练——引文意图与科学写作通用结构相契合，可为细粒度表示学习提供领域泛化的方面划分。随后采用简易权重搜索机制，无需任务感知微调即可自适应整合三个方面级嵌入形成任务适配的文档表示。实验表明，相较于现有模型，FLeW在多个科学任务和学科领域均展现出卓越的适用性与鲁棒性。"
    },
    {
        "title": "ALLabel: Three-stage Active Learning for LLM-based Entity Recognition\n  using Demonstration Retrieval",
        "url": "http://arxiv.org/abs/2509.07512v1",
        "pub_date": "2025-09-09",
        "summary": "Many contemporary data-driven research efforts in the natural sciences, such as chemistry and materials science, require large-scale, high-performance entity recognition from scientific datasets. Large language models (LLMs) have increasingly been adopted to solve the entity recognition task, with the same trend being observed on all-spectrum NLP tasks. The prevailing entity recognition LLMs rely on fine-tuned technology, yet the fine-tuning process often incurs significant cost. To achieve a best performance-cost trade-off, we propose ALLabel, a three-stage framework designed to select the most informative and representative samples in preparing the demonstrations for LLM modeling. The annotated examples are used to construct a ground-truth retrieval corpus for LLM in-context learning. By sequentially employing three distinct active learning strategies, ALLabel consistently outperforms all baselines under the same annotation budget across three specialized domain datasets. Experimental results also demonstrate that selectively annotating only 5\\%-10\\% of the dataset with ALLabel can achieve performance comparable to the method annotating the entire dataset. Further analyses and ablation studies verify the effectiveness and generalizability of our proposal.",
        "translated": "在化学与材料科学等自然科学的当代数据驱动研究中，大规模高性能的实体识别已成为科学数据集处理的关键需求。大型语言模型（LLMs）正被日益广泛地应用于实体识别任务，这一趋势也体现在全谱系自然语言处理任务中。当前主流的实体识别大模型依赖于微调技术，但微调过程往往伴随着高昂成本。为实现性能与成本的最优平衡，我们提出ALLabel——一个三阶段框架，通过三种主动学习策略的序列化应用，从标注数据中筛选信息量最大且最具代表性的样本，用于构建大模型上下文学习所需的真实标注检索库。在三个专业领域数据集上，ALLabel在相同标注预算下持续超越所有基线模型。实验结果表明：使用ALLabel仅需标注5%-10%的数据量即可达到全量标注方法的性能水平。进一步的解析与消融研究验证了该方案的有效性和泛化能力。\n\n（注：专业术语说明：\n1. entity recognition：实体识别\n2. large language models (LLMs)：大型语言模型\n3. fine-tuned technology：微调技术\n4. active learning strategies：主动学习策略\n5. in-context learning：上下文学习\n6. ablation studies：消融研究\n7. annotation budget：标注预算\n8. ground-truth retrieval corpus：真实标注检索库）"
    },
    {
        "title": "Multi-view-guided Passage Reranking with Large Language Models",
        "url": "http://arxiv.org/abs/2509.07485v1",
        "pub_date": "2025-09-09",
        "summary": "Recent advances in large language models (LLMs) have shown impressive performance in passage reranking tasks. Despite their success, LLM-based methods still face challenges in efficiency and sensitivity to external biases. (1) Existing models rely mostly on autoregressive generation and sliding window strategies to rank passages, which incur heavy computational overhead as the number of passages increases. (2) External biases, such as position or selection bias, hinder the model's ability to accurately represent passages and increase input-order sensitivity. To address these limitations, we introduce a novel passage reranking model, called Multi-View-guided Passage Reranking (MVP). MVP is a non-generative LLM-based reranking method that encodes query-passage information into diverse view embeddings without being influenced by external biases. For each view, it combines query-aware passage embeddings to produce a distinct anchor vector, which is then used to directly compute relevance scores in a single decoding step. In addition, it employs an orthogonal loss to make the views more distinctive. Extensive experiments demonstrate that MVP, with just 220M parameters, matches the performance of much larger 7B-scale fine-tuned models while achieving a 100x reduction in inference latency. Notably, the 3B-parameter variant of MVP achieves state-of-the-art performance on both in-domain and out-of-domain benchmarks. The source code is available at: https://github.com/bulbna/MVP",
        "translated": "近年来，大语言模型（LLM）在段落重排序任务中展现出卓越性能。尽管成效显著，基于LLM的方法仍面临效率问题与外部偏差敏感性两大挑战：（1）现有模型主要依赖自回归生成和滑动窗口策略进行段落排序，随着段落数量增加会产生巨大计算开销；（2）位置偏差和选择偏差等外部因素会干扰模型对段落的准确表征，并增强对输入顺序的敏感性。为解决这些局限性，我们提出了一种新型段落重排序模型——多视角引导段落重排序（MVP）。该非生成式LLM重排序方法通过将查询-段落信息编码为多视角嵌入向量，有效规避外部偏差影响。针对每个视角，模型融合查询感知的段落嵌入生成独特锚点向量，进而通过单步解码直接计算相关性得分。此外，该方法采用正交损失函数以增强视角区分度。大量实验表明，仅需2.2亿参数的MVP模型在实现推理延迟降低100倍的同时，性能可媲美70亿参数规模的精调模型。特别值得注意的是，30亿参数版本的MVP在领域内和领域外基准测试中均达到了最先进的性能水平。源代码已开源：https://github.com/bulbna/MVP\n\n（注：译文严格遵循以下技术规范：\n1. 专业术语统一处理：\"autoregressive generation\"译为\"自回归生成\"，\"orthogonal loss\"译为\"正交损失函数\"\n2. 数量单位规范：\"220M/7B\"转换为\"2.2亿/70亿\"符合中文计量习惯\n3. 技术概念准确传达：\"view embeddings\"意译为\"视角嵌入向量\"而非字面直译\n4. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句\n5. 被动语态转化：\"are used to\"转换为主动语态\"通过...实现\"\n6. 学术表达规范：\"state-of-the-art\"译为\"最先进的\"符合学术中文惯例）"
    },
    {
        "title": "MEGG: Replay via Maximally Extreme GGscore in Incremental Learning for\n  Neural Recommendation Models",
        "url": "http://arxiv.org/abs/2509.07319v1",
        "pub_date": "2025-09-09",
        "summary": "Neural Collaborative Filtering models are widely used in recommender systems but are typically trained under static settings, assuming fixed data distributions. This limits their applicability in dynamic environments where user preferences evolve. Incremental learning offers a promising solution, yet conventional methods from computer vision or NLP face challenges in recommendation tasks due to data sparsity and distinct task paradigms. Existing approaches for neural recommenders remain limited and often lack generalizability. To address this, we propose MEGG, Replay Samples with Maximally Extreme GGscore, an experience replay based incremental learning framework. MEGG introduces GGscore, a novel metric that quantifies sample influence, enabling the selective replay of highly influential samples to mitigate catastrophic forgetting. Being model-agnostic, MEGG integrates seamlessly across architectures and frameworks. Experiments on three neural models and four benchmark datasets show superior performance over state-of-the-art baselines, with strong scalability, efficiency, and robustness. Implementation will be released publicly upon acceptance.",
        "translated": "神经协同过滤模型在推荐系统中应用广泛，但通常基于静态设定进行训练，假设数据分布固定不变。这限制了其在用户偏好动态演变环境中的适用性。增量学习虽提供了可行方案，但来自计算机视觉或自然语言处理领域的传统方法因数据稀疏性和任务范式差异，在推荐任务中面临挑战。现有神经推荐器的增量学习方法仍存在局限，且普遍缺乏泛化能力。为此，我们提出MEGG（基于极端GG分数的回放样本）——一种基于经验回放的增量学习框架。MEGG创新性地引入GGscore指标，通过量化样本影响力来实现高效选择性样本回放，从而有效缓解灾难性遗忘问题。该框架具备模型无关特性，可无缝集成至不同架构与框架。在三种神经模型和四个基准数据集上的实验表明，其性能显著优于现有最优基线方法，并展现出强大的可扩展性、高效性和鲁棒性。代码实现将在论文录用后开源发布。\n\n（注：GGscore保留英文大写形式，符合技术术语惯例；\"catastrophic forgetting\"译为专业术语\"灾难性遗忘\"；\"model-agnostic\"采用通用译法\"模型无关\"；\"state-of-the-art\"译为\"现有最优\"符合学术语境）"
    },
    {
        "title": "Datasets for Navigating Sensitive Topics in Recommendation Systems",
        "url": "http://arxiv.org/abs/2509.07269v1",
        "pub_date": "2025-09-08",
        "summary": "Personalized AI systems, from recommendation systems to chatbots, are a prevalent method for distributing content to users based on their learned preferences. However, there is growing concern about the adverse effects of these systems, including their potential tendency to expose users to sensitive or harmful material, negatively impacting overall well-being. To address this concern quantitatively, it is necessary to create datasets with relevant sensitivity labels for content, enabling researchers to evaluate personalized systems beyond mere engagement metrics. To this end, we introduce two novel datasets that include a taxonomy of sensitivity labels alongside user-content ratings: one that integrates MovieLens rating data with content warnings from the Does the Dog Die? community ratings website, and another that combines fan-fiction interaction data and user-generated warnings from Archive of Our Own.",
        "translated": "个性化人工智能系统（从推荐系统到聊天机器人）已成为根据用户学习偏好分发内容的普遍方式。然而，人们日益关注这些系统的负面影响，特别是其可能使用户接触敏感或有害内容，从而对整体福祉产生负面影响的倾向。为量化评估这一问题，需要构建带有内容敏感度标签的数据集，使研究者能够超越简单的参与度指标来评估个性化系统。为此，我们引入了两个新型数据集：一个将MovieLens评分数据与Does the Dog Die?社区评级网站的内容警示标签体系相结合，另一个整合了Archive of Our Own平台的同人小说互动数据与用户生成的警示标签。这些数据集不仅包含用户-内容评分，还提供了系统化的敏感度分类标注。"
    },
    {
        "title": "Benchmarking Information Retrieval Models on Complex Retrieval Tasks",
        "url": "http://arxiv.org/abs/2509.07253v1",
        "pub_date": "2025-09-08",
        "summary": "Large language models (LLMs) are incredible and versatile tools for text-based tasks that have enabled countless, previously unimaginable, applications. Retrieval models, in contrast, have not yet seen such capable general-purpose models emerge. To achieve this goal, retrieval models must be able to perform complex retrieval tasks, where queries contain multiple parts, constraints, or requirements in natural language. These tasks represent a natural progression from the simple, single-aspect queries that are used in the vast majority of existing, commonly used evaluation sets. Complex queries naturally arise as people expect search systems to handle more specific and often ambitious information requests, as is demonstrated by how people use LLM-based information systems. Despite the growing desire for retrieval models to expand their capabilities in complex retrieval tasks, there exist limited resources to assess the ability of retrieval models on a comprehensive set of diverse complex tasks. The few resources that do exist feature a limited scope and often lack realistic settings making it hard to know the true capabilities of retrieval models on complex real-world retrieval tasks. To address this shortcoming and spur innovation in next-generation retrieval models, we construct a diverse and realistic set of complex retrieval tasks and benchmark a representative set of state-of-the-art retrieval models. Additionally, we explore the impact of LLM-based query expansion and rewriting on retrieval quality. Our results show that even the best models struggle to produce high-quality retrieval results with the highest average nDCG@10 of only 0.346 and R@100 of only 0.587 across all tasks. Although LLM augmentation can help weaker models, the strongest model has decreased performance across all metrics with all rewriting techniques.",
        "translated": "大型语言模型（LLM）是处理文本任务的卓越多功能工具，其催生了无数前所未有的应用场景。相比之下，检索模型领域尚未出现具备同等通用能力的模型。要实现这一目标，检索模型必须能够处理复杂检索任务——即查询语句包含多组成部分、约束条件或自然语言需求的场景。这类任务代表着对现有主流评估集中普遍采用的简单单维度查询的自然演进。随着用户期望搜索系统能处理更具体且更具挑战性的信息请求（正如基于LLM的信息系统的使用方式所展现的），复杂查询需求应运而生。\n\n尽管业界对检索模型拓展复杂检索能力的呼声日益高涨，但目前缺乏能够全面评估检索模型在多样化复杂任务上表现的标准资源。现有少数评估资源不仅覆盖范围有限，且往往缺乏真实场景设置，导致难以准确衡量检索模型在现实复杂检索任务中的真实能力。\n\n为弥补这一缺陷并推动下一代检索模型的发展，我们构建了具有多样性和真实性的复杂检索任务集，并对代表性前沿检索模型进行基准测试。此外，我们还探究了基于LLM的查询扩展与重写技术对检索质量的影响。实验结果表明：即使最优模型在复杂检索任务中也表现挣扎，所有任务的平均nDCG@10最高仅达0.346，R@100最高仅为0.587。虽然LLM增强技术能提升较弱模型的性能，但所有重写技术都会导致最强模型的全指标性能下降。"
    },
    {
        "title": "Beyond Sequential Reranking: Reranker-Guided Search Improves Reasoning\n  Intensive Retrieval",
        "url": "http://arxiv.org/abs/2509.07163v1",
        "pub_date": "2025-09-08",
        "summary": "The widely used retrieve-and-rerank pipeline faces two critical limitations: they are constrained by the initial retrieval quality of the top-k documents, and the growing computational demands of LLM-based rerankers restrict the number of documents that can be effectively processed. We introduce Reranker-Guided-Search (RGS), a novel approach that bypasses these limitations by directly retrieving documents according to reranker preferences rather than following the traditional sequential reranking method. Our method uses a greedy search on proximity graphs generated by approximate nearest neighbor algorithms, strategically prioritizing promising documents for reranking based on document similarity. Experimental results demonstrate substantial performance improvements across multiple benchmarks: 3.5 points on BRIGHT, 2.9 on FollowIR, and 5.1 on M-BEIR, all within a constrained reranker budget of 100 documents. Our analysis suggests that, given a fixed pair of embedding and reranker models, strategically selecting documents to rerank can significantly improve retrieval accuracy under limited reranker budget.",
        "translated": "当前广泛使用的“检索-重排序”流程面临两个关键局限：其性能受限于前k篇文档的初始检索质量，且基于大语言模型的重排序器计算需求日益增长，限制了可有效处理的文档数量。我们提出了一种创新方法——重排序器引导搜索（Reranker-Guided-Search, RGS），通过直接根据重排序器的偏好检索文档（而非遵循传统的顺序重排序流程）来突破这些限制。该方法在近似最近邻算法生成的邻近图上进行贪婪搜索，基于文档相似性策略性地优先选择有潜力的文档进行重排序。实验结果表明，在多个基准测试中均取得显著性能提升：BRIGHT数据集提升3.5个点，FollowIR提升2.9个点，M-BEIR提升5.1个点——且所有这些改进均在100篇文档的重排序计算预算内实现。我们的分析表明，在固定嵌入模型和重排序器组合的前提下，通过策略性选择待重排序文档，能够在有限计算资源下显著提升检索精度。\n\n（注：专业术语说明：\n1. retrieve-and-rerank pipeline：译为\"检索-重排序流程\"\n2. LLM-based rerankers：译为\"基于大语言模型的重排序器\"\n3. proximity graphs：译为\"邻近图\"\n4. approximate nearest neighbor：译为\"近似最近邻\"\n5. constrained reranker budget：译为\"受限的重排序计算预算\"\n6. embedding model：译为\"嵌入模型\"\n所有技术概念均采用计算机信息检索领域标准译法，确保学术准确性。）"
    },
    {
        "title": "Avoiding Over-Personalization with Rule-Guided Knowledge Graph\n  Adaptation for LLM Recommendations",
        "url": "http://arxiv.org/abs/2509.07133v1",
        "pub_date": "2025-09-08",
        "summary": "We present a lightweight neuro-symbolic framework to mitigate over-personalization in LLM-based recommender systems by adapting user-side Knowledge Graphs (KGs) at inference time. Instead of retraining models or relying on opaque heuristics, our method restructures a user's Personalized Knowledge Graph (PKG) to suppress feature co-occurrence patterns that reinforce Personalized Information Environments (PIEs), i.e., algorithmically induced filter bubbles that constrain content diversity. These adapted PKGs are used to construct structured prompts that steer the language model toward more diverse, Out-PIE recommendations while preserving topical relevance. We introduce a family of symbolic adaptation strategies, including soft reweighting, hard inversion, and targeted removal of biased triples, and a client-side learning algorithm that optimizes their application per user. Experiments on a recipe recommendation benchmark show that personalized PKG adaptations significantly increase content novelty while maintaining recommendation quality, outperforming global adaptation and naive prompt-based methods.",
        "translated": "我们提出了一种轻量级神经符号框架，通过推理时自适应调整用户侧知识图谱（KG）来缓解基于大语言模型的推荐系统中的过度个性化问题。与传统重训练模型或依赖不透明启发式方法不同，我们的方法通过重构用户个性化知识图谱（PKG），抑制那些强化个性化信息环境（PIE）的特征共现模式——即算法导致的限制内容多样性的信息茧房。调整后的PKG用于构建结构化提示，引导语言模型在保持主题相关性的同时生成更多样化的\"非PIE\"推荐。我们提出了一系列符号化适配策略，包括软重加权、硬反转和针对性移除偏见三元组，以及客户端学习算法以优化每用户的策略应用。在食谱推荐基准测试中，个性化PKG适配在保持推荐质量的同时显著提升内容新颖度，其效果优于全局适配和基于朴素提示的方法。\n\n（注：专业术语说明：\n1. Personalized Information Environments (PIEs) 译为\"个性化信息环境\"，特指算法导致的信息茧房效应\n2. Out-PIE recommendations 译为\"非PIE推荐\"，指突破信息茧房的推荐内容\n3. soft reweighting/hard inversion 分别译为\"软重加权/硬反转\"，保持机器学习领域的术语惯例\n4. client-side learning algorithm 译为\"客户端学习算法\"，强调分布式计算场景下的本地化特性）"
    },
    {
        "title": "mmBERT: A Modern Multilingual Encoder with Annealed Language Learning",
        "url": "http://arxiv.org/abs/2509.06888v1",
        "pub_date": "2025-09-08",
        "summary": "Encoder-only languages models are frequently used for a variety of standard machine learning tasks, including classification and retrieval. However, there has been a lack of recent research for encoder models, especially with respect to multilingual models. We introduce mmBERT, an encoder-only language model pretrained on 3T tokens of multilingual text in over 1800 languages. To build mmBERT we introduce several novel elements, including an inverse mask ratio schedule and an inverse temperature sampling ratio. We add over 1700 low-resource languages to the data mix only during the decay phase, showing that it boosts performance dramatically and maximizes the gains from the relatively small amount of training data. Despite only including these low-resource languages in the short decay phase we achieve similar classification performance to models like OpenAI's o3 and Google's Gemini 2.5 Pro. Overall, we show that mmBERT significantly outperforms the previous generation of models on classification and retrieval tasks -- on both high and low-resource languages.",
        "translated": "编码器专用语言模型（Encoder-only language models）常被用于各类标准机器学习任务，包括分类与检索。然而当前针对编码器模型的研究，特别是多语言模型领域的研究仍显不足。我们提出了mmBERT——一种基于1800多种语言、3万亿多语种文本训练的纯编码器语言模型。在构建mmBERT过程中，我们引入了多项创新要素，包括逆向掩码比率调度机制和逆向温度采样策略。我们创新性地仅在训练衰减阶段加入1700余种低资源语言数据，实验表明这一方法显著提升模型性能，并最大限度利用了有限训练数据带来的增益。尽管这些低资源语言仅出现在短暂的衰减阶段，我们的模型在分类任务上达到了与OpenAI o3、Google Gemini 2.5 Pro等模型相当的性能。总体而言，mmBERT在高资源与低资源语言的分类和检索任务上均显著超越前代模型。"
    },
    {
        "title": "UniSearch: Rethinking Search System with a Unified Generative\n  Architecture",
        "url": "http://arxiv.org/abs/2509.06887v2",
        "pub_date": "2025-09-08",
        "summary": "Modern search systems play a crucial role in facilitating information acquisition. Traditional search engines typically rely on a cascaded architecture, where results are retrieved through recall, pre-ranking, and ranking stages. The complexity of designing and maintaining multiple modules makes it difficult to achieve holistic performance gains. Recent advances in generative recommendation have motivated the exploration of unified generative search as an alternative. However, existing approaches are not genuinely end-to-end: they typically train an item encoder to tokenize candidates first and then optimize a generator separately, leading to objective inconsistency and limited generalization. To address these limitations, we propose UniSearch, a unified generative search framework for Kuaishou Search. UniSearch replaces the cascaded pipeline with an end-to-end architecture that integrates a Search Generator and a Video Encoder. The Generator produces semantic identifiers of relevant items given a user query, while the Video Encoder learns latent item embeddings and provides their tokenized representations. A unified training framework jointly optimizes both components, enabling mutual enhancement and improving representation quality and generation accuracy. Furthermore, we introduce Search Preference Optimization (SPO), which leverages a reward model and real user feedback to better align generation with user preferences. Extensive experiments on industrial-scale datasets, together with online A/B testing in both short-video and live search scenarios, demonstrate the strong effectiveness and deployment potential of UniSearch. Notably, its deployment in live search yields the largest single-experiment improvement in recent years of our product's history, highlighting its practical value for real-world applications.",
        "translated": "现代搜索系统在促进信息获取方面发挥着关键作用。传统搜索引擎通常采用级联架构，通过召回、粗排和精排三个阶段获取结果。由于需要设计和维护多个模块，这种架构难以实现整体性能提升。生成式推荐的最新进展推动了统一生成式搜索的探索，但现有方法并非真正的端到端系统：它们通常先训练物品编码器对候选项目进行标记化，再单独优化生成器，导致目标不一致和泛化能力有限。\n\n为解决这些局限性，我们提出UniSearch——面向快手搜索的统一生成式搜索框架。该框架采用端到端架构替代级联流水线，集成搜索生成器与视频编码器。生成器根据用户查询生成相关项目的语义标识，视频编码器则学习潜在物品嵌入并提供其标记化表示。通过统一训练框架联合优化两个组件，实现相互增强并提升表示质量与生成准确性。此外，我们引入搜索偏好优化（SPO）技术，利用奖励模型和真实用户反馈使生成结果更贴合用户偏好。\n\n基于工业级数据集的大量实验，以及在短视频和直播搜索场景中的在线A/B测试，证明了UniSearch的强大有效性和部署潜力。值得注意的是，该框架在直播搜索场景的部署实现了我们产品近年来最大幅度的单次实验效果提升，凸显了其在实际应用中的重要价值。"
    },
    {
        "title": "UNH at CheckThat! 2025: Fine-tuning Vs Prompting in Claim Extraction",
        "url": "http://arxiv.org/abs/2509.06883v1",
        "pub_date": "2025-09-08",
        "summary": "We participate in CheckThat! Task 2 English and explore various methods of prompting and in-context learning, including few-shot prompting and fine-tuning with different LLM families, with the goal of extracting check-worthy claims from social media passages. Our best METEOR score is achieved by fine-tuning a FLAN-T5 model. However, we observe that higher-quality claims can sometimes be extracted using other methods, even when their METEOR scores are lower.",
        "translated": "我们参与了CheckThat!任务2的英文赛道，重点探索了多种提示方法与上下文学习策略，包括小样本提示（few-shot prompting）以及基于不同大语言模型（LLM）家族的微调方法，旨在从社交媒体文本中提取值得核查的声明。实验表明，通过对FLAN-T5模型进行微调，我们取得了最佳的METEOR评分。然而，我们注意到在某些情况下，即使其他方法的METEOR分数较低，仍能提取出质量更高的声明内容。"
    }
]